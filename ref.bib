
@article{Riehle1997,
	title = {Spike synchronization and rate modulation differentially involved in motor cortical function},
	volume = {278},
	doi = {10.1126/science.278.5345.1950},
	number = {5345},
	journal = {Science (New York, N.Y.)},
	author = {Riehle, Alexa and Grun, Sonja and Diesmann, Markus and Aertsen, Ad},
	year = {1997},
	note = {tex.ids= Riehle1997a
publisher: American Association for the Advancement of Science},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {1950--1953},
	annote = {Publisher: American Association for the Advancement of Science},
	annote = {Publisher: American Association for the Advancement of Science},
	annote = {Publisher: American Association for the Advancement of Science},
}

@inproceedings{MansourPour2018,
	title = {Speed uncertainty and motion perception with naturalistic random textures},
	copyright = {All rights reserved},
	url = {https://laurentperrinet.github.io/publication/mansour-18-vss},
	doi = {10/ggkdkj},
	abstract = {It is still not fully understood how visual system integrates motion energy across different spatial and temporal frequencies to build a coherent percept of the global motion under the complex, noisy naturalistic conditions. We addressed this question by manipulating local speed variability distribution (i. e. speed bandwidth) using a well-controlled class of broadband random-texture stimuli called Motion Clouds (MCs) with continuous naturalistic spatiotemporal frequency spectra (Sanz-Leon et al., 2012, ; Simoncini et al., 2012). In a first 2AFC experiment on speed discrimination, participants had to compare the speed of a broad speed bandwidth MC (range: 0.05-8 $^{\textrm{∘}}$/s) moving at 1 of 5 possible mean speeds (ranging from 5 to 13  $^{\textrm{∘}}$/s) to that of another MC with a small speed bandwidth (SD: 0.05  $^{\textrm{∘}}$/s), always moving at a mean speed of 10 $^{\textrm{∘}}$/s . We found that MCs with larger speed bandwidth (between 0.05-0.5 $^{\textrm{∘}}$/s) were perceived moving faster. Within this range, speed uncertainty results in over-estimating stimulus velocity. However, beyond a critical bandwidth (SD: 0.5  $^{\textrm{∘}}$/s), perception of a coherent speed was lost. In a second 2AFC experiment on direction discrimination, participants had to estimate the motion direction of moving MCs with different speed bandwidths. We found that for large band MCs participant could no longer discriminate motion direction. These results suggest that when increasing speed bandwidth from small to large range, the observer experiences different perceptual regimes. We then decided to run a Maximum Likelihood Difference Scaling (Knoblauch \& Maloney, 2008) experiment with our speed bandwidth stimuli to investigate these different possible perceptual regimes. We identified three regimes within this space that correspond to motion coherency, motion transparency and motion incoherency. These results allow to further characterize the shape of the interactions kernel observed between different speed tuned channels and different spatiotemporal scales (Gekas et al ., 2017) that underlies global velocity estimation.},
	booktitle = {Journal of {Vision}, {Vol}.18, 345, proceedings of {VSS}},
	author = {Mansour Pour, Kiana and Gekas, Nikos and Mamassian, Pascal and Perrinet, Laurent U and Montagnini, Anna and Masson, Guillaume S},
	year = {2018},
	note = {00000 
tex.bdsk-url-2: https://doi.org/10.1167/18.10.345
tex.date-added: 2019-02-25 23:39:35 +0100
tex.date-modified: 2019-07-23 11:33:25 +0200
tex.number: 26.472},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, motion detection},
	annote = {* see https://www.visionsciences.org/programs/VSS₂018Abstracts.pdf * see https://jov.arvojournals.org/article.aspx?articleid=2699338},
	annote = {* see https://www.visionsciences.org/programs/VSS₂018Abstracts.pdf * see https://jov.arvojournals.org/article.aspx?articleid=2699338},
}

@incollection{Perrinet2015a,
	address = {Weinheim, Germany},
	title = {Sparse {Models} for {Computer} {Vision}},
	copyright = {All rights reserved},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9783527680863.ch14/summary},
	booktitle = {Biologically {Inspired} {Computer} {Vision}},
	publisher = {Wiley-VCH Verlag GmbH \& Co. KGaA},
	author = {Perrinet, Laurent U},
	editor = {Keil, Matthias and Cristóbal, Gabriel and Perrinet, Laurent U},
	month = aug,
	year = {2015},
	doi = {10.1002/9783527680863.ch14},
	note = {Section: 13
tex.date-modified: 2020-01-07 12:54:57 +0100
tex.ids: Perrinet15bicv,Perrinet2015c
tex.preprint: https://hal-amu.archives-ouvertes.fr/hal-01444362
tex.url\_code: https://github.com/bicv/Perrinet2015BICVₛparse},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, anr-trax, bicv-sparse, Biologically Inspired Computer vision, sanz12jnp, sparse coding, vacher14},
	pages = {319--346},
}

@article{Boutin2020a,
	title = {Sparse {Deep} {Predictive} {Coding} captures contour integration capabilities of the early visual system},
	copyright = {All rights reserved},
	url = {https://doi.org/10.1371/journal.pcbi.1008629},
	doi = {10.1371/journal.pcbi.1008629},
	abstract = {Both neurophysiological and psychophysical experiments have pointed out the crucial role of recurrent and feedback connections to process context-dependent information in the early visual cortex. While numerous models have accounted for feedback effects at either neural or representational level, none of them were able to bind those two levels of analysis. Is it possible to describe feedback effects at both levels using the same model? We answer this question by combining Predictive Coding (PC) and Sparse Coding (SC) into a hierarchical and convolutional framework. In this Sparse Deep Predictive Coding (SDPC) model, the SC component models the internal recurrent processing within each layer, and the PC component describes the interactions between layers using feedforward and feedback connections. Here, we train a 2-layered SDPC on two different databases of images, and we interpret it as a model of the early visual system (V1 \& V2). We first demonstrate that once the training has converged, SDPC exhibits oriented and localized receptive fields in V1 and more complex features in V2. Second, we analyze the effects of feedback on the neural organization beyond the classical receptive field of V1 neurons using interaction maps. These maps are similar to association fields and reflect the Gestalt principle of good continuation. We demonstrate that feedback signals reorganize interaction maps and modulate neural activity to promote contour integration. Third, we demonstrate at the representational level that the SDPC feedback connections are able to overcome noise in input images. Therefore, the SDPC captures the association field principle at the neural level which results in better disambiguation of blurred images at the representational level.},
	journal = {PLoS Computational Biology},
	author = {Boutin, Victor and Franciosini, Angelo and Chavane, Frédéric Y and Ruffier, Franck and Perrinet, Laurent U},
	month = may,
	year = {2020},
	note = {tex.date-added: 2019-06-18 13:53:53 +0200
tex.date-modified: 2020-12-12 11:55:20 +0100
tex.grants: doc-2-amu,phd-icn,mesocentre
tex.preprint: https://arxiv.org/abs/1902.07651
tex.url\_code: https://github.com/VictorBoutin/InteractionMap
publisher: Public Library of Science San Francisco, CA USA},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, deep-learning, sparse coding},
}

@article{Perrinet2012,
	title = {Motion-{Based} {Prediction} {Is} {Sufficient} to {Solve} the {Aperture} {Problem}},
	volume = {24},
	copyright = {All rights reserved},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/NECO_a_00332 http://arxiv.org/abs/1208.6471 http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00332 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3472550&tool=pmcentrez&rendertype=abstract http://arxiv.org/pdf/12},
	doi = {10/f38x32},
	abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to physio-logy and behavior. We demonstrate that this solution is the result of two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independent of their texture. Second, we observe that incoherent features are explained away, while coherent information diffuses progressively to the global scale. Most previous models included ad hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features as necessary conditions to solve the aperture problem. Here, we have proved that motion-based predictive coding, as it is implemented in this functional model, is sufficient to solve the aperture problem. This solution may give insights into the role of prediction underlying a large class of sensory computations.},
	number = {10},
	journal = {Neural Computation},
	author = {Perrinet, Laurent U. and Masson, G.S. Guillaume S.},
	month = aug,
	year = {2012},
	note = {tex.ids= Perrinet12pred, Perrinet2012b
tex.date-modified: 2019-02-24 23:49:43 +0100
tex.eprint: 22734489
tex.eprinttype: pmid
tex.url\_pdf: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3472550/},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, aperture, aperture problem, aperture-problem, association field, Bayesian model, coding, emergence, khoei12jpp, khoei13jpp, motion detection, motion prediction, perrinet12pred, predictive, predictive coding, predictive-coding, probabilistic, probabilistic representation, problem, representation, thesis, toupate-inpress},
	pages = {2726--2750},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/VCX9DYPA/Perrinet et Masson - 2012 - Motion-Based Prediction Is Sufficient to Solve the.pdf:application/pdf},
}

@article{Sun2016,
	title = {Learning polychronous neuronal groups using joint weight-delay spike-timing-dependent plasticity},
	volume = {28},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00879},
	doi = {10.1162/NECO_a_00879},
	abstract = {Polychronous neuronal group (PNG), a type of cell assembly, is one of the putative mechanisms for neural information representation. According to the reader-centric definition, some readout neurons can become selective to the information represented by polychronous neuronal groups under ongoing activity. Here, in computational models, we show that the frequently activated polychronous neuronal groups can be learned by readout neurons with joint weight-delay spike-timing-dependent plasticity. The identity of neurons in the group and their expected spike timing at millisecond scale can be recovered from the incoming weights and delays of the readout neurons. The detection performance can be further improved by two layers of readout neurons. In this way, the detection of polychronous neuronal groups becomes an intrinsic part of the network, and the readout neurons become differentiated members in the group to indicate whether subsets of the group have been activated according to their spike timing. The readout spikes representing this information can be used to analyze how PNGs interact with each other or propagate to downstream networks for higher-level processing.},
	number = {10},
	journal = {Neural Computation},
	author = {Sun, Haoqi and Sourina, Olga and Huang, Guang-Bin},
	month = oct,
	year = {2016},
	note = {tex.eprint: https://direct.mit.edu/neco/article-pdf/28/10/2181/972099/neco{\textbackslash}\_a{\textbackslash}\_00879.pdf},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2181--2212},
	annote = {tex.eprint: https://direct.mit.edu/neco/article-pdf/28/10/2181/972099/neco{\textbackslash}\_a{\textbackslash}\_00879.pdf},
	annote = {tex.eprint: https://direct.mit.edu/neco/article-pdf/28/10/2181/972099/neco{\textbackslash}\_a{\textbackslash}\_00879.pdf},
	file = {sun2016.pdf:/Users/laurentperrinet/Zotero/storage/8L3AKDIQ/sun2016.pdf:application/pdf},
}

@article{Dan1996,
	title = {Efficient coding of natural scenes in the lateral geniculate nucleus: experimental test of a computational theory},
	volume = {16},
	doi = {10/gdvnc7},
	number = {10},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Dan, Yang and Atick, Joseph J and Reid, R C},
	month = may,
	year = {1996},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {3351--3362},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/JFWMITSV/Dan et al. - 1996 - Efficient coding of natural scenes in the lateral .pdf:application/pdf},
}

@article{Boutin2020,
	title = {Effect of top-down connections in {Hierarchical} {Sparse} {Coding}},
	volume = {32},
	copyright = {All rights reserved},
	url = {https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/},
	doi = {10.1162/neco_a_01325},
	abstract = {Hierarchical Sparse Coding (HSC) is a powerful model to efficiently represent multi-dimensional, structured data such as images. The simplest solution to solve this computationally hard problem is to decompose it into independent layer-wise subproblems. However, neuroscientific evidence would suggest inter-connecting these subproblems as in the Predictive Coding (PC) theory, which adds top-down connections between consecutive layers. In this study, a new model called 2-Layers Sparse Predictive Coding (2L-SPC) is introduced to assess the impact of this inter-layer feedback connection. In particular, the 2L-SPC is compared with a Hierarchical Lasso (Hi-La) network made out of a sequence of independent Lasso layers. The 2L-SPC and the 2-layers Hi-La networks are trained on 4 different databases and with different sparsity parameters on each layer. First, we show that the overall prediction error generated by 2L-SPC is lower thanks to the feedback mechanism as it transfers prediction error between layers. Second, we demonstrate that the inference stage of the 2L-SPC is faster to converge than for the Hi-La model. Third, we show that the 2L-SPC also accelerates the learning process. Finally, the qualitative analysis of both models dictionaries, supported by their activation probability, show that the 2L-SPC features are more generic and informative.},
	number = {11},
	journal = {Neural Computation},
	author = {Boutin, Victor and Franciosini, Angelo and Ruffier, Franck and Perrinet, Laurent U},
	month = feb,
	year = {2020},
	note = {tex.ids= BoutinFranciosiniRuffierPerrinet20
tex.date-modified: 2020-11-03 09:59:57 +0100
tex.grants: doc-2-amu,phd-icn,mesocentre
tex.preprint: https://arxiv.org/abs/2002.00892
publisher: MIT Press},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, deep-learning, sparse coding},
	pages = {2279--2309},
	annote = {https://arxiv.org/abs/2002.00892},
}

@article{Perrinet2015b,
	title = {Edge co-occurrences can account for rapid categorization of natural versus animal images},
	volume = {5},
	doi = {10.1038/srep11400},
	journal = {Scientific reports},
	author = {Perrinet, Laurent U and Bednar, James A},
	year = {2015},
	note = {tex.ids= Perrinet2015, Perrinet2015d, PerrinetBednar15
tex.bdsk-url-2: https://doi.org/10.1038/srep11400
tex.date-added: 2020-03-27 10:11:37 +0100
tex.date-modified: 2020-03-27 10:11:44 +0100
tex.grants: anr-bala-v1
tex.preprint: https://hal-amu.archives-ouvertes.fr/hal-01202447
tex.url\_code: https://github.com/laurentperrinet/PerrinetBednar15
publisher: Nature Publishing Group
url: http://dx.doi.org/10.1038/srep11400},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, anr-trax, association field, assofield, bicv-sparse, Biologically Inspired Computer vision, perrinetbednar15, sanz12jnp, sparse coding, vacher14},
	pages = {11400},
	annote = {00000},
	annote = {In print},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/VPNSZ3H9/Perrinet, Bednar - 2015 - Edge co-occurrences can account for rapid categorization of natural versus animal images(2).pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/KS9X4TBD/Perrinet and Bednar - 2015 - Edge co-occurrences can account for rapid categori.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/W7396PD6/srep11400.html:text/html},
}

@article{Roelfsema2016,
	title = {Early visual cortex as a multiscale cognitive blackboard},
	volume = {2},
	doi = {10.1146/annurev-vision-111815-114443},
	journal = {Annual review of vision science},
	author = {Roelfsema, Pieter R and de Lange, Floris P},
	year = {2016},
	note = {Publisher: Annual Reviews},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {131--151},
	annote = {Publisher: Annual Reviews},
}

@techreport{Bellec2021,
	title = {Fitting summary statistics of neural data with a differentiable spiking network simulator},
	url = {http://arxiv.org/abs/2106.10064},
	abstract = {Fitting network models to neural activity is an important tool in neuroscience. A popular approach is to model a brain area with a probabilistic recurrent spiking network whose parameters maximize the likelihood of the recorded activity. Although this is widely used, we show that the resulting model does not produce realistic neural activity. To correct for this, we suggest to augment the log-likelihood with terms that measure the dissimilarity between simulated and recorded activity. This dissimilarity is defined via summary statistics commonly used in neuroscience and the optimization is efficient because it relies on back-propagation through the stochastically simulated spike trains. We analyze this method theoretically and show empirically that it generates more realistic activity statistics. We find that it improves upon other fitting algorithms for spiking network models like GLMs (Generalized Linear Models) which do not usually rely on back-propagation. This new fitting algorithm also enables the consideration of hidden neurons which is otherwise notoriously hard, and we show that it can be crucial when trying to infer the network connectivity from spike recordings.},
	urldate = {2022-01-06},
	author = {Bellec, Guillaume and Wang, Shuqi and Modirshanechi, Alireza and Brea, Johanni and Gerstner, Wulfram},
	month = nov,
	year = {2021},
	note = {00000
tex.ids= Bellec2021
arXiv: 2106.10064
rights: http://creativecommons.org/licenses/by/4.0/},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
}

@article{Celebrini1993,
	title = {Dynamics of orientation coding in area {V1} of the awake primate},
	volume = {10},
	issn = {1469-8714, 0952-5238},
	url = {https://www.cambridge.org/core/journals/visual-neuroscience/article/abs/dynamics-of-orientation-coding-in-area-v1-of-the-awake-primate/906FA662AD71B432EB6D4F10795A397A},
	doi = {10/dqt5cm},
	abstract = {To investigate the importance of feedback loops in visual information processing, we have analyzed the dynamic aspects of neuronal responses to oriented gratings in cortical area V1 of the awake primate. If recurrent feedback is important in generating orientation selectivity, the initial part of the neuronal response should be relatively poorly selective, and full orientation selectivity should only appear after a delay. Thus, by examining the dynamics of the neuronal responses it should be possible to assess the importance of feedback processes in the development of orientation selectivity. The results were base on a sample of 259 cells recorded in two monkeys, of which 89\% were visually responsive. Of these, approximately two-thirds were orientation selective. Response latency varied considerably between neurons, ranging from a minimum of 41 ms to over 150 ms, although most had latencies of 50–70 ms. Orientation tuning (defined as the bandwidth at half-height) ranged from 16 deg to over 90 deg, with a mean value of around 55 deg. By examining the selectivity of these different neurons by 10-ms time slices, starting at the onset of the neuronal response, we found that the orientation selectivity of virtually every neuron was fully developed at the very start of the neuronal response. Indeed, many neurons showed a marked tendency to respond at somewhat longer latencies to stimuli that were nonoptimally oriented, with the result that orientation selectivity was highest at the very start of the neuronal response. Furthermore, there was no evidence that the neurons with the shortest onset latencies were less selective. Such evidence is inconsistent with the hypothesis that recurrent intracortical feedback plays an important role in the generation of orientation selectivity. Instead, we suggest that orientation selectivity is primarily generated using feedforward mechanisms, including feedforward inhibition. Such a strategy has the advantage of allowing orientation to be computed rapidly, and avoids the initially poorly selective neuronal responses that characterize processing involving recurrent loops.},
	language = {en},
	number = {5},
	urldate = {2021-04-08},
	journal = {Visual Neuroscience},
	author = {Celebrini, Simona and Thorpe, Simon and Trotter, Yves and Imbert, Michel},
	month = sep,
	year = {1993},
	note = {00303
tex.ids= Celebrini1993
publisher: Cambridge University Press},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {811--825},
}

@article{Neftci2019a,
	title = {Surrogate {Gradient} {Learning} in {Spiking} {Neural} {Networks}: {Bringing} the {Power} of {Gradient}-{Based} {Optimization} to {Spiking} {Neural} {Networks}},
	volume = {36},
	issn = {1558-0792},
	shorttitle = {Surrogate {Gradient} {Learning} in {Spiking} {Neural} {Networks}},
	doi = {10.1109/msp.2019.2931595},
	abstract = {Spiking neural networks (SNNs) are nature's versatile solution to fault-tolerant, energy-efficient signal processing. To translate these benefits into hardware, a growing number of neuromorphic spiking NN processors have attempted to emulate biological NNs. These developments have created an imminent need for methods and tools that enable such systems to solve real-world signal processing problems. Like conventional NNs, SNNs can be trained on real, domain-specific data; however, their training requires the overcoming of a number of challenges linked to their binary and dynamical nature. This article elucidates step-by-step the problems typically encountered when training SNNs and guides the reader through the key concepts of synaptic plasticity and data-driven learning in the spiking setting. Accordingly, it gives an overview of existing approaches and provides an introduction to surrogate gradient (SG) methods, specifically, as a particularly flexible and efficient method to overcome the aforementioned challenges.},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Neftci, Emre O. and Mostafa, Hesham and Zenke, Friedemann},
	month = nov,
	year = {2019},
	note = {00000 
Conference Name: IEEE Signal Processing Magazine},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Spiking Neural Networks (SNN)},
	pages = {51--63},
}

@inproceedings{Sironi,
	title = {{HATS}: {Histograms} of {Averaged} {Time} {Surfaces} for {Robust} {Event}-based {Object} {Classiﬁcation}},
	doi = {10.1109/cvpr.2018.00186},
	abstract = {Event-based cameras have recently drawn the attention of the Computer Vision community thanks to their advantages in terms of high temporal resolution, low power consumption and high dynamic range, compared to traditional frame-based cameras. These properties make event-based cameras an ideal choice for autonomous vehicles, robot navigation or UAV vision, among others. However, the accuracy of event-based object classiﬁcation algorithms, which is of crucial importance for any reliable system working in real-world conditions, is still far behind their framebased counterparts. Two main reasons for this performance gap are: 1. The lack of effective low-level representations and architectures for event-based object classiﬁcation and 2. The absence of large real-world event-based datasets. In this paper we address both problems. First, we introduce a novel event-based feature representation together with a new machine learning architecture. Compared to previous approaches, we use local memory units to efﬁciently leverage past temporal information and build a robust eventbased representation. Second, we release the ﬁrst large real-world event-based dataset for object classiﬁcation. We compare our method to the state-of-the-art with extensive experiments, showing better classiﬁcation performance and real-time computation.},
	language = {en},
	author = {Sironi, Amos and Brambilla, Manuele and Bourdis, Nicolas and Lagorce, Xavier and Benosman, Ryad},
	note = {00000},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computer Vision and Pattern Recognition},
	pages = {10},
	annote = {Comment: Accepted for publication at CVPR2018. Dataset available at http://www.prophesee.ai/dataset-n-cars/},
	file = {Sironi et al. - 2018 - HATS Histograms of Averaged Time Surfaces for Rob.pdf:/Users/laurentperrinet/Zotero/storage/MKKILX4P/Sironi et al. - 2018 - HATS Histograms of Averaged Time Surfaces for Rob.pdf:application/pdf},
}

@article{Masquelier2009,
	title = {Competitive {STDP}-{Based} {Spike} {Pattern} {Learning}},
	volume = {21},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.2008.06-08-804},
	doi = {10/dds34f},
	language = {en},
	number = {5},
	urldate = {2018-09-10},
	journal = {Neural Computation},
	author = {Masquelier, Timothée and Guyonneau, Rudy and Thorpe, Simon J.},
	month = may,
	year = {2009},
	note = {00203},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {1259--1276},
	annote = {00203},
}

@article{Olshausen1996,
	title = {Emergence of simple-cell receptive field properties by learning a sparse code for natural images.},
	volume = {381},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/381607a0 http://www.ncbi.nlm.nih.gov/htbin-post/Entrez/query?db=m&form=6&dopt=r&uid=8637596 http://www.ncbi.nlm.nih.gov/pubmed/8637596 http://www.nature.com/doifinder/10.1038/381607a0},
	doi = {10/dvj4qz},
	abstract = {The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
	number = {6583},
	journal = {Nature},
	author = {Olshausen, Bruno A. and Field, David J.},
	year = {1996},
	pmid = {8637596},
	note = {00000 },
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Algorithms, anr-trax, bicv-sparse, Learning, Models, Models,Neurological; Neurons, Neurological, Neurons, Neurons: physiology, Ocular, Ocular: physiology, perrinetadamsfriston14, sparse\_coding, sparse\_hebbian\_learning, sparse\_spike\_coding, Vision, Visual Cortex, Visual Cortex: cytology, Visual Cortex: physiology},
	pages = {607--609},
}

@article{Perrinet2004a,
	title = {Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit},
	volume = {57},
	copyright = {All rights reserved},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231204000670},
	doi = {10.1016/j.neucom.2004.01.010},
	abstract = {In order to account for the rapidity of visual processing, we explore visual coding strategies using a one-pass feed-forward spiking neural network. We based our model on the work of Van Rullen and Thorpe Neural Comput. 13 (6) (2001) 1255, which constructs a retinal representation using an orthogonal wavelet transform. This strategy provides a spike code, thanks to a rank order coding scheme which offers an alternative to the classical spike frequency coding scheme. We extended this model to efficient representations in arbitrary linear generative models by implementing lateral interactions on top of this feed-forward model. This method uses a matching pursuit scheme-recursively detecting in the image the best match with the elements of a dictionary and then subtracting it-and which may similarly define a visual spike code. In particular, this transform could be used with large and arbitrary dictionaries, so that we may define an over-complete representation which may define an efficient sparse spike coding scheme in arbitrary multi-layered architectures. We show here extensions of this method of computing with spike events, introducing an adaptive scheme leading to the emergence of V1-like receptive fields and then a model of bottom-up saliency pursuit. ?? 2004 Elsevier B.V. All rights reserved.},
	number = {1-4},
	journal = {Neurocomputing},
	author = {Perrinet, Laurent and Samuelides, Manuel and Thorpe, Simon},
	month = mar,
	year = {2004},
	note = {tex.ids: Perrinet02sparse
tex.date-modified: 2019-02-25 10:34:26 +0100
tex.preprint: https://hal-amu.archives-ouvertes.fr/hal-00276638},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, association field, assofield, matching, matching pursuit, Natural images statistics, Parallel asynchronous processing, pursuit, sparse coding, Sparse coding, Ultra-rapid categorization, Vision, Wavelet Hansform},
	pages = {125--134},
	annote = {From Duplicate 1 ( Sparse spike coding in an asynchronous feed-forward multi-layer neural network using Matching Pursuit. - Perrinet, Laurent U.; Samuelides, Manuel; Thorpe, Simon J. ) Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann From Duplicate 2 ( Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit - Perrinet, Laurent; Samuelides, Manuel; Thorpe, Simon ) Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann From Duplicate 3 (Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit - Perrinet, Laurent; Samuelides, Manuel; Thorpe, Simon) From Duplicate 1 ( Sparse spike coding in an asynchronous feed-forward multi-layer neural network using Matching Pursuit. - Perrinet, Laurent U.; Samuelides, Manuel; Thorpe, Simon J. ) Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann From Duplicate 2 ( Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit - Perrinet, Laurent; Samuelides, Manuel; Thorpe, Simon ) Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann From Duplicate 2 (Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit - Perrinet, Laurent; Samuelides, Manuel; Thorpe, Simon) Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann},
	annote = {Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann},
	annote = {Special issue: New Aspects in Neurocomputing: 10th European Symposium on Artificial Neural Networks 2002 - Edited by T. Villmann},
}

@article{Stringer2019a,
	title = {High-dimensional geometry of population responses in visual cortex},
	volume = {571},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/s41586-019-1346-5},
	doi = {10/gf4cfj},
	language = {en},
	number = {7765},
	urldate = {2021-12-03},
	journal = {Nature},
	author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
	month = jul,
	year = {2019},
	note = {00203
tex.ids= Stringer2019a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {361--365},
	file = {Stringer et al. - 2019 - High-dimensional geometry of population responses .pdf:/Users/laurentperrinet/Zotero/storage/L8TAJ3F2/Stringer et al. - 2019 - High-dimensional geometry of population responses .pdf:application/pdf;Version acceptée:/Users/laurentperrinet/Zotero/storage/6URZK27D/Stringer et al. - 2019 - High-dimensional geometry of population responses .pdf:application/pdf},
}

@article{Fields2015,
	title = {A new mechanism of nervous system plasticity: activity-dependent myelination},
	volume = {16},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1471-0048},
	shorttitle = {A new mechanism of nervous system plasticity},
	url = {https://www.nature.com/articles/nrn4023},
	doi = {10/gg6ztz},
	abstract = {The precise timing of impulse transmission along axons is crucial for synaptic plasticity and brain oscillations, and is partly determined by myelin thickness. In this Opinion article, R. Douglas Fields discusses how electrical activity influences myelin thickness and thus conduction velocity and circuit properties.},
	language = {en},
	number = {12},
	urldate = {2021-01-07},
	journal = {Nature Reviews Neuroscience},
	author = {Fields, R. Douglas},
	month = dec,
	year = {2015},
	note = {Number: 12
Publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found, biology, delay-learning, myelination},
	pages = {756--767},
	annote = {Number: 12 Publisher: Nature Publishing Group},
	annote = {Number: 12 Publisher: Nature Publishing Group},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/ZU3T7YUR/nrn4023.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/9GMC8IZS/Fields - 2015 - A new mechanism of nervous system plasticity acti.pdf:application/pdf;Version acceptée:/Users/laurentperrinet/Zotero/storage/Q444VVRN/Fields - 2015 - A new mechanism of nervous system plasticity acti.pdf:application/pdf},
}

@article{Fields2020,
	title = {Myelin makes memories},
	volume = {23},
	issn = {1546-1726},
	doi = {10/ggt5bh},
	language = {eng},
	number = {4},
	journal = {Nature Neuroscience},
	author = {Fields, R. Douglas and Bukalo, Olena},
	month = apr,
	year = {2020},
	pmid = {32094969},
	note = {00000 },
	keywords = {⛔ No INSPIRE recid found, Animals, Memory, Memory Consolidation, Mice, Myelin Sheath},
	pages = {469--470},
}

@article{Haag2004,
	title = {Fly motion vision is based on {Reichardt} detectors regardless of the signal-to-noise ratio},
	volume = {101},
	issn = {0027-8424},
	doi = {10/d99ctc},
	abstract = {The computational structure of an optimal motion detector was proposed to depend on the signal-to-noise ratio (SNR) of the stimulus: At low SNR, the optimal motion detector should be a correlation or "Reichardt" type, whereas at high SNR, the detector would employ a gradient scheme [Potters, M. \& Bialek, W. (1994) J. Physiol. (Paris) 4, 1755-1775]. Although a large body of experiments supports the Reichardt detector as the processing scheme leading to direction selectivity in fly motion vision, in most of these studies the SNR was rather low. We therefore reinvestigated the question over a much larger SNR range. Using 2-photon microscopy, we found that local dendritic [Ca(2+)] modulations, which are characteristic of Reichardt detectors, occur in response to drifting gratings over a wide range of luminance levels and contrasts. We also explored, as another fingerprint of Reichardt detectors, the dependence of the velocity optimum on the pattern wavelength. Again, we found Reichardt-typical behavior throughout the whole luminance and contrast range tested. Our results, therefore, provide strong evidence that only a single elementary processing scheme is used in fly motion vision.},
	language = {eng},
	number = {46},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Haag, J. and Denk, W. and Borst, A.},
	month = nov,
	year = {2004},
	pmid = {15534201},
	pmcid = {PMC526200},
	note = {00164 },
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Algorithms, Animals, biology, Calcium Signaling, delay-learning, Diptera, Electrophysiology, Female, insects, Models, Models, Neurological, Motion, Motion Perception, Neurological, Ocular, Optics and Photonics, Photic Stimulation, Vision, Vision, Ocular},
	pages = {16333--16338},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/QHMSC77H/Haag et al. - 2004 - Fly motion vision is based on Reichardt detectors .pdf:application/pdf},
}

@article{Wang2019,
	title = {A {Delay} {Learning} {Algorithm} {Based} on {Spike} {Train} {Kernels} for {Spiking} {Neurons}},
	volume = {13},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2019.00252/full},
	doi = {10/ghsm4z},
	abstract = {Neuroscience research conﬁrms that the synaptic delays are not constant, but can be modulated. This paper proposes a supervised delay learning algorithm for spiking neurons with temporal encoding, in which both the weight and delay of a synaptic connection can be adjusted to enhance the learning performance. The proposed algorithm ﬁrstly deﬁnes spike train kernels to transform discrete spike trains during the learning phase into continuous analog signals so that common mathematical operations can be performed on them, and then deduces the supervised learning rules of synaptic weights and delays by gradient descent method. The proposed algorithm is successfully applied to various spike train learning tasks, and the effects of parameters of synaptic delays are analyzed in detail. Experimental results show that the network with dynamic delays achieves higher learning accuracy and less learning epochs than the network with static delays. The delay learning algorithm is further validated on a practical example of an image classiﬁcation problem. The results again show that it can achieve a good classiﬁcation performance with a proper receptive ﬁeld. Therefore, the synaptic delay learning is signiﬁcant for practical applications and theoretical researches of spiking neural networks.},
	language = {en},
	urldate = {2020-12-17},
	journal = {Frontiers in Neuroscience},
	author = {Wang, Xiangwen and Lin, Xianghong and Dang, Xiaochao},
	month = mar,
	year = {2019},
	note = {00012
tex.ids= Wang19b, Wang2019
publisher: Frontiers},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	pages = {252},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/8TCSC59U/Wang et al. - 2019 - A Delay Learning Algorithm Based on Spike Train Ke.pdf:application/pdf;Wang et al. - 2019 - A Delay Learning Algorithm Based on Spike Train Ke.pdf:/Users/laurentperrinet/Zotero/storage/PAAWV6G4/Wang et al. - 2019 - A Delay Learning Algorithm Based on Spike Train Ke.pdf:application/pdf},
}

@article{Pena2001,
	title = {Cochlear and {Neural} {Delays} for {Coincidence} {Detection} in {Owls}},
	volume = {21},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6763915/},
	doi = {10/ghsm42},
	abstract = {The auditory system uses delay lines and coincidence detection to measure the interaural time difference (ITD). Both axons and the cochlea could provide such delays. The stereausis theory assumes that differences in wave propagation time along the basilar membrane can provide the necessary delays, if the coincidence detectors receive input from fibers innervating different loci on the left and right basilar membranes. If this hypothesis were true, the left and right inputs to coincidence detectors should differ in their frequency tuning. The owl's nucleus laminaris contains coincidence detector neurons that receive input from the left and right cochlear nuclei. Monaural frequency-tuning curves of nucleus laminaris neurons showed small interaural differences. In addition, their preferred ITDs were not correlated with the interaural frequency mismatches. Instead, the preferred ITD of the neuron agrees with that predicted from the distribution of axonal delays. Thus, there is no need to invoke mechanisms other than neural delays to explain the detection of ITDs by the barn owl's laminaris neurons.},
	number = {23},
	urldate = {2021-01-07},
	journal = {The Journal of Neuroscience},
	author = {Peña, José Luis and Viete, Svenja and Funabiki, Kazuo and Saberi, Kourosh and Konishi, Masakazu},
	month = dec,
	year = {2001},
	pmid = {11717379},
	pmcid = {PMC6763915},
	note = {00000 },
	keywords = {⛔ No INSPIRE recid found, biology, delay-learning},
	pages = {9455--9459},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/GXA47KLI/Peña et al. - 2001 - Cochlear and Neural Delays for Coincidence Detecti.pdf:application/pdf},
}

@article{Paredes-Valles2020,
	title = {Unsupervised {Learning} of a {Hierarchical} {Spiking} {Neural} {Network} for {Optical} {Flow} {Estimation}: {From} {Events} to {Global} {Motion} {Perception}},
	volume = {42},
	issn = {1939-3539},
	shorttitle = {Unsupervised {Learning} of a {Hierarchical} {Spiking} {Neural} {Network} for {Optical} {Flow} {Estimation}},
	doi = {10/ggcx69},
	abstract = {The combination of spiking neural networks and event-based vision sensors holds the potential of highly efficient and high-bandwidth optical flow estimation. This paper presents the first hierarchical spiking architecture in which motion (direction and speed) selectivity emerges in an unsupervised fashion from the raw stimuli generated with an event-based camera. A novel adaptive neuron model and stable spike-timing-dependent plasticity formulation are at the core of this neural network governing its spike-based processing and learning, respectively. After convergence, the neural architecture exhibits the main properties of biological visual motion systems, namely feature extraction and local and global motion perception. Convolutional layers with input synapses characterized by single and multiple transmission delays are employed for feature and local motion perception, respectively; while global motion selectivity emerges in a final fully-connected layer. The proposed solution is validated using synthetic and real event sequences. Along with this paper, we provide the cuSNN library, a framework that enables GPU-accelerated simulations of large-scale spiking neural networks. Source code and samples are available at https://github.com/tudelft/cuSNN.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Paredes-Vallés, Federico and Scheper, Kirk Y. W. and de Croon, Guido C. H. E.},
	month = aug,
	year = {2020},
	note = {00000 
Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Biological information theory, Biological system modeling, Biomedical optical imaging, Event-based vision, feature extraction, motion detection, neural nets, neuromorphic computing, Neurons, Optical sensors, unsupervised learning, Vision sensors, Visualization},
	pages = {2051--2064},
	annote = {00047 Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/NFKSEPV6/8660483.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/7GW6CN3D/Paredes-Vallés et al. - 2020 - Unsupervised Learning of a Hierarchical Spiking Ne.pdf:application/pdf},
}

@article{Russo2017,
	title = {Cell assemblies at multiple time scales with arbitrary lag constellations},
	volume = {6},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.19428},
	doi = {10/f9kxd8},
	abstract = {Hebb's idea of a cell assembly as the fundamental unit of neural information processing has dominated neuroscience like no other theoretical concept within the past 60 years. A range of different physiological phenomena, from precisely synchronized spiking to broadly simultaneous rate increases, has been subsumed under this term. Yet progress in this area is hampered by the lack of statistical tools that would enable to extract assemblies with arbitrary constellations of time lags, and at multiple temporal scales, partly due to the severe computational burden. Here we present such a unifying methodological and conceptual framework which detects assembly structure at many different time scales, levels of precision, and with arbitrary internal organization. Applying this methodology to multiple single unit recordings from various cortical areas, we find that there is no universal cortical coding scheme, but that assembly structure and precision significantly depends on the brain area recorded and ongoing task demands.},
	urldate = {2021-12-06},
	journal = {eLife},
	author = {Russo, Eleonora and Durstewitz, Daniel},
	editor = {Howard, Marc},
	month = jan,
	year = {2017},
	note = {tex.ids= Russo2017
publisher: eLife Sciences Publications, Ltd},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e19428},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/5MXSW8ZN/Russo and Durstewitz - 2017 - Cell assemblies at multiple time scales with arbit.pdf:application/pdf},
}

@article{Grossberger2018,
	title = {Unsupervised clustering of temporal patterns in high-dimensional neuronal ensembles using a novel dissimilarity measure},
	volume = {14},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006283},
	doi = {10/gdvbsx},
	abstract = {Temporally ordered multi-neuron patterns likely encode information in the brain. We introduce an unsupervised method, SPOTDisClust (Spike Pattern Optimal Transport Dissimilarity Clustering), for their detection from high-dimensional neural ensembles. SPOTDisClust measures similarity between two ensemble spike patterns by determining the minimum transport cost of transforming their corresponding normalized cross-correlation matrices into each other (SPOTDis). Then, it performs density-based clustering based on the resulting inter-pattern dissimilarity matrix. SPOTDisClust does not require binning and can detect complex patterns (beyond sequential activation) even when high levels of out-of-pattern “noise” spiking are present. Our method handles efficiently the additional information from increasingly large neuronal ensembles and can detect a number of patterns that far exceeds the number of recorded neurons. In an application to neural ensemble data from macaque monkey V1 cortex, SPOTDisClust can identify different moving stimulus directions on the sole basis of temporal spiking patterns.},
	language = {en},
	number = {7},
	urldate = {2021-11-30},
	journal = {PLOS Computational Biology},
	author = {Grossberger, Lukas and Battaglia, Francesco P. and Vinck, Martin},
	year = {2018},
	note = {00000
tex.ids= Grossberger18a
publisher: Public Library of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1006283},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/VJRPYW9K/Grossberger et al. - 2018 - Unsupervised clustering of temporal patterns in hi.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/LZY6YRVF/Grossberger et al. - 2018 - Unsupervised clustering of temporal patterns in hi.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/WU2S4DNR/article.html:text/html;Snapshot:/Users/laurentperrinet/Zotero/storage/IF6H52VP/article.html:text/html},
}

@article{Zenke2021,
	title = {The {Remarkable} {Robustness} of {Surrogate} {Gradient} {Learning} for {Instilling} {Complex} {Function} in {Spiking} {Neural} {Networks}},
	volume = {33},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco_a_01367},
	doi = {10/gkhq76},
	abstract = {Brains process information in spiking neural networks. Their intricate connections shape the diverse functions these networks perform. Yet how network connectivity relates to function is poorly understood, and the functional capabilities of models of spiking networks are still rudimentary. The lack of both theoretical insight and practical algorithms to find the necessary connectivity poses a major impediment to both studying information processing in the brain and building efficient neuromorphic hardware systems. The training algorithms that solve this problem for artificial neural networks typically rely on gradient descent. But doing so in spiking networks has remained challenging due to the nondifferentiable nonlinearity of spikes. To avoid this issue, one can employ surrogate gradients to discover the required connectivity. However, the choice of a surrogate is not unique, raising the question of how its implementation influences the effectiveness of the method. Here, we use numerical simulations to systematically study how essential design parameters of surrogate gradients affect learning performance on a range of classification problems. We show that surrogate gradient learning is robust to different shapes of underlying surrogate derivatives, but the choice of the derivative's scale can substantially affect learning performance. When we combine surrogate gradients with suitable activity regularization techniques, spiking networks perform robust information processing at the sparse activity limit. Our study provides a systematic account of the remarkable robustness of surrogate gradient learning and serves as a practical guide to model functional spiking neural networks.},
	number = {4},
	urldate = {2021-12-02},
	journal = {Neural Computation},
	author = {Zenke, Friedemann and Vogels, Tim P.},
	month = mar,
	year = {2021},
	note = {00035
tex.ids= Zenke2021b},
	keywords = {⛔ No INSPIRE recid found},
	pages = {899--925},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/VQJQZ3R5/Zenke and Vogels - 2021 - The Remarkable Robustness of Surrogate Gradient Le.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/7VFXP6W4/Zenke and Vogels - 2021 - The Remarkable Robustness of Surrogate Gradient Le.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/RVN3EW52/The-Remarkable-Robustness-of-Surrogate-Gradient.html:text/html},
}

@article{Clady2014,
	title = {Asynchronous visual event-based time-to-contact},
	volume = {8},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2014.00009/full},
	doi = {10.3389/fnins.2014.00009},
	abstract = {A reliable and fast sensing of the environment is a fundamental necessity of mobile platforms. Unfortunately conventional cameras due to the current frame-based acquisition paradigm output low temporal dynamics and redundant data flow leading to high computational costs. It is obviously incompatible with the necessities of mobile platforms where energy consumption and computational load are a major issue. The restrictions of the frame-based paradigm are contradictory with applications requiring high speed sensor-based reactive control. This paper introduces a fast obstacle avoidance using the output of an asynchronous event-based time encoded imaging sensor. The approach is event-based in the sense that every incoming event adds to the computation process thus allowing fast avoidance responses. It introduces an event-based time-to-contact approach relying on the computation of visual event-based motion flows. Experiments on a mobile robot are presented in an indoor environment. Time to contact results are compared with those provided by a laser range finder showing that event-based sensing offers new perspectives for mobile robotics sensing.},
	language = {English},
	urldate = {2020-11-04},
	journal = {Frontiers in Neuroscience},
	author = {Clady, Xavier and Clercq, Charles and Ieng, Sio-Hoi and Houseini, Fouzhan and Randazzo, Marco and Natale, Lorenzo and Bartolozzi, Chiara and Benosman, Ryad Benjamin},
	year = {2014},
	note = {00000 
Publisher: Frontiers},
	keywords = {⛔ No INSPIRE recid found, Computer Vision, Event-based Computation, Neuromorphic vision, Robotics, time-to-contact},
	annote = {00000 Publisher: Frontiers},
	annote = {00000 Publisher: Frontiers},
	file = {2020-10-06-APROVIS-MIDI-JC.pdf:/Users/laurentperrinet/Zotero/storage/LKIWTS9Q/2020-10-06-APROVIS-MIDI-JC.pdf:application/pdf;2020-10-06-APROVIS-MIDI-JC.pdf:/Users/laurentperrinet/Zotero/storage/FG84N3ST/2020-10-06-APROVIS-MIDI-JC.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/WR2SI6TX/Clady et al. - 2014 - Asynchronous visual event-based time-to-contact.pdf:application/pdf},
}

@article{Maass1997,
	title = {Networks of spiking neurons: {The} third generation of neural network models},
	volume = {10},
	issn = {08936080},
	shorttitle = {Networks of spiking neurons},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608097000117},
	doi = {10.1016/s0893-6080(97)00011-7},
	abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology. © 1997 Elsevier Science Ltd. All rights reserved.},
	language = {en},
	number = {9},
	urldate = {2020-07-06},
	journal = {Neural Networks},
	author = {Maass, Wolfgang},
	month = dec,
	year = {1997},
	note = {01735
tex.ids= Maass1997},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1659--1671},
	file = {Maass - 1997 - Networks of spiking neurons The third generation .pdf:/Users/laurentperrinet/Zotero/storage/BFEMTCG3/Maass - 1997 - Networks of spiking neurons The third generation .pdf:application/pdf},
}

@article{Zenke2021a,
	title = {Visualizing a joint future of neuroscience and neuromorphic engineering},
	volume = {109},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S089662732100009X},
	doi = {10.1016/j.neuron.2021.01.009},
	abstract = {Recent research resolves the challenging problem of building biophysically plausible spiking neural models that are also capable of complex information processing. This advance creates new opportunities in neuroscience and neuromorphic engineering, which we discussed at an online focus meeting.},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {Neuron},
	author = {Zenke, Friedemann and Bohté, Sander M. and Clopath, Claudia and Comşa, Iulia M. and Göltz, Julian and Maass, Wolfgang and Masquelier, Timothée and Naud, Richard and Neftci, Emre O. and Petrovici, Mihai A. and Scherr, Franz and Goodman, Dan F. M.},
	month = feb,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {571--575},
	file = {ScienceDirect Full Text PDF:/Users/laurentperrinet/Zotero/storage/EZM4HI88/Zenke et al. - 2021 - Visualizing a joint future of neuroscience and neu.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/laurentperrinet/Zotero/storage/3U5KDT8L/Zenke et al. - 2021 - Visualizing a joint future of neuroscience and neu.pdf:application/pdf;ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/XRJRTINL/S089662732100009X.html:text/html;ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/LJ6FTIN8/S089662732100009X.html:text/html},
}

@article{Perrinet2004e,
	title = {Feature detection using spikes: the greedy approach},
	volume = {98},
	copyright = {All rights reserved},
	issn = {0928-4257},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16310348 http://arxiv.org/abs/q-bio/0611003 http://linkinghub.elsevier.com/retrieve/pii/S0928425705000161},
	doi = {10.1016/j.jphysparis.2005.09.012},
	abstract = {A goal of low-level neural processes is to build an efficient code extracting the relevant information from the sensory input. It is believed that this is implemented in cortical areas by elementary inferential computations dynamically extracting the most likely parameters corresponding to the sensory signal. We explore here a neuro-mimetic feed-forward model of the primary visual area (VI) solving this problem in the case where the signal may be described by a robust linear generative model. This model uses an over-complete dictionary of primitives which provides a distributed probabilistic representation of input features. Relying on an efficiency criterion, we derive an algorithm as an approximate solution which uses incremental greedy inference processes. This algorithm is similar to 'Matching Pursuit' and mimics the parallel architecture of neural computations. We propose here a simple implementation using a network of spiking integrate-and-fire neurons which communicate using lateral interactions. Numerical simulations show that this Sparse Spike Coding strategy provides an efficient model for representing visual data from a set of natural images. Even though it is simplistic, this transformation of spatial data into a spatio-temporal pattern of binary events provides an accurate description of some complex neural patterns observed in the spiking activity of biological neural networks.},
	number = {4-6},
	journal = {Journal of Physiology-Paris},
	author = {Perrinet, Laurent},
	year = {2004},
	pmid = {16310348},
	note = {tex.ids: Perrinet04tauc
tex.date-modified: 2019-02-26 12:31:12 +0100
tex.preprint: https://arxiv.org/abs/q-bio/0611003},
	keywords = {⛔ No INSPIRE recid found, Action potentials, afferent, Afferent, afferent cytology, afferent physiology, Afferent: cytology, Afferent: physiology, algorithms, Algorithms, Bayesian model, biological, Biological, cell communication, Cell Communication, cell communication physiology, Cell Communication: physiology, coding decoding, computer simulation, Computer Simulation, Distributed probabilistic representation, humans, Humans, Inverse linear model, linear models, Linear Models, matching pursuit, Matching pursuit, mathematics, Mathematics, models, Models, neural networks (computer), Neural Networks (Computer), neurological, Neurological, Neuronal representation, neurons, Neurons, Over-complete dictionaries, signal transduction, Signal Transduction, signal transduction physiology, Signal Transduction: physiology, sparse coding, sparse hebbian learning, Sparse spike coding, spike, Spike-event computation, statistical, Statistical, visual cortex, Visual Cortex, visual cortex physiology, Visual Cortex: physiology, visual perception, Visual Perception, visual perception physiology, Visual Perception: physiology},
	pages = {530--539},
	annote = {From Duplicate 1 (Feature detection using spikes: the greedy approach - Perrinet, Laurent) (special issue) From Duplicate 2 (Feature detection using spikes: The greedy approach - Perrinet, Laurent) From Duplicate 1 (Feature detection using spikes: the greedy approach - Perrinet, Laurent) From Duplicate 2 ( Feature detection using spikes: the greedy approach - Perrinet, Laurent ) (special issue) From Duplicate 3 (Feature detection using spikes: The greedy approach - Perrinet, Laurent) From Duplicate 1 (Feature detection using spikes: the greedy approach - Perrinet, Laurent) From Duplicate 2 ( Feature detection using spikes: the greedy approach - Perrinet, Laurent ) (special issue)},
	annote = {From Duplicate 1 (Feature detection using spikes: the greedy approach - Perrinet, Laurent) (special issue) From Duplicate 2 (Feature detection using spikes: The greedy approach - Perrinet, Laurent) From Duplicate 1 (Feature detection using spikes: the greedy approach - Perrinet, Laurent) From Duplicate 2 ( Feature detection using spikes: the greedy approach - Perrinet, Laurent ) (special issue) From Duplicate 3 (Feature detection using spikes: The greedy approach - Perrinet, Laurent) From Duplicate 1 (Feature detection using spikes: the greedy approach - Perrinet, Laurent) From Duplicate 2 ( Feature detection using spikes: the greedy approach - Perrinet, Laurent ) (special issue)},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/SCCZJCPH/Perrinet - 2004 - Feature detection using spikes the greedy approach(2).pdf:application/pdf},
}

@article{Stimberg2019,
	title = {Brian 2: an intuitive and efficient neural simulator},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {Brian 2},
	url = {https://www.biorxiv.org/content/10.1101/595710v1},
	doi = {10/gfxr2x},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}To be maximally useful for neuroscience research, neural simulators must make it possible to define original models. This is especially important because a computational experiment might not only need descriptions of neurons and synapses, but also models of interactions with the environment (e.g. muscles), or the environment itself. To preserve high performance when defining new models, current simulators offer two options: low-level programming, or mark-up languages (and other domain specific languages). The first option requires time and expertise, is prone to errors, and contributes to problems with reproducibility and replicability. The second option has limited scope, since it can only describe the range of neural models covered by the ontology. Other aspects of a computational experiment, such as the stimulation protocol, cannot be expressed within this framework. “Brian” 2 is a complete rewrite of Brian that addresses this issue by using runtime code generation with a procedural equation-oriented approach. Brian 2 enables scientists to write code that is particularly simple and concise, closely matching the way they conceptualise their models, while the technique of runtime code generation automatically transforms high level descriptions of models into efficient low level code tailored to different hardware (e.g. CPU or GPU). We illustrate it with several challenging examples: a plastic model of the pyloric network of crustaceans, a closed-loop sensorimotor model, programmatic exploration of a neuron model, and an auditory model with real-time input from a microphone.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-05-16},
	journal = {bioRxiv},
	author = {Stimberg, Marcel and Brette, Romain and Goodman, Dan F. M.},
	month = apr,
	year = {2019},
	note = {00000},
	keywords = {⛔ No INSPIRE recid found},
	pages = {595710},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/TU64KGHA/Stimberg et al. - 2019 - Brian 2 an intuitive and efficient neural simulat.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/YHY9PTHQ/595710v1.html:text/html;Stimberg et al. - 2019 - Brian 2, an intuitive and efficient neural simulat.pdf:/Users/laurentperrinet/Zotero/storage/FTPPPI8X/Stimberg et al. - 2019 - Brian 2, an intuitive and efficient neural simulat.pdf:application/pdf},
}

@article{Goodman2010,
	title = {Spike-timing-based computation in sound localization.},
	volume = {6},
	issn = {1553-7358},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2978676/},
	doi = {10.1371/journal.pcbi.1000993},
	abstract = {Spike timing is precise in the auditory system and it has been argued that it conveys information about auditory stimuli, in particular about the location of a sound source. However, beyond simple time differences, the way in which neurons might extract this information is unclear and the potential computational advantages are unknown. The computational difficulty of this task for an animal is to locate the source of an unexpected sound from two monaural signals that are highly dependent on the unknown source signal. In neuron models consisting of spectro-temporal filtering and spiking nonlinearity, we found that the binaural structure induced by spatialized sounds is mapped to synchrony patterns that depend on source location rather than on source signal. Location-specific synchrony patterns would then result in the activation of location-specific assemblies of postsynaptic neurons. We designed a spiking neuron model which exploited this principle to locate a variety of sound sources in a virtual acoustic environment using measured human head-related transfer functions. The model was able to accurately estimate the location of previously unknown sounds in both azimuth and elevation (including front/back discrimination) in a known acoustic environment. We found that multiple representations of different acoustic environments could coexist as sets of overlapping neural assemblies which could be associated with spatial locations by Hebbian learning. The model demonstrates the computational relevance of relative spike timing to extract spatial information about sources independently of the source signal.},
	number = {11},
	journal = {PLoS Comput Biol},
	author = {Goodman, Dan F. M. and Brette, Romain},
	month = nov,
	year = {2010},
	pmid = {21085681},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, auditory\_stimuli, auditory\_system, neural\_assemblies, sound\_localization, spatial\_information, spike, spike\_timing, spikes, synchrony},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/BLEHRGVV/Goodman and Brette - 2010 - Spike-timing-based computation in sound localizati.pdf:application/pdf},
}

@article{Perrinet2004b,
	title = {Emergence of filters from natural scenes in a sparse spike coding scheme},
	volume = {58-60},
	copyright = {All rights reserved},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231204001389},
	doi = {10.1016/j.neucom.2004.01.133},
	abstract = {As an alternative to classical representations in machine learning algorithms, we explore coding strategies using events as is observed for spiking neurons in the central nervous system. Focusing on visual processing, we have previously shown that we may define a sparse spike coding scheme by implementing accordingly lateral interactions (Neurocomputing 57 (2004) 125). This class of algorithms is both compatible with biological constraints and also to neurophysiological observations and yields a performant algorithm of computing by events. We explore here learning mechanisms to unsupervisely derive an optimal overcomplete set of filters based on previous work of (Vision Res. 37 (1998) 3311) and show its biological relevance. © 2004 Elsevier B.V. All rights reserved.},
	number = {C},
	journal = {Neurocomputing},
	author = {Perrinet, Laurent},
	year = {2004},
	note = {tex.ids: Perrinet03
tex.date-modified: 2019-02-22 11:55:28 +0100},
	keywords = {⛔ No INSPIRE recid found, area-v1, receptive field, receptive\_field, sparse coding, Sparse spike coding, sparse\_coding, Unsupervised learning, Vision},
	pages = {821--826},
	annote = {From Duplicate 1 (Emergence of filters from natural scenes in a sparse spike coding scheme - Perrinet, Laurent) From Duplicate 1 (Emergence of filters from natural scenes in a sparse spike coding scheme. - Perrinet, Laurent U; Samuelides, Manuel; Thorpe, Simon J) Special issue: Computational Neuroscience: Trends in Research 2004 - Edited by E. De Schutter From Duplicate 2 (Emergence of filters from natural scenes in a sparse spike coding scheme - Perrinet, Laurent) Special issue: Computational Neuroscience: Trends in Research 2004 - Edited by E. De Schutter},
	annote = {Special issue: Computational Neuroscience: Trends in Research 2004 - Edited by E. De Schutter},
	annote = {Special issue: Computational Neuroscience: Trends in Research 2004 - Edited by E. De Schutter},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/HTDBU9EG/Perrinet - 2004 - Emergence of filters from natural scenes in a sparse spike coding scheme.pdf:application/pdf},
}

@article{Hogendoorn2019,
	title = {Predictive {Coding} with {Neural} {Transmission} {Delays}: {A} {Real}-{Time} {Temporal} {Alignment} {Hypothesis}},
	volume = {6},
	issn = {2373-2822},
	shorttitle = {Predictive {Coding} with {Neural} {Transmission} {Delays}},
	url = {http://eneuro.org/lookup/doi/10.1523/ENEURO.0412-18.2019},
	doi = {10/ggcrbj},
	language = {en},
	number = {2},
	urldate = {2019-11-12},
	journal = {eneuro},
	author = {Hogendoorn, Hinze and Burkitt, Anthony N.},
	month = mar,
	year = {2019},
	note = {00002
tex.ids= Hogendoorn2019a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {ENEURO.0412--18.2019},
	file = {Hogendoorn and Burkitt - 2019 - Predictive Coding with Neural Transmission Delays.pdf:/Users/laurentperrinet/Zotero/storage/LZCY4XTA/Hogendoorn and Burkitt - 2019 - Predictive Coding with Neural Transmission Delays.pdf:application/pdf},
}

@article{Brunel2000,
	title = {Phase diagrams of sparsely connected networks of excitatory and inhibitory spiking neurons},
	volume = {32-33},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S092523120000179X},
	doi = {10/ftsf35},
	language = {en},
	urldate = {2019-01-14},
	journal = {Neurocomputing},
	author = {Brunel, Nicolas},
	year = {2000},
	note = {00009},
	keywords = {⛔ No INSPIRE recid found, Integrate-and-fire neuron, Neural network, Oscillations, Synchrony},
	pages = {307--312},
	annote = {00009},
}

@article{Engbert2011,
	title = {An integrated model of fixational eye movements and microsaccades},
	volume = {108},
	copyright = {©  . Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/108/39/E765},
	doi = {10/brk38r},
	abstract = {When we fixate a stationary target, our eyes generate miniature (or fixational) eye movements involuntarily. These fixational eye movements are classified as slow components (physiological drift, tremor) and microsaccades, which represent rapid, small-amplitude movements. Here we propose an integrated mathematical model for the generation of slow fixational eye movements and microsaccades. The model is based on the concept of self-avoiding random walks in a potential, a process driven by a self-generated activation field. The self-avoiding walk generates persistent movements on a short timescale, whereas, on a longer timescale, the potential produces antipersistent motions that keep the eye close to an intended fixation position. We introduce microsaccades as fast movements triggered by critical activation values. As a consequence, both slow movements and microsaccades follow the same law of motion; i.e., movements are driven by the self-generated activation field. Thus, the model contributes a unified explanation of why it has been a long-standing problem to separate slow movements and microsaccades with respect to their motion-generating principles. We conclude that the concept of a self-avoiding random walk captures fundamental properties of fixational eye movements and provides a coherent theoretical framework for two physiologically distinct movement types.},
	language = {en},
	number = {39},
	urldate = {2021-02-18},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Engbert, Ralf and Mergenthaler, Konstantin and Sinn, Petra and Pikovsky, Arkady},
	month = sep,
	year = {2011},
	pmid = {21873243},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {⛔ No INSPIRE recid found},
	pages = {E765--E770},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/FFFS8ZAU/Engbert et al. - 2011 - An integrated model of fixational eye movements an.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/R7X8KVVE/E765.html:text/html},
}

@article{Boerlin2011,
	title = {Spike-{Based} {Population} {Coding} and {Working} {Memory}},
	volume = {7},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1001080},
	doi = {10/fqbmkg},
	abstract = {Compelling behavioral evidence suggests that humans can make optimal decisions despite the uncertainty inherent in perceptual or motor tasks. A key question in neuroscience is how populations of spiking neurons can implement such probabilistic computations. In this article, we develop a comprehensive framework for optimal, spike-based sensory integration and working memory in a dynamic environment. We propose that probability distributions are inferred spike-per-spike in recurrently connected networks of integrate-and-fire neurons. As a result, these networks can combine sensory cues optimally, track the state of a time-varying stimulus and memorize accumulated evidence over periods much longer than the time constant of single neurons. Importantly, we propose that population responses and persistent working memory states represent entire probability distributions and not only single stimulus values. These memories are reflected by sustained, asynchronous patterns of activity which make relevant information available to downstream neurons within their short time window of integration. Model neurons act as predictive encoders, only firing spikes which account for new information that has not yet been signaled. Thus, spike times signal deterministically a prediction error, contrary to rate codes in which spike times are considered to be random samples of an underlying firing rate. As a consequence of this coding scheme, a multitude of spike patterns can reliably encode the same information. This results in weakly correlated, Poisson-like spike trains that are sensitive to initial conditions but robust to even high levels of external neural noise. This spike train variability reproduces the one observed in cortical sensory spike trains, but cannot be equated to noise. On the contrary, it is a consequence of optimal spike-based inference. In contrast, we show that rate-based models perform poorly when implemented with stochastically spiking neurons.},
	language = {en},
	number = {2},
	urldate = {2018-12-02},
	journal = {PLOS Computational Biology},
	author = {Boerlin, Martin and Denève, Sophie},
	month = feb,
	year = {2011},
	note = {00085},
	keywords = {⛔ No INSPIRE recid found, Action potentials, Memory, Neural networks, Neuronal tuning, Neurons, Sensory cues, Sensory perception, Working memory},
	pages = {e1001080},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/QREDG7MC/Boerlin and Denève - 2011 - Spike-Based Population Coding and Working Memory.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/RX2LYT86/Boerlin and Denève - 2011 - Spike-Based Population Coding and Working Memory.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/7WUD55L2/article.html:text/html},
}

@article{Perrinet2002,
	title = {Coherence detection in a spiking neuron via {Hebbian} learning},
	volume = {44-46},
	copyright = {All rights reserved},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231202003740 http://linkinghub.elsevier.com/retrieve/pii/S0925-2312(02)00374-0},
	doi = {10/fsk9mk},
	abstract = {It is generally assumed that neurons in the central nervous system communicate through temporal firing patterns. As a first step, we will study the learning of a layer of realistic neurons in the particular case where the relevant messages are formed by temporally cor- related patterns, or synfire patterns. The model is a layer of Integrate-and-Fire (IF) neurons with synaptic current dynamics that adapts by minimizing a cost according to a gradient descent scheme. This leads to a rule similar to Spike-Time Dependent Hebbian Plasticity (STDHP). Our results show that the rule that we derive is biologically plausible and leads to the detection of the coherence in the input in an unsupervised way. An application to shape recognition is shown as an illustration.},
	number = {C},
	journal = {Neurocomputing},
	author = {Perrinet, L.},
	year = {2002},
	note = {tex.ids= Perrinet02stdp, Perrinet2002b
tex.date-modified: 2020-01-07 12:51:03 +0100},
	keywords = {⛔ No INSPIRE recid found, coding decoding, Hebb Rule, Kinetic model, Rank Order Coding, rank-order-coding, sparse hebbian learning, spike, Spiking Neural Networks (SNN), STDP},
	pages = {133--139},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/KZA24DE3/Perrinet - 2002 - Coherence detection in a spiking neuron via Hebbian learning(3).pdf:application/pdf},
}

@article{Masquelier2007,
	title = {Unsupervised {Learning} of {Visual} {Features} through {Spike} {Timing} {Dependent} {Plasticity}},
	volume = {3},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030031},
	doi = {10/cjkr36},
	abstract = {Spike timing dependent plasticity (STDP) is a learning rule that modifies synaptic strength as a function of the relative timing of pre- and postsynaptic spikes. When a neuron is repeatedly presented with similar inputs, STDP is known to have the effect of concentrating high synaptic weights on afferents that systematically fire early, while postsynaptic spike latencies decrease. Here we use this learning rule in an asynchronous feedforward spiking neural network that mimics the ventral visual pathway and shows that when the network is presented with natural images, selectivity to intermediate-complexity visual features emerges. Those features, which correspond to prototypical patterns that are both salient and consistently present in the images, are highly informative and enable robust object recognition, as demonstrated on various classification tasks. Taken together, these results show that temporal codes may be a key to understanding the phenomenal processing speed achieved by the visual system and that STDP can lead to fast and selective responses.},
	language = {en},
	number = {2},
	urldate = {2018-09-10},
	journal = {PLOS Computational Biology},
	author = {Masquelier, Timothée and Thorpe, Simon J.},
	month = feb,
	year = {2007},
	note = {00314},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {e31},
	annote = {00314},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/VGSAA9MH/Masquelier and Thorpe - 2007 - Unsupervised Learning of Visual Features through S.pdf:application/pdf},
}

@article{Bienenstock1995,
	title = {A model of neocortex},
	volume = {6},
	issn = {0954-898X},
	url = {https://doi.org/10.1088/0954-898X_6_2_004},
	doi = {10.1088/0954-898x_6_2_004},
	abstract = {Prompted by considerations about (i) the compositionality of cognitive functions, (ii) the physiology of individual cortical neurons, (iii) the role of accurately timed spike patterns in cortex, and (iv) the regulation of global cortical activity, we suggest that the dynamics of cortex on the 1-ms time scale may be described as the activation of circuits of the synfire-chain type (Abeles 1982, 1991). We suggest that the fundamental computational unit in cortex may be a wave-like spatio-temporal pattern of synfire type, and that the binding mechanism underlying compositionality in cognition may be the accurate synchronization of synfire waves that propagate simultaneously on distinct, weakly coupled, synfire chains. We propose that Hebbian synaptic plasticity may result in a superposition of synfire chains in cortical connectivity, whereby a given neuron participates in many distinct chains. We investigate the behaviour of a much-simplified model of cortical dynamics devised along these principles. Calculations and numerical experiments are performed based on an assumption of randomness of stored chains, in the style of statistical physics. It is demonstrated that: (i) there exists a critical value for the total length of stored chains; (ii) this storage capacity is linear in the network's size; (iii) the behaviour of the network around the critical point is characterized by the self-regulation of the number of synfire waves coactive in the network at any given time.},
	number = {2},
	urldate = {2021-10-21},
	journal = {Network: Computation in Neural Systems},
	author = {Bienenstock, Elie},
	month = jan,
	year = {1995},
	note = {00000 
\_eprint: https://doi.org/10.1088/0954-898X\_6\_2\_004
tex.ids= Bienenstock1995
publisher: Taylor \& Francis},
	keywords = {⛔ No INSPIRE recid found},
	pages = {179--224},
	annote = {Publisher: Taylor \& Francis \_eprint: https://doi.org/10.1088/0954-898X\_6\_2\_004},
	annote = {Publisher: Taylor \& Francis \_eprint: https://doi.org/10.1088/0954-898X\_6\_2\_004},
	file = {Bienenstock Network 95 A Model of Neocortex.pdf:/Users/laurentperrinet/Zotero/storage/7IR7NWDH/Bienenstock Network 95 A Model of Neocortex.pdf:application/pdf;Bienenstock Network 95 A Model of Neocortex.pdf:/Users/laurentperrinet/Zotero/storage/6WQHH3X5/Bienenstock Network 95 A Model of Neocortex.pdf:application/pdf},
}

@article{Pauli2018,
	title = {Reproducing {Polychronization}: {A} {Guide} to {Maximizing} the {Reproducibility} of {Spiking} {Network} {Models}},
	volume = {12},
	issn = {1662-5196},
	shorttitle = {Reproducing {Polychronization}},
	url = {https://www.frontiersin.org/article/10.3389/fninf.2018.00046},
	doi = {10.3389/fninf.2018.00046},
	abstract = {Any modeler who has attempted to reproduce a spiking neural network model from its description in a paper has discovered what a painful endeavor this is. Even when all parameters appear to have been specified, which is rare, typically the initial attempt to reproduce the network does not yield results that are recognizably akin to those in the original publication. Causes include inaccurately reported or hidden parameters (e.g., wrong unit or the existence of an initialization distribution), differences in implementation of model dynamics, and ambiguities in the text description of the network experiment. The very fact that adequate reproduction often cannot be achieved until a series of such causes have been tracked down and resolved is in itself disconcerting, as it reveals unreported model dependencies on specific implementation choices that either were not clear to the original authors, or that they chose not to disclose. In either case, such dependencies diminish the credibility of the model's claims about the behavior of the target system. To demonstrate these issues, we provide a worked example of reproducing a seminal study for which, unusually, source code was provided at time of publication. Despite this seemingly optimal starting position, reproducing the results was time consuming and frustrating. Further examination of the correctly reproduced model reveals that it is highly sensitive to implementation choices such as the realization of background noise, the integration timestep, and the thresholding parameter of the analysis algorithm. From this process, we derive a guideline of best practices that would substantially reduce the investment in reproducing neural network studies, whilst simultaneously increasing their scientific quality. We propose that this guideline can be used by authors and reviewers to assess and improve the reproducibility of future network models.},
	urldate = {2021-10-21},
	journal = {Frontiers in Neuroinformatics},
	author = {Pauli, Robin and Weidel, Philipp and Kunkel, Susanne and Morrison, Abigail},
	year = {2018},
	note = {00000},
	keywords = {⛔ No INSPIRE recid found},
	pages = {46},
	annote = {00000},
	annote = {00000},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/QQ5TVWJV/Pauli et al. - 2018 - Reproducing Polychronization A Guide to Maximizin.pdf:application/pdf},
}

@article{Haessig2020,
	title = {Event-{Based} {Computation} for {Touch} {Localization} {Based} on {Precise} {Spike} {Timing}},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00420},
	doi = {10.3389/fnins.2020.00420},
	abstract = {Precise spike timing and temporal coding are used extensively within the nervous system of insects and in the sensory periphery of higher order animals. However, conventional Artificial Neural Networks (ANNs) and machine learning algorithms cannot take advantage of this coding strategy, due to their rate-based representation of signals. Even in the case of artificial Spiking Neural Networks (SNNs), identifying applications where temporal coding outperforms the rate coding strategies of ANNs is still an open challenge. Neuromorphic sensory-processing systems provide an ideal context for exploring the potential advantages of temporal coding, as they are able to efficiently extract the information required to cluster or classify spatio-temporal activity patterns from relative spike timing. Here we propose a neuromorphic model inspired by the sand scorpion to explore the benefits of temporal coding, and validate it in an event-based sensory-processing task. The task consists in localizing a target using only the relative spike timing of eight spatially-separated vibration sensors. We propose two different approaches in which the SNNs learns to cluster spatio-temporal patterns in an unsupervised manner and we demonstrate how the task can be solved both analytically and through numerical simulation of multiple SNN models. We argue that the models presented are optimal for spatio-temporal pattern classification using precise spike timing in a task that could be used as a standard benchmark for evaluating event-based sensory processing models based on temporal coding.},
	urldate = {2021-10-20},
	journal = {Frontiers in Neuroscience},
	author = {Haessig, Germain and Milde, Moritz B. and Aceituno, Pau Vilimelis and Oubari, Omar and Knight, James C. and van Schaik, André and Benosman, Ryad B. and Indiveri, Giacomo},
	year = {2020},
	note = {00006},
	keywords = {⛔ No INSPIRE recid found},
	pages = {420},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/C6YFC5YP/Haessig et al. - 2020 - Event-Based Computation for Touch Localization Bas.pdf:application/pdf},
}

@article{Goltz2021,
	title = {Fast and energy-efficient neuromorphic deep learning with first-spike times},
	volume = {3},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-021-00388-x},
	doi = {10/gm5gwd},
	abstract = {For a biological agent operating under environmental pressure, energy consumption and reaction times are of critical importance. Similarly, engineered systems are optimized for short time-to-solution and low energy-to-solution characteristics. At the level of neuronal implementation, this implies achieving the desired results with as few and as early spikes as possible. With time-to-ﬁrst-spike coding both of these goals are inherently emerging features of learning. Here, we describe a rigorous derivation of a learning rule for such ﬁrst-spike times in networks of leaky integrate-andﬁre neurons, relying solely on input and output spike times, and show how this mechanism can implement error backpropagation in hierarchical spiking networks. Furthermore, we emulate our framework on the BrainScaleS-2 neuromorphic system and demonstrate its capability of harnessing the system’s speed and energy characteristics. Finally, we examine how our approach generalizes to other neuromorphic platforms by studying how its performance is aﬀected by typical distortive eﬀects induced by neuromorphic substrates.},
	language = {en},
	number = {9},
	urldate = {2021-10-12},
	journal = {Nature Machine Intelligence},
	author = {Göltz, J. and Kriener, L. and Baumbach, A. and Billaudelle, S. and Breitwieser, O. and Cramer, B. and Dold, D. and Kungl, A. F. and Senn, W. and Schemmel, J. and Meier, K. and Petrovici, M. A.},
	month = sep,
	year = {2021},
	note = {00000
tex.ids= Goltz2021
rights: http://creativecommons.org/licenses/by/4.0/},
	keywords = {⛔ No INSPIRE recid found},
	pages = {823--835},
	file = {Göltz et al. - 2021 - Fast and energy-efficient neuromorphic deep learni.pdf:/Users/laurentperrinet/Zotero/storage/LD8ZHIXF/Göltz et al. - 2021 - Fast and energy-efficient neuromorphic deep learni.pdf:application/pdf},
}

@article{Eurich1999,
	title = {Dynamics of {Self}-{Organized} {Delay} {Adaptation}},
	volume = {82},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.82.1594},
	doi = {10/dj9c7q},
	abstract = {Adaptation of interaction delays is essential for the functioning of many natural and technical systems. We introduce a novel framework for studying the dynamics of delay adaptation in systems which optimize coincidence of inputs. For the important case of periodically modulated input we derive conditions for the existence and stability of solutions which constrain the set of mechanisms for reliable delay adaptation. Using numerical examples we show that our approach is applicable to more general than periodic input patterns such as Poissonian point processes with coordinated rate fluctuations.},
	number = {7},
	urldate = {2021-09-16},
	journal = {Physical Review Letters},
	author = {Eurich, Christian W. and Pawelzik, Klaus and Ernst, Udo and Cowan, Jack D. and Milton, John G.},
	month = feb,
	year = {1999},
	note = {00082 
Publisher: American Physical Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1594--1597},
	annote = {00082 Publisher: American Physical Society},
	annote = {00082 Publisher: American Physical Society},
	file = {APS Snapshot:/Users/laurentperrinet/Zotero/storage/BXG4RCHY/PhysRevLett.82.html:text/html},
}

@article{Foss2000,
	title = {Multistability in {Recurrent} {Neural} {Loops} {Arising} {From} {Delay}},
	volume = {84},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.2000.84.2.975},
	doi = {10/gmvbsh},
	abstract = {The dynamics of a recurrent inhibitory neural loop composed of a periodically spiking Aplysia motoneuron reciprocally connected to a computer are investigated as a function of the time delay, τ, for propagation around the loop. It is shown that for certain choices of τ, multiple qualitatively different neural spike trains co-exist. A mathematical model is constructed for the dynamics of this pulsed-coupled recurrent loop in which all parameters are readily measured experimentally: the phase resetting curve of the neuron for a given simulated postsynaptic current and τ. For choices of the parameters for which multiple spiking patterns co-exist in the experimental paradigm, the model exhibits multistability. Numerical simulations suggest that qualitatively similar results will occur if the motoneuron is replaced by several other types of neurons and that once τ becomes sufficiently long, multistability will be the dominant form of dynamical behavior. These observations suggest that great care must be taken in determining the etiology of qualitative changes in neural spiking patterns, particularly when propagation times around polysynaptic loops are long.},
	language = {en},
	number = {2},
	urldate = {2021-09-16},
	journal = {Journal of Neurophysiology},
	author = {Foss, Jennifer and Milton, John},
	month = aug,
	year = {2000},
	note = {00125
tex.ids= Foss00a
publisher: American Physiological Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {975--985},
	file = {Foss and Milton - 2000 - Multistability in Recurrent Neural Loops Arising F.pdf:/Users/laurentperrinet/Zotero/storage/CDDQHQGC/Foss and Milton - 2000 - Multistability in Recurrent Neural Loops Arising F.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/JGPK8SYD/Foss and Milton - 2000 - Multistability in Recurrent Neural Loops Arising F.pdf:application/pdf},
}

@article{Gerstner1995,
	title = {Time structure of the activity in neural network models},
	volume = {51},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.51.738},
	doi = {10/cwcn9d},
	abstract = {Several neural network models in continuous time are reconsidered in the framework of a general mean-field theory which is exact in the limit of a large and fully connected network. The theory assumes pointlike spikes which are generated by a renewal process. The effect of spikes on a receiving neuron is described by a linear response kernel which is the dominant term in a weak-coupling expansion. It is shown that the resulting ‘‘spike response model’’ is the most general renewal model with linear inputs. The standard integrate-and-fire model forms a special case. In a network structure with several pools of identical spiking neurons, the global states and the dynamic evolution are determined by a nonlinear integral equation which describes the effective interaction within and between different pools. We derive explicit stability criteria for stationary (incoherent) and oscillatory (coherent) solutions. It is shown that the stationary state of noiseless systems is ‘‘almost always’’ unstable. Noise suppresses fast oscillations and stabilizes the system. Furthermore, collective oscillations are stable only if the firing occurs while the synaptic potential is increasing. In particular, collective oscillations in a network with delayless excitatory interaction are at most semistable. Inhibitory interactions with short delays or excitatory interactions with long delays lead to stable oscillations. Our general results allow a straightforward application to different network models with spiking neurons. Furthermore, the theory allows an estimation of the errors introduced in firing rate or ‘‘graded-response’’ models.},
	number = {1},
	urldate = {2021-09-17},
	journal = {Physical Review E},
	author = {Gerstner, Wulfram},
	month = jan,
	year = {1995},
	note = {00580
tex.ids= Gerstner1995
publisher: American Physical Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {738--758},
	file = {APS Snapshot:/Users/laurentperrinet/Zotero/storage/F8RTKAJW/PhysRevE.51.html:text/html;Version soumise:/Users/laurentperrinet/Zotero/storage/DSCM98UQ/Gerstner - 1995 - Time structure of the activity in neural network m.pdf:application/pdf},
}

@book{Hebb1949,
	address = {New York},
	title = {The organization of behavior: {A} neuropsychological theory},
	publisher = {Wiley},
	author = {Hebb, Donald O.},
	year = {1949},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, bicv-sparse},
	annote = {* origin : "Actions, sensations, and states of feeling, occurring together, or in close succession, tend to grow together, or cohere, in such a way that when any of them is afterwards presented to the mind, the others are apt to be brought up in idea." (Bain, 1872, p85.) *: he http://neuron-ai.tuke.sk/NCS/VOL1/P3\_html/node14.html is a student of Lashley (engramm) * http://www.smithsrisca.demon.co.uk/hebbian-theory.html * p.62 "When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A's efficiency, as one of the cells firing B, is increased."},
}

@article{Duffy2019,
	title = {Variation in sequence dynamics improves maintenance of stereotyped behavior in an example from bird song},
	volume = {116},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/19/9592},
	doi = {10/gpfjm6},
	abstract = {{\textless}p{\textgreater}Performing a stereotyped behavior successfully over time requires both maintaining performance quality and adapting efficiently to environmental or physical changes affecting performance. The bird song system is a paradigmatic example of learning a stereotyped behavior and therefore is a good place to study the interaction of these two goals. Through a model of bird song learning, we show how instability in neural representation of stable behavior confers advantages for adaptation and maintenance with minimal cost to performance quality. A precise, temporally sparse sequence from the premotor nucleus HVC is crucial to the performance of song in songbirds. We find that learning in the presence of sequence variations facilitates rapid relearning after shifts in the target song or muscle structure and results in decreased error with neuron loss. This robustness is due to the prevention of the buildup of correlations in the learned connectivity. In the absence of sequence variations, these correlations grow, due to the relatively low dimensionality of the exploratory variation in comparison with the number of plastic synapses. Our results suggest one would expect to see variability in neural systems executing stereotyped behaviors, and this variability is an advantageous feature rather than a challenge to overcome.{\textless}/p{\textgreater}},
	language = {en},
	number = {19},
	urldate = {2022-02-10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Duffy, Alison and Abe, Elliott and Perkel, David J. and Fairhall, Adrienne L.},
	month = may,
	year = {2019},
	pmid = {31015294},
	note = {tex.ids= Duffy2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {9592--9597},
	file = {Duffy et al. - 2019 - Variation in sequence dynamics improves maintenance of stereotyped behavior in an example from bird song.pdf:/Users/laurentperrinet/Zotero/storage/ILBNJG9Q/Duffy et al. - 2019 - Variation in sequence dynamics improves maintenance of stereotyped behavior in an example from bird song.pdf:application/pdf;Texte intégral:/Users/laurentperrinet/Zotero/storage/88XHVB3H/Duffy et al. - 2019 - Variation in sequence dynamics improves maintenanc.pdf:application/pdf},
}

@article{Chavane2022,
	title = {Revisiting horizontal connectivity rules in {V1}: from like-to-like towards like-to-all},
	copyright = {All rights reserved},
	issn = {1863-2661},
	shorttitle = {Revisiting horizontal connectivity rules in {V1}},
	url = {https://doi.org/10.1007/s00429-022-02455-4},
	doi = {10.1007/s00429-022-02455-4},
	abstract = {Horizontal connections in the primary visual cortex of carnivores, ungulates and primates organize on a near-regular lattice. Given the similar length scale for the regularity found in cortical orientation maps, the currently accepted theoretical standpoint is that these maps are underpinned by a like-to-like connectivity rule: horizontal axons connect preferentially to neurons with similar preferred orientation. However, there is reason to doubt the rule’s explanatory power, since a growing number of quantitative studies show that the like-to-like connectivity preference and bias mostly observed at short-range scale, are highly variable on a neuron-to-neuron level and depend on the origin of the presynaptic neuron. Despite the wide availability of published data, the accepted model of visual processing has never been revised. Here, we review three lines of independent evidence supporting a much-needed revision of the like-to-like connectivity rule, ranging from anatomy to population functional measures, computational models and to theoretical approaches. We advocate an alternative, distance-dependent connectivity rule that is consistent with new structural and functional evidence: from like-to-like bias at short horizontal distance to like-to-all at long horizontal distance. This generic rule accounts for the observed high heterogeneity in interactions between the orientation and retinotopic domains, that we argue is necessary to process non-trivial stimuli in a task-dependent manner.},
	language = {en},
	urldate = {2022-02-06},
	journal = {Brain Structure and Function},
	author = {Chavane, Frédéric and Perrinet, Laurent Udo and Rankin, James},
	month = feb,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	file = {Chavane et al. - 2022 - Revisiting horizontal connectivity rules in V1 fr.pdf:/Users/laurentperrinet/Zotero/storage/QP6SABLU/Chavane et al. - 2022 - Revisiting horizontal connectivity rules in V1 fr.pdf:application/pdf},
}

@article{Berens2012,
	title = {A {Fast} and {Simple} {Population} {Code} for {Orientation} in {Primate} {V1}},
	volume = {32},
	copyright = {Copyright © 2012 the authors 0270-6474/12/3210618-09\$15.00/0. This article is freely available online through the J Neurosci Open Choice option.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/32/31/10618},
	doi = {10/f365rn},
	abstract = {Orientation tuning has been a classic model for understanding single-neuron computation in the neocortex. However, little is known about how orientation can be read out from the activity of neural populations, in particular in alert animals. Our study is a first step toward that goal. We recorded from up to 20 well isolated single neurons in the primary visual cortex of alert macaques simultaneously and applied a simple, neurally plausible decoder to read out the population code. We focus on two questions: First, what are the time course and the timescale at which orientation can be read out from the population response? Second, how complex does the decoding mechanism in a downstream neuron have to be to reliably discriminate between visual stimuli with different orientations? We show that the neural ensembles in primary visual cortex of awake macaques represent orientation in a way that facilitates a fast and simple readout mechanism: With an average latency of 30–80 ms, the population code can be read out instantaneously with a short integration time of only tens of milliseconds, and neither stimulus contrast nor correlations need to be taken into account to compute the optimal synaptic weight pattern. Our study shows that—similar to the case of single-neuron computation—the representation of orientation in the spike patterns of neural populations can serve as an exemplary case for understanding the computations performed by neural ensembles underlying visual processing during behavior.},
	language = {en},
	number = {31},
	urldate = {2020-11-09},
	journal = {Journal of Neuroscience},
	author = {Berens, Philipp and Ecker, Alexander S. and Cotton, R. James and Ma, Wei Ji and Bethge, Matthias and Tolias, Andreas S.},
	month = aug,
	year = {2012},
	pmid = {22855811},
	note = {00000
tex.ids= Berens12a, Berens2012a
publisher: Society for Neuroscience
section: Articles},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {10618--10626},
	annote = {00000 tex.ids= Berens12a publisher: Society for Neuroscience section: Articles},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/V43UMH4H/Berens et al. - 2012 - A Fast and Simple Population Code for Orientation .pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/5TB6HMBG/10618.html:text/html},
}

@article{Stringer2019,
	title = {Spontaneous behaviors drive multidimensional, brainwide activity},
	volume = {364},
	url = {http://www.science.org/doi/10.1126/science.aav7893},
	doi = {10/gfz6mh},
	number = {6437},
	urldate = {2021-12-03},
	journal = {Science},
	author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Reddy, Charu Bai and Carandini, Matteo and Harris, Kenneth D.},
	month = apr,
	year = {2019},
	note = {00444
tex.ids= Stringer19b, Stringer2019
publisher: American Association for the Advancement of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {eaav7893},
	file = {Accepted Version:/Users/laurentperrinet/Zotero/storage/5VJT6VNH/Stringer et al. - 2019 - Spontaneous behaviors drive multidimensional, brai.pdf:application/pdf;Accepted Version:/Users/laurentperrinet/Zotero/storage/RC3X7LDJ/Stringer et al. - 2019 - Spontaneous behaviors drive multidimensional, brai.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/6GGYGFK5/science.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/7XZGXUH4/Stringer et al. - 2019 - Spontaneous behaviors drive multidimensional, brai.pdf:application/pdf},
}

@article{Malvache2016,
	title = {Awake hippocampal reactivations project onto orthogonal neuronal assemblies},
	volume = {353},
	issn = {1095-9203},
	doi = {10/bqpq},
	abstract = {The chained activation of neuronal assemblies is thought to support major cognitive processes, including memory. In the hippocampus, this is observed during population bursts often associated with sharp-wave ripples, in the form of an ordered reactivation of neurons. However, the organization and lifetime of these assemblies remain unknown. We used calcium imaging to map patterns of synchronous neuronal activation in the CA1 region of awake mice during runs on a treadmill. The patterns were composed of the recurring activation of anatomically intermingled, but functionally orthogonal, assemblies. These assemblies reactivated discrete temporal segments of neuronal sequences observed during runs and could be stable across consecutive days. A binding of these assemblies into longer chains revealed temporally ordered replay. These modules may represent the default building blocks for encoding or retrieving experience.},
	language = {eng},
	number = {6305},
	journal = {Science (New York, N.Y.)},
	author = {Malvache, Arnaud and Reichinnek, Susanne and Villette, Vincent and Haimerl, Caroline and Cossart, Rosa},
	month = sep,
	year = {2016},
	pmid = {27634534},
	note = {00105 },
	keywords = {⛔ No INSPIRE recid found, Animals, Brain Mapping, CA1 Region, CA1 Region, Hippocampal, Calcium Signaling, Exercise Test, Hippocampal, Male, Mice, Nerve Net, Neurons, Running, Wakefulness},
	pages = {1280--1283},
	annote = {00105},
	annote = {00105},
	file = {malvache2016.pdf:/Users/laurentperrinet/Zotero/storage/GAHL294J/malvache2016.pdf:application/pdf},
}

@article{Villette2015,
	title = {Internally {Recurring} {Hippocampal} {Sequences} as a {Population} {Template} of {Spatiotemporal} {Information}},
	volume = {88},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627315008417},
	doi = {10/f7whnn},
	abstract = {The hippocampus is essential for spatiotemporal cognition. Sequences of neuronal activation provide a substrate for this fundamental function. At the behavioral timescale, these sequences have been shown to occur either in the presence of successive external landmarks or through internal mechanisms within an episodic memory task. In both cases, activity is externally constrained by the organization of the task and by the size of the environment explored. Therefore, it remains unknown whether hippocampal activity can self-organize into a default mode in the absence of any external memory demand or spatiotemporal boundary. Here we show that, in the presence of self-motion cues, a population code integrating distance naturally emerges in the hippocampus in the form of recurring sequences. These internal dynamics clamp spontaneous travel since run distance distributes into integer multiples of the span of these sequences. These sequences may thus guide navigation when external landmarks are reduced.},
	language = {en},
	number = {2},
	urldate = {2022-01-17},
	journal = {Neuron},
	author = {Villette, Vincent and Malvache, Arnaud and Tressard, Thomas and Dupuy, Nathalie and Cossart, Rosa},
	month = oct,
	year = {2015},
	note = {00085},
	keywords = {⛔ No INSPIRE recid found},
	pages = {357--366},
	annote = {00085},
	annote = {00085},
	file = {Villette et al. - 2015 - Internally Recurring Hippocampal Sequences as a Population Template of Spatiotemporal Information.pdf:/Users/laurentperrinet/Zotero/storage/TH2KTXVR/Villette et al. - 2015 - Internally Recurring Hippocampal Sequences as a Population Template of Spatiotemporal Information.pdf:application/pdf},
}

@article{Izhikevich2009,
	title = {Polychronous {Wavefront} {Computations}},
	volume = {19},
	issn = {0218-1274, 1793-6551},
	url = {https://www.izhikevich.org/publications/polychronous_wavefront_computations.htm},
	doi = {10.1142/s0218127409023809},
	abstract = {There is great interest in methods for computing that do not involve digital machines. Many computational paradigms were inspired by brain research, such as Boolean neuronal logic [McCulloch \& Pitts, 1943], the perceptron [Rosenblatt, 1958], attractor neural networks [Hopfield, 1982] and cellular neural nets [Chua \& Yang, 1988]. All these paradigms abstract biological circuits to artificial neural networks, i.e. interconnected units (neurons) that perform computations based on the connections between the units (synapses). Here we present a novel computational framework based on polychronous wavefront dynamics. It is entirely different from an artificial neural network paradigm, rather it is based on temporal and spatial patterns of activity in pulse-propagating media and their interaction with transponders, which create pulses in response to receiving appropriate inputs, e.g. two coincident input pulses. A pulse propagates as a circular wave from its source to other transponders. Computations result from interactions between transponders, and they are encoded by the exact physical locations of transponders and by precise timings of pulses. We illustrate temporal pattern recognition, reverberating memory, temporal signal analysis and basic logical operations using polychronous wavefront computations. This work reveals novel principles for designing nanoscale computational devices.},
	language = {en},
	number = {05},
	urldate = {2019-09-10},
	journal = {International Journal of Bifurcation and Chaos},
	author = {Izhikevich, Eugene M. and Hoppensteadt, Frank C.},
	month = may,
	year = {2009},
	note = {00088
tex.ids= Izhikevich09a
publisher: World Scientific Publishing Co.},
	keywords = {⛔ No INSPIRE recid found, polychronization},
	pages = {1733--1739},
	file = {Submitted Version:/Users/laurentperrinet/Zotero/storage/3DMB7VDE/Izhikevich and Hoppensteadt - 2009 - Polychronous wavefront computations.pdf:application/pdf},
}

@incollection{Paugam-Moisy2012,
	address = {Berlin, Heidelberg},
	title = {Computing with {Spiking} {Neuron} {Networks}},
	isbn = {978-3-540-92909-3 978-3-540-92910-9},
	url = {http://link.springer.com/10.1007/978-3-540-92910-9_10},
	abstract = {Spiking Neuron Networks (SNNs) are often referred to as the 3rd generation of neural networks. Highly inspired from natural computing in the brain and recent advances in neurosciences, they derive their strength and interest from an accurate modeling of synaptic interactions between neurons, taking into account the time of spike ﬁring. SNNs overcome the computational power of neural networks made of threshold or sigmoidal units. Based on dynamic event-driven processing, they open up new horizons for developing models with an exponential capacity of memorizing and a strong ability to fast adaptation. Today, the main challenge is to discover efﬁcient learning rules that might take advantage of the speciﬁc features of SNNs while keeping the nice properties (general-purpose, easy-to-use, available simulators, etc.) of traditional connectionist models. This chapter relates the history of the “spiking neuron” in Section 1 and summarizes the most currently-in-use models of neurons and synaptic plasticity in Section 2. The computational power of SNNs is addressed in Section 3 and the problem of learning in networks of spiking neurons is tackled in Section 4, with insights into the tracks currently explored for solving it. Finally, Section 5 discusses application domains, implementation issues and proposes several simulation frameworks.},
	language = {en},
	urldate = {2021-01-08},
	booktitle = {Handbook of {Natural} {Computing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Paugam-Moisy, Hélène and Bohte, Sander},
	editor = {Rozenberg, Grzegorz and Bäck, Thomas and Kok, Joost N.},
	year = {2012},
	doi = {10.1007/978-3-540-92910-9_10},
	note = {00000
tex.ids= Paugam-Moisy2012},
	keywords = {⛔ No INSPIRE recid found},
	pages = {335--376},
	file = {HAL Snapshot:/Users/laurentperrinet/Zotero/storage/GT39QMQZ/hal-01587781.html:text/html;Submitted Version:/Users/laurentperrinet/Zotero/storage/2738KD8R/Paugam-Moisy and Bohte - 2012 - Computing with Spiking Neuron Networks.pdf:application/pdf;Submitted Version:/Users/laurentperrinet/Zotero/storage/E4MTZJKK/Paugam-Moisy and Bohte - 2012 - Computing with Spiking Neuron Networks.pdf:application/pdf},
}

@article{Barlow1989,
	title = {Unsupervised {Learning}},
	volume = {1},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1989.1.3.295},
	doi = {10.1162/neco.1989.1.3.295},
	abstract = {What use can the brain make of the massive flow of sensory information that occurs without any associated rewards or punishments? This question is reviewed in the light of connectionist models of unsupervised learning and some older ideas, namely the cognitive maps and working models of Tolman and Craik, and the idea that redundancy is important for understanding perception (Attneave 1954), the physiology of sensory pathways (Barlow 1959), and pattern recognition (Watanabe 1960). It is argued that (1) The redundancy of sensory messages provides the knowledge incorporated in the maps or models. (2) Some of this knowledge can be obtained by observations of mean, variance, and covariance of sensory messages, and perhaps also by a method called “minimum entropy coding.” (3) Such knowledge may be incorporated in a model of “what usually happens” with which incoming messages are automatically compared, enabling unexpected discrepancies to be immediately identified. (4) Knowledge of the sort incorporated into such a filter is a necessary prerequisite of ordinary learning, and a representation whose elements are independent makes it possible to form associations with logical functions of the elements, not just with the elements themselves.},
	number = {3},
	urldate = {2021-08-06},
	journal = {Neural Computation},
	author = {Barlow, H.B.},
	month = sep,
	year = {1989},
	note = {00000},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {295--311},
}

@inproceedings{Kim2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Real-{Time} {3D} {Reconstruction} and 6-{DoF} {Tracking} with an {Event} {Camera}},
	isbn = {978-3-319-46466-4},
	doi = {10.1007/978-3-319-46466-4_21},
	abstract = {We propose a method which can perform real-time 3D reconstruction from a single hand-held event camera with no additional sensing, and works in unstructured scenes of which it has no prior knowledge. It is based on three decoupled probabilistic filters, each estimating 6-DoF camera motion, scene logarithmic (log) intensity gradient and scene inverse depth relative to a keyframe, and we build a real-time graph of these to track and model over an extended local workspace. We also upgrade the gradient estimate for each keyframe into an intensity image, allowing us to recover a real-time video-like intensity sequence with spatial and temporal super-resolution from the low bit-rate input event stream. To the best of our knowledge, this is the first algorithm provably able to track a general 6D motion along with reconstruction of arbitrary structure including its intensity and the reconstruction of grayscale video that exclusively relies on event camera data.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Kim, Hanme and Leutenegger, Stefan and Davison, Andrew J.},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	note = {00259},
	keywords = {⛔ No INSPIRE recid found, 3D reconstruction, 6-DoF tracking, Event-based camera, Intensity reconstruction, SLAM, Visual odometry},
	pages = {349--364},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/VRTYRPYD/Kim et al. - 2016 - Real-Time 3D Reconstruction and 6-DoF Tracking wit.pdf:application/pdf;Springer Full Text PDF:/Users/laurentperrinet/Zotero/storage/C3NAZI7R/Kim et al. - 2016 - Real-Time 3D Reconstruction and 6-DoF Tracking wit.pdf:application/pdf},
}

@article{Moser2014,
	title = {On {Stability} of {Distance} {Measures} for {Event} {Sequences} {Induced} by {Level}-{Crossing} {Sampling}},
	volume = {62},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/6737305/},
	doi = {10.1109/tsp.2014.2305642},
	abstract = {While Shannon’s paradigm of sampling is based on equidistant points in time, triggered by a clock, level-crossing sampling schemes are based on the evaluation of the input signal’s amplitude. Three types of level-crossing concepts are considered: a) absolute level-crossings, b) absolute level-crossings with hysteretic quantization, that ignores repeated crossings, and c) thresholding changes. The latter is also referred to as send-on-delta. Such event-driven sampling principles are encountered in asynchronous event-based data acquisition of wireless sensor networks in order to reduce the amount of data transfer and energy consumption, in event-based imaging in order to realize high-dynamic range image acquisition or in biology in terms of neuronal spike trains. The paper addresses the similarity between the event sequences which encode the quantized signals resulting from such event-based sampling concepts. It is shown that such event-driven sampling principles induce instability effects when using dissimilarity measures which are state-of-the-art in this context. As an alternative metric, Hermann Weyl’s discrepancy norm is introduced, by which such instability effects can be avoided.},
	language = {en},
	number = {8},
	urldate = {2021-12-23},
	journal = {IEEE Transactions on Signal Processing},
	author = {Moser, Bernhard A. and Natschlager, Thomas},
	month = apr,
	year = {2014},
	note = {00026
tex.ids= Moser2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1987--1999},
	file = {Moser et Natschlager - 2014 - On Stability of Distance Measures for Event Sequen.pdf:/Users/laurentperrinet/Zotero/storage/7WXKN5YT/Moser et Natschlager - 2014 - On Stability of Distance Measures for Event Sequen.pdf:application/pdf},
}

@article{Agus2010,
	title = {Rapid {Formation} of {Robust} {Auditory} {Memories}: {Insights} from {Noise}},
	volume = {66},
	issn = {08966273},
	shorttitle = {Rapid {Formation} of {Robust} {Auditory} {Memories}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627310002850},
	doi = {10.1016/j.neuron.2010.04.014},
	abstract = {Before a natural sound can be recognized, an auditory signature of its source must be learned through experience. Here we used random waveforms to probe the formation of new memories for arbitrary complex sounds. A behavioral measure was designed, based on the detection of repetitions embedded in noises up to 4 s long. Unbeknownst to listeners, some noise samples reoccurred randomly throughout an experimental block. Results showed that repeated exposure induced learning for otherwise totally unpredictable and meaningless sounds. The learning was unsupervised and resilient to interference from other task-relevant noises. When memories were formed, they emerged rapidly, performance became abruptly near-perfect, and multiple noises were remembered for several weeks. The acoustic transformations to which recall was tolerant suggest that the learned features were local in time. We propose that rapid sensory plasticity could explain how the auditory brain creates useful memories from the ever-changing, but sometimes repeating, acoustical world.},
	language = {en},
	number = {4},
	urldate = {2021-12-23},
	journal = {Neuron},
	author = {Agus, Trevor R. and Thorpe, Simon J. and Pressnitzer, Daniel},
	month = may,
	year = {2010},
	note = {00188
tex.ids= Agus2010},
	keywords = {⛔ No INSPIRE recid found},
	pages = {610--618},
	file = {Agus et al. - 2010 - Rapid Formation of Robust Auditory Memories Insig.pdf:/Users/laurentperrinet/Zotero/storage/LN7ZWYYJ/Agus et al. - 2010 - Rapid Formation of Robust Auditory Memories Insig.pdf:application/pdf},
}

@article{Dardelet2021,
	title = {An {Event}-by-{Event} {Feature} {Detection} and {Tracking} {Invariant} to {Motion} {Direction} and {Velocity}},
	url = {https://www.techrxiv.org/articles/preprint/An_Event-by-Event_Feature_Detection_and_Tracking_Invariant_to_Motion_Direction_and_Velocity/17013824/1},
	doi = {10.36227/techrxiv.17013824.v1},
	abstract = {Contour velocity estimation and tracking from a fully event-based perspective.},
	urldate = {2021-12-14},
	author = {Dardelet, Laurent and Benosman, Ryad and Ieng, Sio-Hoi},
	month = nov,
	year = {2021},
	note = {1 citations (Crossref) [2022-09-03]
00000
tex.ids= Dardelet2021a},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	file = {Dardelet et al. - 2021 - An Event-by-Event Feature Detection and Tracking Invariant to Motion Direction and Velocity.pdf:/Users/laurentperrinet/Zotero/storage/EH9KE6JP/Dardelet et al. - 2021 - An Event-by-Event Feature Detection and Tracking Invariant to Motion Direction and Velocity.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/BDIPXEUC/Dardelet et al. - 2021 - An Event-by-Event Feature Detection and Tracking I.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/CTKTC9BM/17013824.html:text/html},
}

@article{Kerr2013,
	title = {Delay {Selection} by {Spike}-{Timing}-{Dependent} {Plasticity} in {Recurrent} {Networks} of {Spiking} {Neurons} {Receiving} {Oscillatory} {Inputs}},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002897},
	doi = {10.1371/journal.pcbi.1002897},
	abstract = {Learning rules, such as spike-timing-dependent plasticity (STDP), change the structure of networks of neurons based on the firing activity. A network level understanding of these mechanisms can help infer how the brain learns patterns and processes information. Previous studies have shown that STDP selectively potentiates feed-forward connections that have specific axonal delays, and that this underlies behavioral functions such as sound localization in the auditory brainstem of the barn owl. In this study, we investigate how STDP leads to the selective potentiation of recurrent connections with different axonal and dendritic delays during oscillatory activity. We develop analytical models of learning with additive STDP in recurrent networks driven by oscillatory inputs, and support the results using simulations with leaky integrate-and-fire neurons. Our results show selective potentiation of connections with specific axonal delays, which depended on the input frequency. In addition, we demonstrate how this can lead to a network becoming selective in the amplitude of its oscillatory response to this frequency. We extend this model of axonal delay selection within a single recurrent network in two ways. First, we show the selective potentiation of connections with a range of both axonal and dendritic delays. Second, we show axonal delay selection between multiple groups receiving out-of-phase, oscillatory inputs. We discuss the application of these models to the formation and activation of neuronal ensembles or cell assemblies in the cortex, and also to missing fundamental pitch perception in the auditory brainstem.},
	language = {en},
	number = {2},
	urldate = {2020-03-10},
	journal = {PLOS Computational Biology},
	author = {Kerr, Robert R. and Burkitt, Anthony N. and Thomas, Doreen A. and Gilson, Matthieu and Grayden, David B.},
	month = feb,
	year = {2013},
	pmcid = {PMC3567188},
	pmid = {23408878},
	note = {00023
tex.ids= Kerr2013, Kerr2013a
publisher: Public Library of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1002897},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/RT6LYPX9/Kerr et al. - 2013 - Delay Selection by Spike-Timing-Dependent Plastici.pdf:application/pdf;PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/FLMEJ4U6/Kerr et al. - 2013 - Delay Selection by Spike-Timing-Dependent Plastici.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/QQ88RKVX/article.html:text/html},
}

@article{Kempen2021,
	title = {Top-down coordination of local cortical state during selective attention},
	volume = {109},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(20)30995-8},
	doi = {10/ghvj3k},
	language = {English},
	number = {5},
	urldate = {2021-06-07},
	journal = {Neuron},
	author = {Kempen, Jochem van and Gieselmann, Marc A. and Boyd, Michael and Steinmetz, Nicholas A. and Moore, Tirin and Engel, Tatiana A. and Thiele, Alexander},
	month = mar,
	year = {2021},
	pmid = {33406410},
	note = {00005
tex.ids= Kempen2021a, vanKempen2021
publisher: Elsevier},
	keywords = {⛔ No INSPIRE recid found},
	pages = {894--904.e8},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/QEGQWCGP/Kempen et al. - 2021 - Top-down coordination of local cortical state duri.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/SRVB52E7/Kempen et al. - 2021 - Top-down coordination of local cortical state duri.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/AD3G36VJ/S0896-6273(20)30995-8.html:text/html;Snapshot:/Users/laurentperrinet/Zotero/storage/4GKBDRQU/S0896-6273(20)30995-8.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/WJBBVAF8/van Kempen et al. - 2021 - Top-down coordination of local cortical state duri.pdf:application/pdf},
}

@article{Gerstner1996,
	title = {A neuronal learning rule for sub-millisecond temporal coding},
	volume = {383},
	copyright = {1996 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/383076a0},
	doi = {10/d72hbx},
	abstract = {A PARADOX that exists in auditory and electrosensory neural systems1,2 is that they encode behaviourally relevant signals in the range of a few microseconds with neurons that are at least one order of magnitude slower. The importance of temporal coding in neural information processing is not clear yet3–8. A central question is whether neuronal firing can be more precise than the time constants of the neuronal processes involved9. Here we address this problem using the auditory system of the barn owl as an example. We present a modelling study based on computer simulations of a neuron in the laminar nucleus. Three observations explain the paradox. First, spiking of an 'integrate-and-fire' neuron driven by excitatory postsynaptic potentials with a width at half-maximum height of 250 μs, has an accuracy of 25 μs if the presynaptic signals arrive coherently. Second, the necessary degree of coherence in the signal arrival times can be attained during ontogenetic development by virtue of an unsupervised hebbian learning rule. Learning selects connections with matching delays from a broad distribution of axons with random delays. Third, the learning rule also selects the correct delays from two independent groups of inputs, for example, from the left and right ear.},
	language = {en},
	number = {6595},
	urldate = {2018-09-24},
	journal = {Nature},
	author = {Gerstner, Wulfram and Kempter, Richard and Hemmen, J. Leo van and Wagner, Hermann},
	month = sep,
	year = {1996},
	note = {00000
tex.ids= Gerstner1996b
number: 6595
publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found},
	pages = {76--78},
	annote = {Number: 6595 Publisher: Nature Publishing Group},
	annote = {Number: 6595 Publisher: Nature Publishing Group},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/5ZRMCFYN/Gerstner et al. - 1996 - A neuronal learning rule for sub-millisecond tempo.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/92F8L2LZ/383076a0.html:text/html},
}

@article{Huning1998,
	title = {Synaptic {Delay} {Learning} in {Pulse}-{Coupled} {Neurons}},
	volume = {10},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/089976698300017665},
	doi = {10/cthfps},
	abstract = {We present rules for the unsupervised learning of coincidence between excitatory postsynaptic potentials (EPSPs) by the adjustment of post-synaptic delays between the transmitter binding and the opening of ion channels. Starting from a gradient descent scheme, we develop a robust and more biological threshold rule by which EPSPs from different synapses can be gradually pulled into coincidence. The synaptic delay changes are determined from the summed potential—at the site where the coincidence is to be established—and from postulated synaptic learning functions that accompany the individual EPSPs. According to our scheme, templates for the detection of spatiotemporal patterns of synaptic activation can be learned, which is demonstrated by computer simulation. Finally, we discuss possible relations to biological mechanisms.},
	number = {3},
	urldate = {2021-09-16},
	journal = {Neural Computation},
	author = {Hüning, Harald and Glünder, Helmut and Palm, Günther},
	month = apr,
	year = {1998},
	note = {00039
tex.ids= Huning1998a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {555--565},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/JC7SVI2C/Hüning et al. - 1998 - Synaptic Delay Learning in Pulse-Coupled Neurons.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/BA22J6CU/Hüning et al. - 1998 - Synaptic Delay Learning in Pulse-Coupled Neurons.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/4ZG8SBKR/Hüning et al. - 1998 - Synaptic Delay Learning in Pulse-Coupled Neurons.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/8ADN8RAU/Synaptic-Delay-Learning-in-Pulse-Coupled-Neurons.html:text/html},
}

@article{Ikegaya2004,
	title = {Synfire {Chains} and {Cortical} {Songs}: {Temporal} {Modules} of {Cortical} {Activity}},
	volume = {304},
	shorttitle = {Synfire {Chains} and {Cortical} {Songs}},
	url = {http://www.science.org/doi/10.1126/science.1093173},
	doi = {10/djckcn},
	number = {5670},
	urldate = {2021-11-29},
	journal = {Science},
	author = {Ikegaya, Yuji and Aaron, Gloster and Cossart, Rosa and Aronov, Dmitriy and Lampl, Ilan and Ferster, David and Yuste, Rafael},
	month = apr,
	year = {2004},
	note = {00000
tex.ids= Ikegaya2004a
publisher: American Association for the Advancement of Science},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, polychronization},
	pages = {559--564},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/GE474ICA/Ikegaya et al. - 2004 - Synfire Chains and Cortical Songs Temporal Module.pdf:application/pdf;ikegaya.som.pdf:/Users/laurentperrinet/Zotero/storage/R8CG2RNL/ikegaya.som.pdf:application/pdf},
}

@article{Rucci2018,
	title = {Temporal {Coding} of {Visual} {Space}},
	volume = {22},
	issn = {1364-6613},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6179437/},
	doi = {10/gfcskd},
	abstract = {Establishing a representation of space is a major goal for sensory systems. Spatial information, however, is not always explicit in the incoming sensory signals. In most modalities, it needs to be actively extracted from cues embedded in the temporal flow of receptor activation. Vision, on the other hand, starts with a sophisticated optical imaging system that explicitly preserves spatial information on the retina. This may lead to the assumption that vision is predominantly a spatial process: all that is needed is to transmit the retinal image to the cortex, like uploading a digital photograph, to establish a spatial map of the world. However, this deceptively simple analogy is inconsistent with theoretical models and experiments that study visual processing in the context of normal motor behavior. We argue here that like other senses, vision relies heavily on temporal strategies and temporal neural codes to extract and represent spatial information.},
	number = {10},
	urldate = {2021-12-13},
	journal = {Trends in cognitive sciences},
	author = {Rucci, Michele and Ahissar, Ehud and Burr, David},
	month = oct,
	year = {2018},
	pmcid = {PMC6179437},
	pmid = {30266148},
	note = {00044
tex.ids= Rucci2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {883--895},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/YEU27UZC/Rucci et al. - 2018 - Temporal Coding of Visual Space.pdf:application/pdf},
}

@article{Safaie2020,
	title = {Turning the body into a clock: {Accurate} timing is facilitated by simple stereotyped interactions with the environment},
	volume = {117},
	copyright = {© 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Turning the body into a clock},
	url = {https://www.pnas.org/content/117/23/13084},
	doi = {10/gnqsmh},
	abstract = {How animals adapt their behavior according to regular time intervals between events is not well understood, especially when intervals last several seconds. One possibility is that animals use disembodied internal neuronal representations of time to decide when to initiate a given action at the end of an interval. However, animals rarely remain immobile during time intervals but tend to perform stereotyped behaviors, raising the possibility that motor routines improve timing accuracy. To test this possibility, we used a task in which rats, freely moving on a motorized treadmill, could obtain a reward if they approached it after a fixed interval. Most animals took advantage of the treadmill length and its moving direction to develop, by trial-and-error, the same motor routine whose execution resulted in the precise timing of their reward approaches. Noticeably, when proficient animals did not follow this routine, their temporal accuracy decreased. Then, naïve animals were trained in modified versions of the task designed to prevent the development of this routine. Compared to rats trained in the first protocol, these animals didn’t reach a comparable level of timing accuracy. Altogether, our results indicate that timing accuracy in rats is improved when the environment affords cues that animals can incorporate into motor routines.},
	language = {en},
	number = {23},
	urldate = {2021-12-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Safaie, Mostafa and Jurado-Parras, Maria-Teresa and Sarno, Stefania and Louis, Jordane and Karoutchi, Corane and Petit, Ludovic F. and Pasquet, Matthieu O. and Eloy, Christophe and Robbe, David},
	month = jun,
	year = {2020},
	pmid = {32434909},
	note = {10 citations (Crossref) [2022-09-03]
00010
tex.ids= Safaie2020a
publisher: National Academy of Sciences
section: Biological Sciences},
	keywords = {⛔ No INSPIRE recid found},
	pages = {13084--13093},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/D3Q346BG/Safaie et al. - 2020 - Turning the body into a clock Accurate timing is .pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/4XCWZ3KH/13084.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/M7QEW78U/Safaie et al. - 2020 - Turning the body into a clock Accurate timing is .pdf:application/pdf},
}

@article{Ghosh2019,
	title = {Spatiotemporal {Filtering} for {Event}-{Based} {Action} {Recognition}},
	url = {https://arxiv.org/abs/1903.07067v1},
	doi = {10.48550/arXiv.1903.07067},
	abstract = {In this paper, we address the challenging problem of action recognition, using event-based cameras. To recognise most gestural actions, often higher temporal precision is required for sampling visual information. Actions are defined by motion, and therefore, when using event-based cameras it is often unnecessary to re-sample the entire scene. Neuromorphic, event-based cameras have presented an alternative to visual information acquisition by asynchronously time-encoding pixel intensity changes, through temporally precise spikes (10 micro-second resolution), making them well equipped for action recognition. However, other challenges exist, which are intrinsic to event-based imagers, such as higher signal-to-noise ratio, and a spatiotemporally sparse information. One option is to convert event-data into frames, but this could result in significant temporal precision loss. In this work we introduce spatiotemporal filtering in the spike-event domain, as an alternative way of channeling spatiotemporal information through to a convolutional neural network. The filters are local spatiotemporal weight matrices, learned from the spike-event data, in an unsupervised manner. We find that appropriate spatiotemporal filtering significantly improves CNN performance beyond state-of-the-art on the event-based DVS Gesture dataset. On our newly recorded action recognition dataset, our method shows significant improvement when compared with other, standard ways of generating the spatiotemporal filters.},
	language = {en},
	urldate = {2022-04-29},
	author = {Ghosh, Rohan and Gupta, Anupam and Nakagawa, Andrei and Soares, Alcimar and Thakor, Nitish},
	month = mar,
	year = {2019},
	note = {tex.ids= Ghosh2019},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Submitted to IEEE Transactions in Pattern Analysis and Machine Intelligence},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/8L2YGGKZ/Ghosh et al. - 2019 - Spatiotemporal Filtering for Event-Based Action Re.pdf:application/pdf;Ghosh et al. - 2019 - Spatiotemporal Filtering for Event-Based Action Re.pdf:/Users/laurentperrinet/Zotero/storage/VNCMWIF9/Ghosh et al. - 2019 - Spatiotemporal Filtering for Event-Based Action Re.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/YAMSKFA4/1903.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/UQK5CSHS/Ghosh et al. - 2019 - Spatiotemporal filtering for event-based action re.pdf:application/pdf},
}

@article{Bernert2018,
	title = {An {Attention}-{Based} {Spiking} {Neural} {Network} for {Unsupervised} {Spike}-{Sorting}},
	volume = {29},
	issn = {0129-0657},
	url = {https://www.worldscientific.com/doi/10.1142/S0129065718500594},
	doi = {10.1142/s0129065718500594},
	abstract = {Bio-inspired computing using artificial spiking neural networks promises performances outperforming currently available computational approaches. Yet, the number of applications of such networks remains limited due to the absence of generic training procedures for complex pattern recognition, which require the design of dedicated architectures for each situation. We developed a spike-timing-dependent plasticity (STDP) spiking neural network (SSN) to address spike-sorting, a central pattern recognition problem in neuroscience. This network is designed to process an extracellular neural signal in an online and unsupervised fashion. The signal stream is continuously fed to the network and processed through several layers to output spike trains matching the truth after a short learning period requiring only few data. The network features an attention mechanism to handle the scarcity of action potential occurrences in the signal, and a threshold adaptation mechanism to handle patterns with different sizes. This method outperforms two existing spike-sorting algorithms at low signal-to-noise ratio (SNR) and can be adapted to process several channels simultaneously in the case of tetrode recordings. Such attention-based STDP network applied to spike-sorting opens perspectives to embed neuromorphic processing of neural data in future brain implants.},
	number = {08},
	urldate = {2021-01-26},
	journal = {International Journal of Neural Systems},
	author = {Bernert, Marie and Yvert, Blaise},
	month = dec,
	year = {2018},
	note = {00016
tex.ids= Bernert2018a, Bernert2019, Bernert2019a
publisher: World Scientific Publishing Co.},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1850059},
	annote = {00016 tex.ids= Bernert2019, Bernert2019a publisher: World Scientific Publishing Co.},
	file = {Bernert and Yvert - 2019 - An Attention-Based Spiking Neural Network for Unsu.pdf:/Users/laurentperrinet/Zotero/storage/T5WK4ATB/Bernert and Yvert - 2019 - An Attention-Based Spiking Neural Network for Unsu.pdf:application/pdf},
}

@techreport{Bernert2017,
	title = {Fully unsupervised online spike sorting based on an artificial spiking neural network},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/236224v1},
	abstract = {Spike sorting is a crucial step of neural data processing widely used in neuroscience and neuroprosthetics. However, current methods remain not fully automatic and require heavy computations making them not embeddable in implantable devices. To overcome these limitations, we propose a novel method based on an artificial spiking neural network designed to process neural data online and completely automatically. An input layer continuously encodes the data stream into artificial spike trains, which are then processed by two further layers to output artificial trains of spikes reproducing the real spiking activity present in the input signal. The proposed method can be adapted to process several channels simultaneously in the case of tetrode recordings. It outperforms two existing algorithms at low SNR and has the advantage to be compatible with neuromorphic computing and the perspective of being embedded in very low-power analog systems for future implantable devices serving neurorehabilitation applications.},
	language = {en},
	urldate = {2022-04-08},
	institution = {bioRxiv},
	author = {Bernert, Marie and Yvert, Blaise},
	month = dec,
	year = {2017},
	doi = {10.1101/236224},
	note = {tex.ids= Bernert2017a
section: New Results
type: article},
	keywords = {⛔ No INSPIRE recid found},
	pages = {236224},
	annote = {tex.ids= Bernert2017a section: New Results type: article},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/E5CV3ZW4/Bernert and Yvert - 2017 - Fully unsupervised online spike sorting based on a.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/ZE2SYW9Y/236224v1.html:text/html},
}

@article{Branco2010,
	title = {Dendritic {Discrimination} of {Temporal} {Input} {Sequences} in {Cortical} {Neurons}},
	volume = {329},
	url = {http://www.science.org/doi/10.1126/science.1189664},
	doi = {10.1126/science.1189664},
	number = {5999},
	urldate = {2022-03-29},
	journal = {Science},
	author = {Branco, Tiago and Clark, Beverley A. and Häusser, Michael},
	month = sep,
	year = {2010},
	note = {tex.ids= Branco2010
publisher: American Association for the Advancement of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1671--1675},
	file = {Branco et al. - 2010 - Dendritic Discrimination of Temporal Input Sequenc.pdf:/Users/laurentperrinet/Zotero/storage/IIEN6IQA/Branco et al. - 2010 - Dendritic Discrimination of Temporal Input Sequenc.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/UEALZZ4G/Branco et al. - 2010 - Dendritic Discrimination of Temporal Input Sequenc.pdf:application/pdf;Version acceptée:/Users/laurentperrinet/Zotero/storage/UPSFCS3Z/Branco et al. - 2010 - Dendritic Discrimination of Temporal Input Sequenc.pdf:application/pdf},
}

@article{Torre2016,
	title = {Synchronous {Spike} {Patterns} in {Macaque} {Motor} {Cortex} during an {Instructed}-{Delay} {Reach}-to-{Grasp} {Task}},
	volume = {36},
	copyright = {Copyright © 2016 Torre, et al.. This article is freely available online through the J Neurosci Author Open Choice option.},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/36/32/8329},
	doi = {10.1523/JNEUROSCI.4375-15.2016},
	abstract = {The computational role of spike time synchronization at millisecond precision among neurons in the cerebral cortex is hotly debated. Studies performed on data of limited size provided experimental evidence that low-order correlations occur in relation to behavior. Advances in electrophysiological technology to record from hundreds of neurons simultaneously provide the opportunity to observe coordinated spiking activity of larger populations of cells. We recently published a method that combines data mining and statistical evaluation to search for significant patterns of synchronous spikes in massively parallel spike trains (Torre et al., 2013). The method solves the computational and multiple testing problems raised by the high dimensionality of the data. In the current study, we used our method on simultaneous recordings from two macaque monkeys engaged in an instructed-delay reach-to-grasp task to determine the emergence of spike synchronization in relation to behavior. We found a multitude of synchronous spike patterns aligned in both monkeys along a preferential mediolateral orientation in brain space. The occurrence of the patterns is highly specific to behavior, indicating that different behaviors are associated with the synchronization of different groups of neurons (“cell assemblies”). However, pooled patterns that overlap in neuronal composition exhibit no specificity, suggesting that exclusive cell assemblies become active during different behaviors, but can recruit partly identical neurons. These findings are consistent across multiple recording sessions analyzed across the two monkeys.
SIGNIFICANCE STATEMENT Neurons in the brain communicate via electrical impulses called spikes. How spikes are coordinated to process information is still largely unknown. Synchronous spikes are effective in triggering a spike emission in receiving neurons and have been shown to occur in relation to behavior in a number of studies on simultaneous recordings of few neurons. We recently published a method to extend this type of investigation to larger data. Here, we apply it to simultaneous recordings of hundreds of neurons from the motor cortex of macaque monkeys performing a motor task. Our analysis reveals groups of neurons selectively synchronizing their activity in relation to behavior, which sheds new light on the role of synchrony in information processing in the cerebral cortex.},
	language = {en},
	number = {32},
	urldate = {2022-03-29},
	journal = {Journal of Neuroscience},
	author = {Torre, Emiliano and Quaglio, Pietro and Denker, Michael and Brochier, Thomas and Riehle, Alexa and Grün, Sonja},
	month = aug,
	year = {2016},
	pmid = {27511007},
	note = {tex.ids= Torre16a, Torre2016
publisher: Society for Neuroscience
section: Articles},
	keywords = {⛔ No INSPIRE recid found},
	pages = {8329--8340},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/HH4EEG2R/Torre et al. - 2016 - Synchronous Spike Patterns in Macaque Motor Cortex.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/DSIVSUM8/8329.html:text/html},
}

@incollection{Grun2010,
	address = {Boston, MA},
	title = {Unitary {Event} {Analysis}},
	isbn = {978-1-4419-5675-0},
	url = {https://doi.org/10.1007/978-1-4419-5675-0_10},
	abstract = {It has been proposed that cortical neurons organize dynamically into functional groups (“cell assemblies”) by the temporal structure of their joint spiking activity. The Unitary Events analysis method detects conspicuous patterns of coincident spike activity among simultaneously recorded single neurons. The statistical significance of a pattern is evaluated by comparing the number of occurrences to the number expected on the basis of the firing rates of the neurons. Key elements of the method are the proper formulation of the null hypothesis and the derivation of the corresponding count distribution of coincidences used in the significance test. Performing the analysis in a sliding window manner results in a time-resolved measure of significant spike synchrony. In this chapter we review the basic components of UE analysis and explore its dependencies on parameters like the allowed temporal imprecision and features of the data like firing rate and coincidence rate. Violations of the assumptions of stationarity of the firing rate within the analysis window and Poisson statistics can be tolerated to a reasonable degree without inducing false positives. We conclude that the UE method is robust already in its basic form. Still, it is preferable to use coincidence distributions for the significance test that are well adapted to particular features of the data. The chapter presents practical advice and solutions based on surrogates.},
	language = {en},
	urldate = {2022-03-29},
	booktitle = {Analysis of {Parallel} {Spike} {Trains}},
	publisher = {Springer US},
	author = {Grün, Sonja and Diesmann, Markus and Aertsen, Ad},
	editor = {Grün, Sonja and Rotter, Stefan},
	year = {2010},
	doi = {10.1007/978-1-4419-5675-0_10},
	note = {tex.ids= Grun2010},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {191--220},
}

@article{Softky1993,
	title = {The highly irregular firing of cortical cells is inconsistent with temporal integration of random {EPSPs}},
	volume = {13},
	copyright = {© 1993 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/13/1/334},
	doi = {10.1523/JNEUROSCI.13-01-00334.1993},
	abstract = {How random is the discharge pattern of cortical neurons? We examined recordings from primary visual cortex (V1; Knierim and Van Essen, 1992) and extrastriate cortex (MT; Newsome et al., 1989a) of awake, behaving macaque monkey and compared them to analytical predictions. For nonbursting cells firing at sustained rates up to 300 Hz, we evaluated two indices of firing variability: the ratio of the variance to the mean for the number of action potentials evoked by a constant stimulus, and the rate-normalized coefficient of variation (Cv) of the interspike interval distribution. Firing in virtually all V1 and MT neurons was nearly consistent with a completely random process (e.g., Cv approximately 1). We tried to model this high variability by small, independent, and random EPSPs converging onto a leaky integrate-and- fire neuron (Knight, 1972). Both this and related models predicted very low firing variability (Cv {\textless}{\textless} 1) for realistic EPSP depolarizations and membrane time constants. We also simulated a biophysically very detailed compartmental model of an anatomically reconstructed and physiologically characterized layer V cat pyramidal cell (Douglas et al., 1991) with passive dendrites and active soma. If independent, excitatory synaptic input fired the model cell at the high rates observed in monkey, the Cv and the variability in the number of spikes were both very low, in agreement with the integrate-and-fire models but in strong disagreement with the majority of our monkey data. The simulated cell only produced highly variable firing when Hodgkin-Huxley- like currents (INa and very strong IDR) were placed on distal dendrites. Now the simulated neuron acted more as a millisecond- resolution detector of dendritic spike coincidences than as a temporal integrator. We argue that neurons that act as temporal integrators over many synaptic inputs must fire very regularly. Only in the presence of either fast and strong dendritic nonlinearities or strong synchronization among individual synaptic events will the degree of predicted variability approach that of real cortical neurons.},
	language = {en},
	number = {1},
	urldate = {2022-03-29},
	journal = {Journal of Neuroscience},
	author = {Softky, W. R. and Koch, C.},
	month = jan,
	year = {1993},
	pmid = {8423479},
	note = {tex.ids= Softky1993
publisher: Society for Neuroscience
section: Articles},
	keywords = {⛔ No INSPIRE recid found},
	pages = {334--350},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/RP2Q5WAR/Softky and Koch - 1993 - The highly irregular firing of cortical cells is i.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/9ZPPPFA8/334.html:text/html},
}

@article{Schneidman2006,
	title = {Weak pairwise correlations imply strongly correlated network states in a neural population},
	volume = {440},
	copyright = {2006 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature04701},
	doi = {10.1038/nature04701},
	abstract = {Biological networks have so many possible states that exhaustive sampling is impossible. Successful analysis thus depends on simplifying hypotheses, but experiments on many systems hint that complicated, higher-order interactions among large groups of elements have an important role. Here we show, in the vertebrate retina, that weak correlations between pairs of neurons coexist with strongly collective behaviour in the responses of ten or more neurons. We find that this collective behaviour is described quantitatively by models that capture the observed pairwise correlations but assume no higher-order interactions. These maximum entropy models are equivalent to Ising models, and predict that larger networks are completely dominated by correlation effects. This suggests that the neural code has associative or error-correcting properties, and we provide preliminary evidence for such behaviour. As a first test for the generality of these ideas, we show that similar results are obtained from networks of cultured cortical neurons.},
	language = {en},
	number = {7087},
	urldate = {2022-03-24},
	journal = {Nature},
	author = {Schneidman, Elad and Berry, Michael J. and Segev, Ronen and Bialek, William},
	month = apr,
	year = {2006},
	note = {tex.ids= Schneidman2006, Schneidman:2006he
number: 7087
publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found, Humanities and Social Sciences, multidisciplinary, Science},
	pages = {1007--1012},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/S54ZQ9CQ/nature04701.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/9SZW6F58/Schneidman et al. - 2006 - Weak pairwise correlations imply strongly correlat.pdf:application/pdf;Version acceptée:/Users/laurentperrinet/Zotero/storage/IQS6DFG5/Schneidman et al. - 2006 - Weak pairwise correlations imply strongly correlat.pdf:application/pdf},
}

@article{Zhang2020,
	title = {Supervised learning in spiking neural networks with synaptic delay-weight plasticity},
	volume = {409},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231220304665},
	doi = {10.1016/j.neucom.2020.03.079},
	abstract = {Spiking neurons encode information through their spiking temporal patterns. Although the precise spike-timing based encoding scheme has long been recognised, the exact mechanism that underlies the learning of such precise spike-timing in the brain remains an open question. Most of the existing learning methods for spiking neurons are based on synaptic weight adjustment. However, biological evidences suggest that synaptic delays can also be modulated to play an important role in the learning process. This paper investigates the viability of integrating synaptic delay plasticity into supervised learning and proposes a novel learning method that adjusts both the synaptic delays and weights of the learning neurons to make them fire precisely timed spikes, that is referred to as synaptic delay-weight plasticity. Remote Supervised Method (ReSuMe) and Perceptron Based Spiking Neuron Learning Rule (PBSNLR), two representative supervised learning methods, are studied to illustrate how the synaptic delay-weight plasticity works. The performance of the proposed learning method is thoroughly evaluated on synthetic data and is further demonstrated on real-world classification tasks. The experiments show that the synaptic delay-weight learning method outperforms the traditional synaptic weight learning methods in many ways.},
	language = {en},
	urldate = {2022-03-16},
	journal = {Neurocomputing},
	author = {Zhang, Malu and Wu, Jibin and Belatreche, Ammar and Pan, Zihan and Xie, Xiurui and Chua, Yansong and Li, Guoqi and Qu, Hong and Li, Haizhou},
	month = oct,
	year = {2020},
	note = {tex.ids= Zhang2020, Zhang2020a, zhang2020supervised
publisher: Elsevier},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Spiking neural networks, Spiking neurons, Supervised learning, Synaptic delay, Synaptic plasticity, Synaptic weight},
	pages = {103--118},
	annote = {Publisher: Elsevier},
	file = {ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/DW9NTW4R/S0925231220304665.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/Q46PYJYZ/Zhang et al. - 2020 - Supervised learning in spiking neural networks wit.pdf:application/pdf;Version acceptée:/Users/laurentperrinet/Zotero/storage/DJ2QJTMT/Zhang et al. - 2020 - Supervised learning in spiking neural networks wit.pdf:application/pdf},
}

@article{Pillow2008,
	title = {Spatio-temporal correlations and visual signalling in a complete neuronal population},
	volume = {454},
	issn = {0028-0836},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2684455/},
	doi = {10.1038/nature07140},
	abstract = {Statistical dependencies in the responses of sensory neurons govern both the amount of stimulus information conveyed and the means by which downstream neurons can extract it. Although a variety of measurements indicate the existence of such dependencies–, their origin and importance for neural coding are poorly understood. Here we analyse the functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses,. The model, with parameters fit directly to physiological data, simultaneously captures both the stimulus dependence and detailed spatio-temporal correlations in population responses, and provides two insights into the structure of the neural code. First, neural encoding at the population level is less noisy than one would expect from the variability of individual neurons: spike times are more precise, and can be predicted more accurately when the spiking of neighbouring neurons is taken into account. Second, correlations provide additional sensory information: optimal, model-based decoding that exploits the response correlation structure extracts 20\% more information about the visual scene than decoding under the assumption of independence, and preserves 40\% more visual information than optimal linear decoding. This model-based approach reveals the role of correlated activity in the retinal coding of visual stimuli, and provides a general framework for understanding the importance of correlated activity in populations of neurons.},
	number = {7207},
	urldate = {2022-03-24},
	journal = {Nature},
	author = {Pillow, Jonathan W. and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M. and Chichilnisky, E. J. and Simoncelli, Eero P.},
	month = aug,
	year = {2008},
	pmcid = {PMC2684455},
	pmid = {18650810},
	note = {tex.ids= Pillow2008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {995--999},
	file = {Version acceptée:/Users/laurentperrinet/Zotero/storage/9C3CT944/Pillow et al. - 2008 - Spatio-temporal correlations and visual signalling.pdf:application/pdf;Version acceptée:/Users/laurentperrinet/Zotero/storage/82SYR3KL/Pillow et al. - 2008 - Spatio-temporal correlations and visual signalling.pdf:application/pdf},
}

@article{Ii2022,
	title = {Spike {Trains} of {Retinal} {Ganglion} {Cells} {Viewing} a {Repeated} {Natural} {Movie}},
	url = {https://dataspace.princeton.edu/handle/88435/dsp015425kd84r},
	doi = {10.34770/V0V4-3H52},
	abstract = {This archive contains spike trains simultaneously recorded from ganglion cells in the tiger salamander retina with a multi-electrode array while viewing a repeated natural movie clip.  These data have been analyzed in previous papers, notably Puchalla et al. Neuron 2005 and Schneidman et al. Nature 2006.},
	language = {en\_US},
	urldate = {2022-03-21},
	author = {Ii, Berry and J, Michael},
	month = mar,
	year = {2022},
	note = {Accepted: 2022-03-08T20:25:34Z
tex.ids= Berry2022
publisher: Princeton University
type: dataset},
	keywords = {⛔ No INSPIRE recid found},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/W3PDITAC/dsp015425kd84r.html:text/html},
}

@article{Guise2014,
	title = {A {Bayesian} {Model} of {Polychronicity}},
	volume = {26},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/26/9/2052-2073/8000},
	doi = {10/f6chbq},
	abstract = {A significant feature of spiking neural networks with varying connection delays, such as those in the brain, is the existence of strongly connected groups of neurons known as polychronous neural groups (PNGs). Polychronous groups are found in large numbers in these networks and are proposed by Izhikevich ( 2006a ) to provide a neural basis for representation and memory. When exposed to a familiar stimulus, spiking neural networks produce consistencies in the spiking output data that are the hallmarks of PNG activation. Previous methods for studying the PNG activation response to stimuli have been limited by the template-based methods used to identify PNG activation. In this letter, we outline a new method that overcomes these difficulties by establishing for the first time a probabilistic interpretation of PNG activation. We then demonstrate the use of this method by investigating the claim that PNGs might provide the foundation of a representational system.},
	language = {en},
	number = {9},
	urldate = {2021-11-26},
	journal = {Neural Computation},
	author = {Guise, Mira and Knott, Alistair and Benuskova, Lubica},
	month = sep,
	year = {2014},
	note = {00000
tex.ids= Guise2014, guise2014bayesian
publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {2052--2073},
	file = {Guise et al. - 2014 - A Bayesian Model of Polychronicity.pdf:/Users/laurentperrinet/Zotero/storage/H57S96CE/Guise et al. - 2014 - A Bayesian Model of Polychronicity.pdf:application/pdf},
}

@article{Grimaldi2022,
	title = {A robust event-driven approach to always-on object recognition},
	url = {https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1},
	doi = {10/gn62xd},
	abstract = {We propose a neuromimetic architecture able to perform always-on pattern recognition. To achieve this, we extended an existing event-based algorithm [1], which introduced novel spatio-temporal features as a Hierarchy Of Time-Surfaces (HOTS). Built from asynchronous events acquired by a neuromorphic camera, these time surfaces allow to code the local dynamics of a visual scene and to create an efficient event-based pattern recognition architecture. Inspired by neuroscience, we extended this method to increase its performance. Our first contribution was to add a homeostatic gain control on the activity of neurons to improve the learning of spatio-temporal patterns [2]. A second contribution is to draw an analogy between the HOTS algorithm and Spiking Neural Networks (SNN). Following that analogy, our last contribution is to modify the classification layer and remodel the offline pattern categorization method previously used into an online and event-driven one. This classifier uses the spiking output of the network to define novel time surfaces and we then perform online classification with a neuromimetic implementation of a multinomial logistic regression. Not only do these improvements increase consistently the performances of the network, they also make this event-driven pattern recognition algorithm online and bio-realistic. Results were validated on different datasets: DVS barrel [3], Poker-DVS [4] and N-MNIST [5]. We foresee to develop the SNN version of the method and to extend this fully event-driven approach to more naturalistic tasks, notably for always-on, ultra-fast object categorization.},
	language = {en},
	urldate = {2022-01-13},
	author = {Grimaldi, Antoine and Boutin, Victor and Ieng, Sio-Hoi and Benosman, Ryad and Perrinet, Laurent},
	month = jan,
	year = {2022},
	note = {00000
tex.ids= Grimaldi2022a, Grimaldi22pami
tex.bdsk-url-2: https://doi.org/10.36227/techrxiv.18003077.v1
tex.date-modified: 2022-01-20 09:10:37 +0100
tex.grants: aprovis3D
publisher: TechRxiv
url: https://www.techrxiv.org/articles/preprint/A\_robust\_event-driven\_approach\_to\_always-on\_object\_recognition/18003077/1},
	keywords = {⛔ No INSPIRE recid found, efficient coding, event-based vision, homeostasis, neuromorphic hardware, online classification},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/4Q9P5YTG/Grimaldi et al. - 2022 - A robust event-driven approach to always-on object.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/RR4VUC42/1.html:text/html},
}

@article{Haimerl2019,
	title = {Internal representation of hippocampal neuronal population spans a time-distance continuum},
	volume = {116},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/15/7477},
	doi = {10/ghpbm3},
	abstract = {The hippocampus plays a critical role in episodic memory: the sequential representation of visited places and experienced events. This function is mirrored by hippocampal activity that self organizes into sequences of neuronal activation that integrate spatiotemporal information. What are the underlying mechanisms of such integration is still unknown. Single cell activity was recently shown to combine time and distance information; however, it remains unknown whether a degree of tuning between space and time can be defined at the network level. Here, combining daily calcium imaging of CA1 sequence dynamics in running head-fixed mice and network modeling, we show that CA1 network activity tends to represent a specific combination of space and time at any given moment, and that the degree of tuning can shift within a continuum from 1 day to the next. Our computational model shows that this shift in tuning can happen under the control of the external drive power. We propose that extrinsic global inputs shape the nature of spatiotemporal integration in the hippocampus at the population level depending on the task at hand, a hypothesis which may guide future experimental studies.},
	language = {en},
	number = {15},
	urldate = {2022-01-17},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Haimerl, Caroline and Angulo-Garcia, David and Villette, Vincent and Reichinnek, Susanne and Torcini, Alessandro and Cossart, Rosa and Malvache, Arnaud},
	month = apr,
	year = {2019},
	pmid = {30910984},
	note = {00012
tex.ids= Haimerl2019a
publisher: National Academy of Sciences
section: Biological Sciences},
	keywords = {⛔ No INSPIRE recid found, attractor network, hippocampus, neural model, space representation, time representation},
	pages = {7477--7482},
	file = {475095v1.full.pdf:/Users/laurentperrinet/Zotero/storage/ETP4F9N2/475095v1.full.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/276KB86B/Haimerl et al. - 2019 - Internal representation of hippocampal neuronal po.pdf:application/pdf;Haimerl et al. - 2019 - Internal representation of hippocampal neuronal population spans a time-distance continuum.pdf:/Users/laurentperrinet/Zotero/storage/XV2G9MFX/Haimerl et al. - 2019 - Internal representation of hippocampal neuronal population spans a time-distance continuum.pdf:application/pdf;Haimerl et al. - 2019 - Internal representation of hippocampal neuronal population spans a time-distance continuum.pdf:/Users/laurentperrinet/Zotero/storage/7CVS4IDT/Haimerl et al. - 2019 - Internal representation of hippocampal neuronal population spans a time-distance continuum.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/S2ELPGQ4/7477.html:text/html},
}

@article{Davis2021,
	title = {Spontaneous traveling waves naturally emerge from horizontal fiber time delays and travel through locally asynchronous-irregular states},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-021-26175-1},
	doi = {10/gm79hh},
	abstract = {Studies of sensory-evoked neuronal responses often focus on mean spike rates, with fluctuations treated as internally-generated noise. However, fluctuations of spontaneous activity, often organized as traveling waves, shape stimulus-evoked responses and perceptual sensitivity. The mechanisms underlying these waves are unknown. Further, it is unclear whether waves are consistent with the low rate and weakly correlated “asynchronous-irregular” dynamics observed in cortical recordings. Here, we describe a large-scale computational model with topographically-organized connectivity and conduction delays relevant to biological scales. We find that spontaneous traveling waves are a general property of these networks. The traveling waves that occur in the model are sparse, with only a small fraction of neurons participating in any individual wave. Consequently, they do not induce measurable spike correlations and remain consistent with locally asynchronous irregular states. Further, by modulating local network state, they can shape responses to incoming inputs as observed in vivo.},
	language = {en},
	number = {1},
	urldate = {2021-10-26},
	journal = {Nature Communications},
	author = {Davis, Zachary W. and Benigno, Gabriel B. and Fletterman, Charlee and Desbordes, Theo and Steward, Christopher and Sejnowski, Terrence J. and H. Reynolds, John and Muller, Lyle},
	month = oct,
	year = {2021},
	note = {00000 
Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Primary\_atype: Research
Subject\_term: Extrastriate cortex;Network models;Sensory processing
Subject\_term\_id: extrastriate-cortex;network-models;sensory-processing
tex.ids= Davis2021, davis2021spontaneous
number: 1
publisher: Nature Publishing Group},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {6057},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/T4ZQ6Y6F/Davis et al. - 2021 - Spontaneous traveling waves naturally emerge from .pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/7RR2JYR3/s41467-021-26175-1.html:text/html},
}

@article{Perrinet2004c,
	title = {Coding {Static} {Natural} {Images} {Using} {Spiking} {Event} {Times}: {Do} {Neurons} {Cooperate}?},
	volume = {15},
	copyright = {All rights reserved},
	issn = {1045-9227},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15484892 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1333080},
	doi = {10.1109/TNN.2004.833303},
	abstract = {To understand possible strategies of temporal spike coding in the central nervous system, we study functional neuromimetic models of visual processing for static images. We will first present the retinal model which was introduced by Van Rullen and Thorpe and which represents the multiscale contrast values of the image using an orthonormal wavelet transform. These analog values activate a set of spiking neurons which each fire once to produce an asynchronous wave of spikes. According to this model, the image may be progressively reconstructed from this spike wave thanks to regularities in the statistics of the coefficients determined with natural images. Here, we study mathematically how the quality of information transmission carried by this temporal representation varies over time. In particular, we study how these regularities can be used to optimize information transmission by using a form of temporal cooperation of neurons to code analog values. The original model used wavelet transforms that are close to orthogonal. However, the selectivity of realistic neurons overlap, and we propose an extension of the previous model by adding a spatial cooperation between filters. This model extends the previous scheme for arbitrary–and possibly nonorthogonal–representations of features in the images. In particular, we compared the performance of increasingly over-complete representations in the retina. Results show that this algorithm provides an efficient spike coding strategy for low-level visual processing which may adapt to the complexity of the visual input.},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Perrinet, Laurent and Samuelides, Manuel and Thorpe, Simon},
	month = sep,
	year = {2004},
	pmid = {15484892},
	note = {tex.ids= Perrinet03ieee, Perrinet04a, Perrinet2004c, perrinet2004coding
tex.date-modified: 2019-09-02 15:45:35 +0200
tex.eprint: 15484892
tex.eprinttype: pmid
tex.preprint: https://arxiv.org/abs/q-bio/0611002
publisher: IEEE},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Action potentials, Algorithms, and, Animals, association field, assofield, asynchronous, bicv-sparse, Biologically Inspired Computer vision, Biomembranes, Central nervous system, coding, computing, Contrast Sensitivity, Filters, Fires, Humans, Image coding, Image reconstruction, images, matching, matching pursuit, matching-pursuit, Models, natural, natural-scenes, Neurological, neuronal, Neurons, Neurons: physiology, Ocular, Ocular: physiology, over-complete, parallel, parallel-processing, processing, pursuit, Reaction Time, Reaction Time: physiology, representation, Retina, Retina: physiology, sparse coding, sparse hebbian learning, spike, statistics, Statistics, statistics of natural images, Synaptic Transmission, Synaptic Transmission: physiology, temporal, Time Factors, Time Perception, Time Perception: physiology, ultra-rapid, vision, Vision, Visual Cortex, Visual Cortex: physiology, Visual Pathways, Visual Pathways: physiology, Visual Perception, Visual Perception: physiology, Wavelet transforms},
	pages = {1164--75},
	annote = {Publisher: IEEE},
	annote = {Publisher: IEEE},
	annote = {Publisher: IEEE},
	annote = {Special issue on 'Temporal Coding for Neural Information Processing'},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/3V3DILND/Perrinet, Samuelides, Thorpe - 2004 - Coding Static Natural Images Using Spiking Event Times Do Neurons Cooperate(2).pdf:application/pdf;Version soumise:/Users/laurentperrinet/Zotero/storage/QEGMZMKH/Perrinet et al. - 2004 - Coding static natural images using spiking event t.pdf:application/pdf},
}

@article{Gutig2006,
	title = {The tempotron: a neuron that learns spike timing–based decisions},
	volume = {9},
	issn = {1546-1726},
	shorttitle = {The tempotron},
	url = {http://www.nature.com/articles/nn1643/},
	doi = {10/ch29r4},
	abstract = {The timing of action potentials in sensory neurons contains substantial information about the eliciting stimuli. Although the computational advantages of spike timing–based neuronal codes have long been recognized, it is unclear whether, and if so how, neurons can learn to read out such representations. We propose a new, biologically plausible supervised synaptic learning rule that enables neurons to efficiently learn a broad range of decision rules, even when information is embedded in the spatiotemporal structure of spike patterns rather than in mean firing rates. The number of categorizations of random spatiotemporal patterns that a neuron can implement is several times larger than the number of its synapses. The underlying nonlinear temporal computation allows neurons to access information beyond single-neuron statistics and to discriminate between inputs on the basis of multineuronal spike statistics. Our work demonstrates the high capacity of neural systems to learn to decode information embedded in distributed patterns of spike synchrony.},
	language = {en},
	number = {3},
	urldate = {2022-01-31},
	journal = {Nature Neuroscience},
	author = {Gütig, Robert and Sompolinsky, Haim},
	month = mar,
	year = {2006},
	note = {00716
tex.ids= Gutig2006a, gutig2006tempotron
number: 3
publisher: Nature Publishing Group},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {420--428},
	annote = {00716},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/E9LYJ2C6/Gütig and Sompolinsky - 2006 - The tempotron a neuron that learns spike timing–b.pdf:application/pdf;nn1643:/Users/laurentperrinet/Zotero/storage/RU5GTAK4/nn1643.html:text/html;Snapshot:/Users/laurentperrinet/Zotero/storage/ZZ79YMPB/nn1643.html:text/html;Snapshot:/Users/laurentperrinet/Zotero/storage/494JTWUU/nn1643.html:text/html},
}

@article{Gollisch2008,
	title = {Rapid {Neural} {Coding} in the {Retina} with {Relative} {Spike} {Latencies}},
	copyright = {American Association for the Advancement of Science},
	url = {https://www.science.org/doi/abs/10.1126/science.1149639},
	doi = {10.1126/science.1149639},
	abstract = {Natural vision is a highly dynamic process. Frequent body, head, and eye movements constantly bring new images onto the retina for brief periods, challenging our understanding of the neural code for vision. We report that certain retinal ganglion ...},
	language = {EN},
	urldate = {2022-01-05},
	journal = {Science},
	author = {Gollisch, Tim and Meister, Markus},
	month = feb,
	year = {2008},
	note = {00627
tex.ids= Gollisch2008, Gollisch:2008jv, gollisch2008rapid
publisher: American Association for the Advancement of Science},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
}

@article{Pastalkova2008,
	title = {Internally {Generated} {Cell} {Assembly} {Sequences} in the {Rat} {Hippocampus}},
	volume = {321},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570043/},
	doi = {10.1126/science.1159775},
	abstract = {A longstanding conjecture in neuroscience is that aspects of cognition depend on the brain's ability to self-generate sequential neuronal activity. We found that reliably and continually-changing cell assemblies in the rat hippocampus appeared not only during spatial navigation but also in the absence of changing environmental or body-derived inputs. During the delay period of a memory task each moment in time was characterized by the activity of a unique assembly of neurons. Identical initial conditions triggered a similar assembly sequence, whereas different conditions gave rise, uniquely, to different sequences, thereby predicting behavioral choices, including errors. Such sequences were not formed in control, non-memory, tasks. We hypothesize that neuronal representations, evolved for encoding distance in spatial navigation, also support episodic recall and the planning of action sequences.},
	number = {5894},
	urldate = {2022-02-23},
	journal = {Science (New York, N.Y.)},
	author = {Pastalkova, Eva and Itskov, Vladimir and Amarasingham, Asohan and Buzsáki, György},
	month = sep,
	year = {2008},
	pmcid = {PMC2570043},
	pmid = {18772431},
	note = {tex.ids= Pastalkova2008a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1322--1327},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/BLDU3X5N/Pastalkova et al. - 2008 - Internally Generated Cell Assembly Sequences in th.pdf:application/pdf;PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/BM7SDLNQ/Pastalkova et al. - 2008 - Internally Generated Cell Assembly Sequences in th.pdf:application/pdf},
}

@article{Luczak2007,
	title = {Sequential structure of neocortical spontaneous activity in vivo},
	volume = {104},
	copyright = {© 2006 by The National Academy of Sciences of the USA},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/104/1/347},
	doi = {10.1073/pnas.0605643104},
	abstract = {Even in the absence of sensory stimulation, the neocortex shows complex spontaneous activity patterns, often consisting of alternating “DOWN” states of generalized neural silence and “UP” states of massive, persistent network activity. To investigate how this spontaneous activity propagates through neuronal assemblies in vivo, we simultaneously recorded populations of 50–200 cortical neurons in layer V of anesthetized and awake rats. Each neuron displayed a virtually unique spike pattern during UP states, with diversity seen amongst both putative pyramidal cells and interneurons, reflecting a complex but stereotypically organized sequential spread of activation through local cortical networks. Spike timing was most precise during the first ≈100 ms after UP state onset, and decayed as UP states progressed. A subset of UP states propagated as traveling waves, but waves passing a given point in either direction initiated similar local sequences, suggesting local networks as the substrate of sequential firing patterns. A search for repeating motifs indicated that their occurrence and structure was predictable from neurons' individual latencies to UP state onset. We suggest that these stereotyped patterns arise from the interplay of intrinsic cellular conductances and local circuit properties.},
	language = {en},
	number = {1},
	urldate = {2022-02-23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Luczak, Artur and Barthó, Peter and Marguet, Stephan L. and Buzsáki, György and Harris, Kenneth D.},
	month = jan,
	year = {2007},
	pmid = {17185420},
	note = {tex.ids= Luczak2007a
publisher: National Academy of Sciences
section: Biological Sciences},
	keywords = {⛔ No INSPIRE recid found, microcircuits, neuronal assembly, repeating sequences, slow oscillations, syntire chains},
	pages = {347--352},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/EVEAWBEB/Luczak et al. - 2007 - Sequential structure of neocortical spontaneous ac.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/YMUFLVRA/Luczak et al. - 2007 - Sequential structure of neocortical spontaneous ac.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/39BR3K46/347.html:text/html},
}

@article{Buzsaki2018,
	title = {Space and time: {The} hippocampus as a sequence generator},
	volume = {22},
	issn = {1364-6613},
	shorttitle = {Space and time},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6166479/},
	doi = {10.1016/j.tics.2018.07.006},
	abstract = {Neural computations are often compared to instrument-measured distance or duration, and such relationships are interpreted by a human observer. However, neural circuits do not depend on human-made instruments but perform computations relative to an internally defined rate-of-change. While neuronal correlations with external measures, such as distance or duration, can be observed in spike rates or other measures of neuronal activity, what matters for the brain is how such activity patterns are utilized by downstream neural observers. We suggest that hippocampal operations can be described by sequential activity of neuronal assemblies and their internally defined rate of change without resorting to the concept of space or time.},
	number = {10},
	urldate = {2022-02-23},
	journal = {Trends in cognitive sciences},
	author = {Buzsáki, Gyӧrgy and Tingley, David},
	month = oct,
	year = {2018},
	pmcid = {PMC6166479},
	pmid = {30266146},
	note = {tex.ids= Buzsaki2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {853--869},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/RPGGBZ44/Buzsáki et Tingley - 2018 - Space and time The hippocampus as a sequence gene.pdf:application/pdf;Version acceptée:/Users/laurentperrinet/Zotero/storage/UKYPMKPA/Buzsáki et Tingley - 2018 - Space and Time The Hippocampus as a Sequence Gene.pdf:application/pdf},
}

@misc{Nadafian2020,
	title = {Bio-plausible {Unsupervised} {Delay} {Learning} for {Extracting} {Temporal} {Features} in {Spiking} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2011.09380},
	abstract = {The plasticity of the conduction delay between neurons plays a fundamental role in learning. However, the exact underlying mechanisms in the brain for this modulation is still an open problem. Understanding the precise adjustment of synaptic delays could help us in developing effective brain-inspired computational models in providing aligned insights with the experimental evidence. In this paper, we propose an unsupervised biologically plausible learning rule for adjusting the synaptic delays in spiking neural networks. Then, we provided some mathematical proofs to show that our learning rule gives a neuron the ability to learn repeating spatio-temporal patterns. Furthermore, the experimental results of applying an STDP-based spiking neural network equipped with our proposed delay learning rule on Random Dot Kinematogram indicate the efficacy of the proposed delay learning rule in extracting temporal features.},
	urldate = {2021-04-06},
	author = {Nadafian, Alireza and Ganjtabesh, Mohammad},
	month = nov,
	year = {2020},
	note = {00000
tex.ids= Nadafian2020
arXiv: 2011.09380
rights: http://arxiv.org/licenses/nonexclusive-distrib/1.0/},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/ZFD8DBSX/Nadafian et Ganjtabesh - 2020 - Bio-plausible Unsupervised Delay Learning for Extr.pdf:application/pdf;arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/JBQCECGT/Nadafian et Ganjtabesh - 2020 - Bio-plausible Unsupervised Delay Learning for Extr.pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/378MJ7JF/2011.html:text/html},
}

@article{Hazan2018,
	title = {{BindsNET}: {A} machine learning-oriented spiking neural networks library in {Python}},
	shorttitle = {{BindsNET}},
	url = {http://arxiv.org/abs/1806.01423},
	abstract = {The development of spiking neural network simulation software is a critical component enabling the modeling of neural systems and the development of biologically inspired algorithms. Existing software frameworks support a wide range of neural functionality, software abstraction levels, and hardware devices, yet are typically not suitable for rapid prototyping or application to problems in the domain of machine learning. In this paper, we describe a new Python package for the simulation of spiking neural networks, speciﬁcally geared towards machine learning and reinforcement learning. Our software, called BindsNET, enables rapid building and simulation of spiking networks and features user-friendly, concise syntax. BindsNET is built on top of the PyTorch deep neural networks library, enabling fast CPU and GPU computation for large spiking networks. The BindsNET framework can be adjusted to meet the needs of other existing computing and hardware environments, e.g., TensorFlow. We also provide an interface into the OpenAI gym library, allowing for training and evaluation of spiking networks on reinforcement learning problems. We argue that this package facilitates the use of spiking networks for large-scale machine learning experimentation, and show some simple examples of how we envision BindsNET can be used in practice.},
	language = {en},
	urldate = {2018-06-09},
	journal = {arXiv:1806.01423 [cs, q-bio]},
	author = {Hazan, Hananel and Saunders, Daniel J. and Khan, Hassaan and Sanghavi, Darpan T. and Siegelmann, Hava T. and Kozma, Robert},
	month = jun,
	year = {2018},
	note = {00000 
arXiv: 1806.01423},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Neural and Evolutionary Computing, GPU-computing, Machine Laerning, Python (programming language), PyTorch, Quantitative Biology - Neurons and Cognition, reinforcement learning (RL)., Spiking Neural Networks (SNN)},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/8Q363J6K/Hazan et al. - 2018 - BindsNET A Machine Learning-Oriented Spiking Neur.pdf:application/pdf;Hazan et al. - 2018 - BindsNET A machine learning-oriented spiking neur.pdf:/Users/laurentperrinet/Zotero/storage/XPDDFZX3/Hazan et al. - 2018 - BindsNET A machine learning-oriented spiking neur.pdf:application/pdf},
}

@article{Warner2022,
	title = {A probabilistic latent variable model for detecting structure in binary data},
	url = {http://arxiv.org/abs/2201.11108},
	abstract = {We introduce a novel, probabilistic binary latent variable model to detect noisy or approximate repeats of patterns in sparse binary data. The model is based on the ”Noisy-OR model” [5], used previously for disease and topic modelling. The model’s capability is demonstrated by extracting structure in recordings from retinal neurons, but it can be widely applied to discover and model latent structure in noisy binary data. In the context of spiking neural data, the task is to “explain” spikes of individual neurons in terms of groups of neurons, ”Cell Assemblies” (CAs), that often fire together, due to mutual interactions or other causes. The model infers sparse activity in a set of binary latent variables, each describing the activity of a cell assembly. When the latent variable of a cell assembly is active, it reduces the probabilities of neurons belonging to this assembly to be inactive. The conditional probability kernels of the latent components are learned from the data in an expectation maximization scheme, involving inference of latent states and parameter adjustments to the model. We thoroughly validate the model on synthesized spike trains constructed to statistically resemble recorded retinal responses to white noise stimulus and natural movie stimulus in data. We also apply our model to spiking responses recorded in retinal ganglion cells (RGCs) during stimulation with a movie and discuss the found structure.},
	language = {en},
	urldate = {2022-02-02},
	journal = {arXiv:2201.11108 [cs, q-bio, stat]},
	author = {Warner, Christopher and Ruda, Kiersten and Sommer, Friedrich T.},
	month = jan,
	year = {2022},
	note = {00000
tex.ids= Warner2022
arXiv: 2201.11108},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Machine Learning, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
	annote = {arXiv: 2201.11108},
	annote = {arXiv: 2201.11108},
	annote = {Comment: 25 pages, 20 figures},
	annote = {Comment: 25 pages, 20 figures},
	file = {Warner et al. - 2022 - A probabilistic latent variable model for detectin.pdf:/Users/laurentperrinet/Zotero/storage/6WNA579D/Warner et al. - 2022 - A probabilistic latent variable model for detectin.pdf:application/pdf;Warner et al. - 2022 - A probabilistic latent variable model for detectin.pdf:/Users/laurentperrinet/Zotero/storage/AFZEY7Y3/Warner et al. - 2022 - A probabilistic latent variable model for detectin.pdf:application/pdf},
}

@article{Grun2002,
	title = {Unitary {Events} in {Multiple} {Single}-{Neuron} {Spiking} {Activity}: {II}. {Nonstationary} {Data}},
	volume = {14},
	issn = {0899-7667, 1530-888X},
	shorttitle = {Unitary {Events} in {Multiple} {Single}-{Neuron} {Spiking} {Activity}},
	url = {https://direct.mit.edu/neco/article/14/1/81-119/6573},
	doi = {10.1162/089976602753284464},
	abstract = {In order to detect members of a functional group (cell assembly) in simultaneously recorded neuronal spiking activity, we adopted the widely used operational definition that membership in a common assembly is expressed in near-simultaneous spike activity. Unitary event analysis, a statistical method to detect the significant occurrence of coincident spiking activity in stationary data, was recently developed (see the companion article in this issue). The technique for the detection of unitary events is based on the assumption that the underlying processes are stationary in time. This requirement, however, is usually not fulfilled in neuronal data. Here we describe a method that properly normalizes for changes of rate: the unitary events by moving window analysis (UEMWA). Analysis for unitary events is performed separately in overlapping time segments by sliding a window of constant width along the data. In each window, stationarity is assumed. Performance and sensitivity are demonstrated by use of simulated spike trains of independently firing neurons, into which coincident events are inserted. If cortical neurons organize dynamically into functional groups, the occurrence of near-simultaneous spike activity should be time varying and related to behavior and stimuli. UEMWA also accounts for these potentially interesting nonstationarities and allows locating them in time. The potential of the new method is illustrated by results from multiple single-unit recordings from frontal and motor cortical areas in awake, behaving monkey.},
	language = {en},
	number = {1},
	urldate = {2022-07-21},
	journal = {Neural Computation},
	author = {Grün, Sonja and Diesmann, Markus and Aertsen, Ad},
	month = jan,
	year = {2002},
	pmid = {11747535},
	note = {tex.ids= Grun02a, Grun2002a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {81--119},
	file = {Grün et al. - 2002 - Unitary Events in Multiple Single-Neuron Spiking A.pdf:/Users/laurentperrinet/Zotero/storage/7GY5TTUJ/Grün et al. - 2002 - Unitary Events in Multiple Single-Neuron Spiking A.pdf:application/pdf},
}

@article{Grun2002a,
	title = {Unitary events in multiple single-neuron spiking activity: {I}. {Detection} and significance},
	volume = {14},
	issn = {0899-7667},
	shorttitle = {Unitary events in multiple single-neuron spiking activity},
	doi = {10.1162/089976602753284455},
	abstract = {It has been proposed that cortical neurons organize dynamically into functional groups (cell assemblies) by the temporal structure of their joint spiking activity. Here, we describe a novel method to detect conspicuous patterns of coincident joint spike activity among simultaneously recorded single neurons. The statistical significance of these unitary events of coincident joint spike activity is evaluated by the joint-surprise. The method is tested and calibrated on the basis of simulated, stationary spike trains of independently firing neurons, into which coincident joint spike events were inserted under controlled conditions. The sensitivity and specificity of the method are investigated for their dependence on physiological parameters (firing rate, coincidence precision, coincidence pattern complexity) and temporal resolution of the analysis. In the companion article in this issue, we describe an extension of the method, designed to deal with nonstationary firing rates.},
	language = {eng},
	number = {1},
	journal = {Neural Computation},
	author = {Grün, Sonja and Diesmann, Markus and Aertsen, Ad},
	month = jan,
	year = {2002},
	pmid = {11747534},
	note = {tex.ids= Grun2002},
	keywords = {⛔ No INSPIRE recid found},
	pages = {43--80},
}

@article{Pipa2008,
	title = {{NeuroXidence}: reliable and efficient analysis of an excess or deficiency of joint-spike events},
	volume = {25},
	issn = {1573-6873},
	shorttitle = {{NeuroXidence}},
	url = {https://doi.org/10.1007/s10827-007-0065-3},
	doi = {10.1007/s10827-007-0065-3},
	abstract = {We present a non-parametric and computationally efficient method named NeuroXidence that detects coordinated firing of two or more neurons and tests whether the observed level of coordinated firing is significantly different from that expected by chance. The method considers the full auto-structure of the data, including the changes in the rate responses and the history dependencies in the spiking activity. Also, the method accounts for trial-by-trial variability in the dataset, such as the variability of the rate responses and their latencies. NeuroXidence can be applied to short data windows lasting only tens of milliseconds, which enables the tracking of transient neuronal states correlated to information processing. We demonstrate, on both simulated data and single-unit activity recorded in cat visual cortex, that NeuroXidence discriminates reliably between significant and spurious events that occur by chance.},
	language = {en},
	number = {1},
	urldate = {2022-07-21},
	journal = {Journal of Computational Neuroscience},
	author = {Pipa, Gordon and Wheeler, Diek W. and Singer, Wolf and Nikolić, Danko},
	month = aug,
	year = {2008},
	note = {tex.ids= Pipa2008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {64--88},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/KAHAYGL5/Pipa et al. - 2008 - NeuroXidence reliable and efficient analysis of a.pdf:application/pdf},
}

@article{Linden2022,
	title = {Movement is governed by rotational population dynamics in spinal motor networks},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.31.458405v3},
	doi = {10.1101/2021.08.31.458405},
	abstract = {Although the generation of movements is a fundamental function of the nervous system, the underlying neural principles remain unclear. Since flexor- and extensor-muscles alternate during rhythmic movements like walking, it is often assumed that the responsible neural circuitry is similarly displaying alternating activity. Here, we present ensemble-recordings of neurons in the lumbar spinal cord that indicate that, rather than alternating, the population is performing a low-dimensional “rotation” in neural space, in which the neural activity is cycling through all phases continuously during the rhythmic behavior. The radius of rotation correlates with the intended muscle force and a perturbation of the low-dimensional trajectory can modify the motor behavior. Since existing models of spinal motor control offer an inadequate explanation of rotation, we propose a new theory of neural generation of movements from which this and other unresolved issues, such as speed regulation, force control, and multi-functionalism, are readily explained.},
	language = {en},
	urldate = {2022-07-12},
	author = {Lindén, Henrik and Petersen, Peter C. and Vestergaard, Mikkel and Berg, Rune W.},
	month = mar,
	year = {2022},
	note = {Pages: 2021.08.31.458405
tex.ids= Linden2021
section: New Results},
	keywords = {⛔ No INSPIRE recid found},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/ZHG9MNH4/Lindén et al. - 2022 - Movement is governed by rotational population dyna.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/QIPA6D54/2021.08.31.html:text/html},
}

@inproceedings{State2019,
	address = {Cham},
	title = {Training {Delays} in {Spiking} {Neural} {Networks}},
	volume = {11727},
	isbn = {978-3-030-30486-7 978-3-030-30487-4},
	url = {http://link.springer.com/10.1007/978-3-030-30487-4_54},
	language = {en},
	urldate = {2022-06-27},
	booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2019: {Theoretical} {Neural} {Computation}},
	publisher = {Springer International Publishing},
	author = {State, Laura and Vilimelis Aceituno, Pau},
	editor = {Tetko, Igor V. and Kůrková, Věra and Karpov, Pavel and Theis, Fabian},
	year = {2019},
	doi = {10.1007/978-3-030-30487-4_54},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {713--717},
	file = {State et Vilimelis Aceituno - 2019 - Training Delays in Spiking Neural Networks.pdf:/Users/laurentperrinet/Zotero/storage/GRBQTKI3/State et Vilimelis Aceituno - 2019 - Training Delays in Spiking Neural Networks.pdf:application/pdf},
}

@article{Tavanaei2018,
	title = {Representation learning using event-based {STDP}},
	volume = {105},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608018301801},
	doi = {10.1016/j.neunet.2018.05.018},
	abstract = {Although representation learning methods developed within the framework of traditional neural networks are relatively mature, developing a spiking representation model remains a challenging problem. This paper proposes an event-based method to train a feedforward spiking neural network (SNN) layer for extracting visual features. The method introduces a novel spike-timing-dependent plasticity (STDP) learning rule and a threshold adjustment rule both derived from a vector quantization-like objective function subject to a sparsity constraint. The STDP rule is obtained by the gradient of a vector quantization criterion that is converted to spike-based, spatio-temporally local update rules in a spiking network of leaky, integrate-and-fire (LIF) neurons. Independence and sparsity of the model are achieved by the threshold adjustment rule and by a softmax function implementing inhibition in the representation layer consisting of WTA-thresholded spiking neurons. Together, these mechanisms implement a form of spike-based, competitive learning. Two sets of experiments are performed on the MNIST and natural image datasets. The results demonstrate a sparse spiking visual representation model with low reconstruction loss comparable with state-of-the-art visual coding approaches, yet our rule is local in both time and space, thus biologically plausible and hardware friendly.},
	language = {en},
	urldate = {2022-05-13},
	journal = {Neural Networks},
	author = {Tavanaei, Amirhossein and Masquelier, Timothée and Maida, Anthony},
	month = sep,
	year = {2018},
	note = {tex.ids= Tavanaei2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {294--303},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/N783MHNA/Tavanaei et al. - 2018 - Representation learning using event-based STDP.pdf:application/pdf;ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/WWYAAJLM/S0893608018301801.html:text/html},
}

@article{Rasetto2022,
	title = {The {Challenges} {Ahead} for {Bio}-inspired {Neuromorphic} {Event} {Processors}: {How} {Memristors} {Dynamic} {Properties} {Could} {Revolutionize} {Machine} {Learning}},
	shorttitle = {The {Challenges} {Ahead} for {Bio}-inspired {Neuromorphic} {Event} {Processors}},
	url = {http://arxiv.org/abs/2201.12673},
	abstract = {Neuromorphic engineering has led to the necessary process of rethinking of how we process and integrate information, analyze data, and use the resulting insights to improve computation and avoid the current high power and latency of Artiﬁcial Intelligence (AI) hardware. Current neuromorphic processors are, however, limited by digital technologies, which cannot reproduce the abilities of biological neural computation in terms of power, latency and area cost. In this paper, we show that the combined use of the dynamic properties of memristors to implement a model of synaptic integration and the determination of the correct level of abstraction of biological neural networks has the potential to open a new range of capabilities for neuromorphic processors. We test this approach using a novel three-terminal LixWO3 electrochemical memristor, by deriving its conductance model and using it to emulate synaptic temporal kernel computation in the context of a pattern recognition task. We show that these devices allow for robust results with no loss in precision while opening the path for an energy efﬁcient approach to build novel bio-inspired processing units in silicon.},
	language = {en},
	urldate = {2022-02-02},
	journal = {arXiv:2201.12673 [cs]},
	author = {Rasetto, Marco and Wan, Qingzhou and Akolkar, Himanshu and Shi, Bertram and Xiong, Feng and Benosman, Ryad},
	month = jan,
	year = {2022},
	note = {00000
tex.ids= Rasetto2022
arXiv: 2201.12673
rights: http://creativecommons.org/licenses/by/4.0/},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found, Computer Science - Emerging Technologies},
	annote = {00000},
	annote = {arXiv: 2201.12673 [cs]},
	file = {Rasetto et al. - 2022 - The Challenges Ahead for Bio-inspired Neuromorphic:/Users/laurentperrinet/Zotero/storage/D68CGUMX/Rasetto et al. - 2022 - The Challenges Ahead for Bio-inspired Neuromorphic.pdf:application/pdf;Rasetto et al. - 2022 - The Challenges Ahead for Bio-inspired Neuromorphic.pdf:/Users/laurentperrinet/Zotero/storage/QWMUN7LX/Rasetto et al. - 2022 - The Challenges Ahead for Bio-inspired Neuromorphic.pdf:application/pdf;Texte intégral:/Users/laurentperrinet/Zotero/storage/55R3SYI5/Rasetto et al. - 2022 - The Challenges Ahead for Bio-inspired Neuromorphic.pdf:application/pdf},
}

@article{Ghosh2021,
	title = {Synchronization in time-varying networks},
	url = {http://arxiv.org/abs/2109.07618},
	abstract = {Over the past two decades, complex network theory provided the ideal framework for investigating the intimate relationships between the topological properties characterizing the wiring of connections among a system's unitary components and its emergent synchronized functioning. An increased number of setups from the real world found therefore a representation in term of graphs, while more and more sophisticated methods were developed with the aim of furnishing a realistic description of the connectivity patterns under study. In particular, a significant number of systems in physics, biology and social science features a time-varying nature of the interactions among their units. We here give a comprehensive review of the major results obtained by contemporary studies on the emergence of synchronization in time-varying networks. In particular, two paradigmatic frameworks will be described in details. The first encompasses those systems where the time dependence of the nodes' connections is due to adaptation, external forces, or any other process affecting each of the links of the network. The second framework, instead, corresponds to the case in which the structural evolution of the graph is due to the movement of the nodes, or agents, in physical spaces and to the fact that interactions may be ruled by space-dependent laws in a way that connections are continuously switched on and off in the course of the time. Finally, our report ends with a short discussion on promising directions and open problems for future studies.},
	urldate = {2021-09-21},
	journal = {arXiv:2109.07618 [physics]},
	author = {Ghosh, Dibakar and Frasca, Mattia and Rizzo, Alessandro and Majhi, Soumen and Rakshit, Sarbendu and Alfaro-Bittner, Karin and Boccaletti, Stefano},
	month = sep,
	year = {2021},
	note = {00000 
arXiv: 2109.07618},
	keywords = {⛔ No INSPIRE recid found},
	annote = {00000 arXiv: 2109.07618},
	annote = {00000 arXiv: 2109.07618},
	annote = {Comment: 78 pages, 38 figures},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/6S3WVH3R/Ghosh et al. - 2021 - Synchronization in time-varying networks.pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/LZPYNE9F/2109.html:text/html},
}

@article{Perrinet2002b,
	title = {Sparse {Image} {Coding} {Using} an {Asynchronous} {Spiking} {Neural} {Network}},
	copyright = {All rights reserved},
	journal = {Proceedings of ESANN},
	author = {Perrinet, Laurent U and Samuelides, Manuel},
	year = {2002},
	note = {tex.ids: Perrinet02esann
tex.date-modified: 2019-02-22 11:55:28 +0100},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found, area-v1, receptive field, sparse coding},
	pages = {313--318},
}

@techreport{Yin2022,
	title = {{SATA}: {Sparsity}-{Aware} {Training} {Accelerator} for {Spiking} {Neural} {Networks}},
	shorttitle = {{SATA}},
	url = {http://arxiv.org/abs/2204.05422},
	abstract = {Spiking Neural Networks (SNNs) have gained huge attention as a potential energy-efficient alternative to conventional Artificial Neural Networks (ANNs) due to their inherent high-sparsity activation. Recently, SNNs with backpropagation through time (BPTT) have achieved a higher accuracy result on image recognition tasks compared to other SNN training algorithms. Despite the success on the algorithm perspective, prior works neglect the evaluation of the hardware energy overheads of BPTT, due to the lack of a hardware evaluation platform for SNN training algorithm design. Moreover, although SNNs have been long seen as an energy-efficient counterpart of ANNs, a quantitative comparison between the training cost of SNNs and ANNs is missing. To address the above-mentioned issues, in this work, we introduce SATA (Sparsity-Aware Training Accelerator), a BPTT-based training accelerator for SNNs. The proposed SATA provides a simple and re-configurable accelerator architecture for the general-purpose hardware evaluation platform, which makes it easier to analyze the training energy for SNN training algorithms. Based on SATA, we show quantitative analyses on the energy efficiency of SNN training and make a comparison between the training cost of SNNs and ANNs. The results show that SNNs consume \$1.27{\textbackslash}times\$ more total energy with considering sparsity (spikes, gradient of firing function, and gradient of membrane potential) when compared to ANNs. We find that such high training energy cost is from time-repetitive convolution operations and data movements during backpropagation. Moreover, to guide the future SNN training algorithm design, we provide several observations on energy efficiency with respect to different SNN-specific training parameters.},
	urldate = {2022-05-03},
	author = {Yin, Ruokai and Moitra, Abhishek and Bhattacharjee, Abhiroop and Kim, Youngeun and Panda, Priyadarshini},
	month = apr,
	year = {2022},
	note = {tex.ids= Yin2022
arXiv: 2204.05422
rights: http://creativecommons.org/licenses/by-nc-nd/4.0/},
	keywords = {⛔ No INSPIRE recid found},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/52QHJ3F6/Yin et al. - 2022 - SATA Sparsity-Aware Training Accelerator for Spik.pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/I4WCB7G2/2204.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/WT8DFXCD/Yin et al. - 2022 - SATA Sparsity-Aware Training Accelerator for Spik.pdf:application/pdf},
}

@techreport{Williams2020,
	title = {Point process models for sequence detection in high-dimensional neural spike trains},
	url = {http://arxiv.org/abs/2010.04875},
	abstract = {Sparse sequences of neural spikes are posited to underlie aspects of working memory, motor production, and learning. Discovering these sequences in an unsupervised manner is a longstanding problem in statistical neuroscience. Promising recent work utilized a convolutive nonnegative matrix factorization model to tackle this challenge. However, this model requires spike times to be discretized, utilizes a sub-optimal least-squares criterion, and does not provide uncertainty estimates for model predictions or estimated parameters. We address each of these shortcomings by developing a point process model that characterizes fine-scale sequences at the level of individual spikes and represents sequence occurrences as a small number of marked events in continuous time. This ultra-sparse representation of sequence events opens new possibilities for spike train modeling. For example, we introduce learnable time warping parameters to model sequences of varying duration, which have been experimentally observed in neural circuits. We demonstrate these advantages on experimental recordings from songbird higher vocal center and rodent hippocampus.},
	urldate = {2022-02-04},
	author = {Williams, Alex H. and Degleris, Anthony and Wang, Yixin and Linderman, Scott W.},
	month = oct,
	year = {2020},
	note = {00003
tex.ids= Williams2020a
arXiv: 2010.04875
rights: http://creativecommons.org/licenses/by/4.0/},
	keywords = {⛔ No INSPIRE recid found},
	annote = {Comment: 24 pages, 5 figures},
	annote = {Comment: 24 pages, 5 figures},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/JMT95WXR/Williams et al. - 2020 - Point process models for sequence detection in hig.pdf:application/pdf;arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/8R25RWES/Williams et al. - 2020 - Point process models for sequence detection in hig.pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/Z5UV69TT/2010.html:text/html;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/RQ6GVV6Q/2010.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/PKDQBVGM/Williams et al. - 2020 - Point process models for sequence detection in hig.pdf:application/pdf},
}

@article{Perrinet2014,
	title = {Active inference, eye movements and oculomotor delays},
	volume = {108},
	copyright = {All rights reserved},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/s00422-014-0620-8},
	doi = {10/f6skjq},
	abstract = {This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalised coordinates of motion. Representing hidden states in generalised coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the generative model to simulate smooth pursuit eye movements in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system, like the oculomotor system, tries to control its environment with delayed signals.},
	number = {6},
	journal = {Biological Cybernetics},
	author = {Perrinet, Laurent U and Adams, Rick A and Friston, Karl J},
	month = dec,
	year = {2014},
	note = {tex.ids= Perrinet14a, Perrinet2014a, Perrinet2014b
tex.date-modified: 2020-03-31 11:07:29 +0200
tex.eprint: 25128318
tex.eprinttype: pmid
tex.preprint: https://hal-amu.archives-ouvertes.fr/hal-01382350
publicationTitle: Biological cybernetics
publisher: Springer Berlin Heidelberg
url: http://link.springer.com/article/10.1007\%2Fs00422-014-0620-8},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, active inference, Active inference, active-inference, bayesian, Bayesian model, bicv-motion, bicv-sparse, Biologically Inspired Computer vision, delays, eye, eye movements, eye-movements, free energy, free-energy, Generalised coordinates, generalized-coordinates, generalized-filtering, motion detection, oculomotor, Oculomotor delays, perception, perrinetadamsfriston14, Smooth pursuit eye movements, smooth-pursuit, Tracking eye movements, tracking-eye-movements, Variational free energy, variational-filtering},
	pages = {777--801},
	annote = {00000},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/JNP6ZTEI/Perrinet et al. - 2014 - Active inference, eye movements and oculomotor del.pdf:application/pdf},
}

@inproceedings{Grimaldi2021a,
	title = {A homeostatic gain control mechanism to improve event-driven object recognition},
	copyright = {All rights reserved},
	url = {https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/},
	doi = {10.1109/cbmi50038.2021.9461901},
	abstract = {We propose a neuromimetic architecture able to perform pattern recognition. To achieve this, we extended the existing event-based algorithm from Lagorce et al (2017) which introduced novel spatio-temporal features: time surfaces. Built from asynchronous events acquired by a neuromorphic camera, these time surfaces allow to code the local dynamics of a visual scene and create an efficient hierarchical event-based pattern recognition architecture. Inspired by biological findings and the efficient coding hypothesis, our main contribution is to integrate homeostatic regulation into the Hebbian learning rule. Indeed, in order to be optimally informative, average neural activity within a layer should be equally balanced across neurons. We used that principle to regularize neurons within the same layer by setting a gain depending on their past activity and such that they emit spikes with balanced firing rates. The efficiency of this technique was first demonstrated through a robust improvement in spatio-temporal patterns which were learnt during the training phase. In order to compare with state-of-the-art methods, we replicated past results on the same dataset as Lagorce et al (2017) and extended results in this study to the widely used N-MNIST dataset.},
	booktitle = {Content-based multimedia indexing ({CBMI}) 2021},
	author = {Grimaldi, Antoine and Boutin, Victor and Ieng, Sio-Hoi and Perrinet, Laurent U and Benosman, Ryad},
	month = jun,
	year = {2021},
	note = {tex.ids= Grimaldi2021c
tex.bdsk-url-2: https://doi.org/10.1109/CBMI50038.2021.9461901
tex.grants: aprovis3D
tex.url\_preprint: https://hal.archives-ouvertes.fr/hal-03336554},
	keywords = {⛔ No INSPIRE recid found, efficient coding, event-based vision, homeostasis, neuromorphic hardware, online classification},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/68LKF2BL/Grimaldi et al. - 2021 - A homeostatic gain control mechanism to improve ev.pdf:application/pdf},
}

@article{Serre2007,
	title = {A feedforward architecture accounts for rapid categorization},
	volume = {104},
	issn = {1091-6490},
	url = {http://dx.doi.org/10.1073/pnas.0700622104},
	doi = {10.1073/pnas.0700622104},
	abstract = {Primates are remarkably good at recognizing objects. The level of performance of their visual system and its robustness to image degradations still surpasses the best computer vision systems despite decades of engineering effort. In particular, the high accuracy of primates in ultra rapid object categorization and rapid serial visual presentation tasks is remarkable. Given the number of processing stages involved and typical neural latencies, such rapid visual processing is likely to be mostly feedforward. Here we show that a specific implementation of a class of feedforward theories of object recognition (that extend the Hubel and Wiesel simple-to-complex cell hierarchy and account for many anatomical and physiological constraints) can predict the level and the pattern of performance achieved by humans on a rapid masked animal vs. non-animal categorization task.},
	number = {15},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Serre, Thomas and Oliva, Aude and Poggio, Tomaso},
	month = apr,
	year = {2007},
	pmid = {17404214},
	note = {Publisher: National Academy of Sciences
tex.priority: 2},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, assofield, bicv-sparse, perrinet11sfn},
	pages = {6424--6429},
	annote = {tex.bdsk-url-2: https://doi.org/10.1073/pnas.0700622104 tex.date-added: 2022-05-05 19:08:15 +0200 tex.date-modified: 2022-05-05 19:08:15 +0200},
	annote = {tex.bdsk-url-2: https://doi.org/10.1073/pnas.0700622104 tex.date-added: 2022-05-05 19:08:15 +0200 tex.date-modified: 2022-05-05 19:08:15 +0200},
}

@article{Carr1990,
	title = {A circuit for detection of interaural time differences in the brain stem of the barn owl},
	volume = {10},
	doi = {10.1523/JNEUROSCI.10-10-03227.1990},
	number = {10},
	journal = {Journal of Neuroscience},
	author = {Carr, CE and Konishi, M},
	year = {1990},
	note = {tex.ids= Carr1990a
publisher: Soc Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {3227--3246},
	annote = {Publisher: Society for Neuroscience Section: Articles},
	annote = {Publisher: Society for Neuroscience Section: Articles},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/VYQ8RBWB/Carr et Konishi - 1990 - A circuit for detection of interaural time differe.pdf:application/pdf},
}

@article{Koenderink1987,
	title = {Representation of local geometry in the visual system},
	volume = {55},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/BF00318371},
	doi = {10.1007/BF00318371},
	abstract = {It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree. Arbitrary concatenations of such RF profiles yield again similar ones of higher order and for a greater degree of blurring.},
	language = {en},
	number = {6},
	urldate = {2022-08-31},
	journal = {Biological Cybernetics},
	author = {Koenderink, J. J. and van Doorn, A. J.},
	month = mar,
	year = {1987},
	note = {457 citations (Crossref) [2022-09-03]},
	keywords = {⛔ No INSPIRE recid found},
	pages = {367--375},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/KB5RBTQN/Koenderink and van Doorn - 1987 - Representation of local geometry in the visual sys.pdf:application/pdf},
}

@article{Khoei2017,
	title = {The {Flash}-{Lag} {Effect} as a {Motion}-{Based} {Predictive} {Shift}},
	volume = {13},
	copyright = {Licence Creative Commons Attribution - Pas d’utilisation commerciale - Partage dans les mêmes conditions 4.0 International (CC-BY-NC-SA)},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068},
	doi = {10.1371/journal.pcbi.1005068},
	abstract = {Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object’s motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects’ position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation at the present time of spatial information in the visual pathways.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {PLOS Computational Biology},
	author = {Khoei, Mina A. and Masson, Guillaume S. and Perrinet, Laurent U.},
	month = jan,
	year = {2017},
	note = {tex.ids= Khoei2017a
publisher: Public Library of Science},
	keywords = {⛔ No INSPIRE recid found, Coding mechanisms, Extrapolation, Motion, Psychophysics, Sensory perception, Velocity, Vision, Visual system},
	pages = {e1005068},
	annote = {Publisher: Public Library of Science},
	annote = {Publisher: Public Library of Science},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/W6IE7KE8/Khoei et al. - 2017 - The Flash-Lag Effect as a Motion-Based Predictive .pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/BY6RHZYN/Khoei et al. - 2017 - The Flash-Lag Effect as a Motion-Based Predictive .pdf:application/pdf},
}

@article{Meister1995,
	title = {Concerted signaling by retinal ganglion cells.},
	volume = {270},
	doi = {10/dszfrn},
	number = {5239},
	journal = {Science (New York, N.Y.)},
	author = {Meister, M and Lagnado, L and Baylor, D A},
	month = nov,
	year = {1995},
	note = {tex.ids= Meister1995a},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {1207--1210},
}

@article{DeWeese2002,
	title = {Binary coding in auditory cortex},
	volume = {15},
	journal = {Advances in neural information processing systems},
	author = {DeWeese, Michael and Zador, Anthony},
	year = {2002},
	note = {tex.ids= DeWeese2003},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/PXPJ7G8V/DeWeese et Zador - 2003 - Binary coding in auditory cortex.pdf:application/pdf},
}

@article{Vacher2018,
	title = {Bayesian modeling of motion perception using dynamical stochastic textures},
	copyright = {All rights reserved},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/necoₐ₀1142},
	doi = {10/ggkdk4},
	abstract = {A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a gen-erative model intended to probe visual motion perception. It is first derived in a set of axiomatic steps constrained by biological plausibility. We then extend previous con-tributions by detailing three equivalent formulations of the Gaussian dynamic texture model. First, the composite dynamic textures are constructed by the random aggrega-tion of warped patterns, which can be viewed as 3D Gaussian fields. Second, these textures are cast as solutions to a stochastic partial differential equation (sPDE). This essential step enables real time, on-the-fly, texture synthesis using time-discretized auto-regressive processes. It also allows for the derivation of a local motion-energy model, which corresponds to the log-likelihood of the probability density. The log-likelihoods are finally essential for the construction of a Bayesian inference framework. We use the model to probe speed perception in humans psychophysically using zoom-like changes in stimulus spatial frequency content. The likelihood is contained within the genera-tive model and we chose a slow speed prior consistent with previous literature. We then validated the fitting process of the model using synthesized data. The human data replicates previous findings that relative perceived speed is positively biased by spatial frequency increments. The effect cannot be fully accounted for by previous models, but the current prior acting on the spatio-temporal likelihoods has proved necessary in accounting for the perceptual bias.},
	journal = {Neural Computation},
	author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyré, Gabriel},
	month = nov,
	year = {2018},
	note = {tex.ids= Vacher18
tex.bdsk-url-2: https://doi.org/10.1162/necoₐ₀1142
tex.date-modified: 2019-11-12 13:43:38 +0100
tex.grants: anr-speed
tex.preprint: https://arxiv.org/abs/1611.01390
tex.url: https://www.mitpressjournals.org/doi/abs/10.1162/neco\_a\_01142
publisher: MIT Press},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Bayesian model, motion detection, motion-clouds, Psychophysics},
	annote = {00003},
	annote = {Parameterization of the class of Motion Clouds stimuli. The illustration relates the parametric changes in MC with real world (top row) and observer (second row) movements. (A) Orientation changes resulting in scene rotation are parameterized through þ as shown in the bottom row where a horizontal a and obliquely oriented b MC are compared. (B) Zoom movements, either from scene looming or observer movements in depth, are characterised by scale changes reflected by a scale or frequency term  shown for a larger or closer object b compared to more distant a. (C) Translational movements in the scene characterised by V using the same formulation for static (a) slow (b) and fast moving MC, with the variability in these speeds quantified by . (ξ and τ) in the third row are the spatial and temporal frequency scale parameters. The development of this formulation is detailed in the text.},
	annote = {Parameterization of the class of Motion Clouds stimuli. The illustration relates the parametric changes in MC with real world (top row) and observer (second row) movements. (A) Orientation changes resulting in scene rotation are parameterized through þ as shown in the bottom row where a horizontal a and obliquely oriented b MC are compared. (B) Zoom movements, either from scene looming or observer movements in depth, are characterised by scale changes reflected by a scale or frequency term  shown for a larger or closer object b compared to more distant a. (C) Translational movements in the scene characterised by V using the same formulation for static (a) slow (b) and fast moving MC, with the variability in these speeds quantified by . (ξ and τ) in the third row are the spatial and temporal frequency scale parameters. The development of this formulation is detailed in the text.},
}

@article{Benosman2012,
	title = {Asynchronous frameless event-based optical flow},
	volume = {27},
	doi = {10.1016/j.neunet.2011.11.001},
	abstract = {This paper introduces a process to compute optical flow using an asynchronous event-based retina at high speed and low computational load. A new generation of artificial vision sensors has now started to rely on biologically inspired designs for light acquisition. Biological retinas, and their artificial counterparts, are totally asynchronous and data driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework for processing visual data using asynchronous event-based acquisition, providing a method for the evaluation of optical flow. The paper shows that current limitations of optical flow computation can be overcome by using event-based visual acquisition, where high data sparseness and high temporal resolution permit the computation of optical flow with micro-second accuracy and at very low computational cost.},
	language = {english},
	journal = {Neural Networks},
	author = {Benosman, Ryad},
	year = {2012},
	note = {tex.ids= Benosman2012a},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Asynchronous acquisition, Event-based vision, Frameless vision, Optical flow, Spikes, Temporal dynamics},
	pages = {6},
	annote = {00155},
}

@article{Benvenuti2020,
	title = {Anticipatory responses along motion trajectories in awake monkey area {V1}},
	copyright = {All rights reserved},
	url = {https://www.biorxiv.org/content/10.1101/2020.03.26.010017v1},
	doi = {10.1101/2020.03.26.010017},
	abstract = {What are the neural mechanisms underlying motion integration of translating objects? Visual motion integration is generally conceived of as a feedforward, hierarchical, information processing. However, feedforward models fail to account for many contextual effects revealed using natural moving stimuli. In particular, a translating object evokes a sequence of transient feedforward responses in the primary visual cortex but also propagations of activity through horizontal and feedback pathways. We investigated how these pathways shape the representation of a translating bar in monkey V1. We show that, for long trajectories, spiking activity builds-up hundreds of milliseconds before the bar enters the neurons receptive fields. Using VSDI and LFP recordings guided by a phenomenological model of propagation dynamics, we demonstrate that this anticipatory response arises from the interplay between horizontal and feedback networks driving V1 neurons well ahead of their feedforward inputs. This mechanism could subtend several perceptual contextual effects observed with translating objects.},
	language = {english},
	urldate = {2020-03-31},
	journal = {bioRxiv : the preprint server for biology},
	author = {Benvenuti, Giacomo and Chemla, Sandrine and Boonman, Arjan and Perrinet, Laurent U and Masson, Guillaume S and Chavane, Frederic},
	month = mar,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results
tex.bdsk-url-2: https://doi.org/10/ggqj77
tex.copyright: o̧pyright 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.
tex.date-added: 2020-03-31 11:06:47 +0200
tex.date-modified: 2020-03-31 11:07:45 +0200},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {2020.03.26.010017},
}

@article{Kaplan2013a,
	title = {Anisotropic connectivity implements motion-based prediction in a spiking neural network},
	volume = {7},
	copyright = {All rights reserved},
	issn = {1662-5188},
	url = {https://doi.org/10.3389/fncom.2013.00112},
	doi = {10/f2zw5z},
	abstract = {Predictive coding hypothesizes that the brain explicitly infers upcoming sensory input to establish a coherent representation of the world. Although it is becoming generally accepted, it is not clear on which level spiking neural networks may implement predictive coding and what function their connectivity may have. We present a network model of conductance-based integrate-and-fire neurons inspired by the architecture of retinotopic cortical areas that assumes predictive coding is implemented through network connectivity, namely in the connection delays and in selectiveness for the tuning properties of source and target cells. We show that the applied connection pattern leads to motion-based prediction in an experiment tracking a moving dot. In contrast to our proposed model, a network with random or isotropic connectivity fails to predict the path when the moving dot disappears. Furthermore, we show that a simple linear decoding approach is sufficient to transform neuronal spiking activity into a probabilistic estimate for reading out the target trajectory.},
	number = {SEP},
	journal = {Frontiers in Computational Neuroscience},
	author = {Kaplan, B.A. Bernhard A. and Lansner, Anders and Masson, G.S. Guillaume S G.S. Guillaume S. and Perrinet, Laurent U.},
	month = sep,
	year = {2013},
	note = {tex.ids= Kaplan13, Kaplan13b, Kaplan2013b
tex.date-modified: 2019-02-25 23:22:38 +0100
tex.eprint: 24062680
tex.eprinttype: pmid
tex.grants: facets-itn
publisher: Frontiers
url: http://journal.frontiersin.org/article/10.3389/fncom.2013.00112/abstract},
	keywords = {⛔ No INSPIRE recid found, Bayesian model, khoei14thesis, khoei15fle, large-scale neuromorphic systems, Large-scale neuromorphic systems, large-scaleₙetworks, motion detection, Motion detection, motion extrapolation, Motion extrapolation, motion prediction, motion-extrapolation, motionextrapolation, network of spiking neurons, Network of spiking neurons, predictive coding, Predictive coding, probabilistic representation, Probabilistic representation, pynn, spike, spikes},
	pages = {112},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Kaplan13},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Kaplan13},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/FKPQE2SY/Kaplan et al. - 2013 - Anisotropic connectivity implements motion-based p.pdf:application/pdf},
}

@article{Pasturel2020,
	title = {Humans adapt their anticipatory eye movements to the volatility of visual motion properties},
	copyright = {All rights reserved},
	url = {https://doi.org/10.1371/journal.pcbi.1007438},
	doi = {10.1371/journal.pcbi.1007438},
	abstract = {Humans are able to accurately track a moving object with a combination of saccades and smooth eye movements. These movements allow us to align and stabilize the object on the fovea, thus enabling high*resolution visual analysis. When predictive information is available about target motion, anticipatory smooth pursuit eye movements (aSPEM) are efficiently generated before target appearance, which reduce the typical sensorimotor delay between target motion onset and foveation. It is generally assumed that the role of anticipatory eye movements is to limit the behavioral impairment due to eye*to*target position and velocity mismatch. By manipulating the probability for target motion direction we were able to bias the direction and mean velocity of aSPEM, as measured during a fixed duration gap before target ramp*motion onset. This suggests that probabilistic information may be used to inform the internal representation of motion prediction for the initiation of anticipatory movements. However, such estimate may become particularly challenging in a dynamic context, where the probabilistic contingencies vary in time in an unpredictable way. In addition, whether and how the information processing underlying the buildup of aSPEM is linked to an explicit estimate of probabilities is unknown. We developed a new paired* task paradigm in order to address these two questions. In a first session, participants observe a target moving horizontally with constant speed from the center either to the right or left across trials. The probability of either motion direction changes randomly in time. Participants are asked to estimate "how much they are confident that the target will move to the right or left in the next trial" and to adjust the cursor's position on the screen accordingly. In a second session the participants eye movements are recorded during the observation of the same sequence of random*direction trials. In parallel, we are developing new automatic routines for the advanced analysis of oculomotor traces. In order to extract the relevant parameters of the oculomotor responses (latency, gain, initial acceleration, catch*up saccades), we developed new tools based on best*fitting procedure of predefined patterns (i.e. the typical smooth pursuit velocity profile).},
	journal = {PLoS Computational Biology},
	author = {Pasturel, Chloé and Montagnini, Anna and Perrinet, Laurent U},
	month = jan,
	year = {2020},
	note = {00002 
tex.ids= Pasturel2019
tex.date-added: 2019-07-23 11:45:15 +0200
tex.date-modified: 2020-08-05 11:45:15 +0200
tex.grants: pace-itn
tex.preprint: https://www.biorxiv.org/content/10.1101/784116v3
tex.url\_code: https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020
tex.url\_pdf: https://www.biorxiv.org/content/10.1101/784116v3.full.pdf},
	keywords = {⛔ No INSPIRE recid found, motion anticipation},
	file = {Pasturel et al. - 2019 - Humans adapt their anticipatory eye movements to t.pdf:/Users/laurentperrinet/Zotero/storage/2MLSTZ2V/Pasturel et al. - 2019 - Humans adapt their anticipatory eye movements to t.pdf:application/pdf},
}

@article{Lagorce2017,
	title = {{HOTS}: {A} {Hierarchy} of {Event}-{Based} {Time}-{Surfaces} for {Pattern} {Recognition}},
	volume = {39},
	issn = {0162-8828},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27411216%20http://ieeexplore.ieee.org/document/7508476/},
	doi = {10.1109/TPAMI.2016.2574707},
	abstract = {This paper describes novel event-based spatiotemporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a 4 class canonical dynamic card pip task, achieving near 100\% accuracy on each. We introduce a new 7 class moving face recognition task, achieving 79\% accuracy.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Lagorce, Xavier and Orchard, Garrick and Galluppi, Francesco and Shi, Bertram E. and Benosman, Ryad B.},
	year = {2017},
	pmid = {27411216},
	note = {tex.ids= Lagorce2017a
tex.bdsk-url-2: https://doi.org/10.1109/TPAMI.2016.2574707
tex.date-added: 2020-11-09 16:16:25 +0100
tex.date-modified: 2020-11-09 16:16:25 +0100
url: http://www.ncbi.nlm.nih.gov/pubmed/27411216 http://ieeexplore.ieee.org/document/7508476/},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, event-based vision, feature extraction, Neuromorphic sensing},
	pages = {1346--1359},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/I595JAMK/Lagorce et al. - 2017 - HOTS A Hierarchy of Event-Based Time-Surfaces for.pdf:application/pdf},
}

@article{DeAngelis1999,
	title = {Functional micro-organization of primary visual cortex: receptive field analysis of nearby neurons},
	volume = {19},
	doi = {10.1523/JNEUROSCI.19-10-04046.1999},
	number = {10},
	journal = {Journal of Neuroscience},
	author = {DeAngelis, Gregory C and Ghose, Geoffrey M and Ohzawa, Izumi and Freeman, Ralph D},
	year = {1999},
	note = {Publisher: Soc Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {4046--4064},
}

@article{Izhikevich2006,
	title = {Polychronization: {Computation} with spikes},
	volume = {18},
	issn = {0899-7667},
	shorttitle = {Polychronization},
	url = {https://doi.org/10.1162/089976606775093882},
	doi = {10.1162/089976606775093882},
	abstract = {We present a minimal spiking network that can polychronize, that is, exhibit reproducible time-locked but not synchronous firing patterns with millisecond precision, as in synfire braids. The network consists of cortical spiking neurons with axonal conduction delays and spike-timing-dependent plasticity (STDP); a ready-to-use MATLAB code is included. It exhibits sleeplike oscillations, gamma (40 Hz) rhythms, conversion of firing rates to spike timings, and other interesting regimes. Due to the interplay between the delays and STDP, the spiking neurons spontaneously self-organize into groups and generate patterns of stereotypical polychronous activity. To our surprise, the number of coexisting polychronous groups far exceeds the number of neurons in the network, resulting in an unprecedented memory capacity of the system. We speculate on the significance of polychrony to the theory of neuronal group selection (TNGS, neural Darwinism), cognitive neural computations, binding and gamma rhythm, mechanisms of attention, and consciousness as “attention to memories.”},
	number = {2},
	urldate = {2018-09-24},
	journal = {Neural Computation},
	author = {Izhikevich, Eugene M.},
	month = feb,
	year = {2006},
	note = {publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …
tex.ids= izhikevich2006polychronization},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {245--282},
	annote = {00000},
	annote = {00000},
	annote = {00943 tex.ids= Izhikevich06},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/SXXLNJNI/Izhikevich - 2006 - Polychronization Computation with Spikes.pdf:application/pdf;Izhikevich - 2006 - Polychronization Computation with Spikes.pdf:/Users/laurentperrinet/Zotero/storage/CJZS73WJ/Izhikevich - 2006 - Polychronization Computation with Spikes.pdf:application/pdf},
}

@article{Carandini2012,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	doi = {10.1038/nrn3136},
	number = {1},
	journal = {Nature Reviews Neuroscience},
	author = {Carandini, Matteo and Heeger, David J},
	year = {2012},
	pmid = {22108672},
	note = {tex.ids= Carandini12a, Carandini2011
publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found, Adaptation, Afferent Pathways, Anim, contrast\_response, divisive\_normalization, normalization, Physiological},
	pages = {51--62},
	file = {Accepted Version:/Users/laurentperrinet/Zotero/storage/X7VAKBHJ/Carandini and Heeger - 2011 - Normalization as a canonical neural computation.pdf:application/pdf;Carandini and Heeger - 2012 - Normalization as a canonical neural computation.pdf:/Users/laurentperrinet/Zotero/storage/L86BIUEY/Carandini and Heeger - 2012 - Normalization as a canonical neural computation.pdf:application/pdf},
}

@article{Priebe2006,
	title = {Tuning for {Spatiotemporal} {Frequency} and {Speed} in {Directionally} {Selective} {Neurons} of {Macaque} {Striate} {Cortex}},
	volume = {26},
	doi = {10/d6f8gm},
	number = {11},
	journal = {Journal of Neuroscience},
	author = {Priebe, N J},
	month = mar,
	year = {2006},
	note = {00213
tex.ids= Priebe2006a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2941--2950},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/NBUVBMNG/Priebe - 2006 - Tuning for Spatiotemporal Frequency and Speed in D.pdf:application/pdf;PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/K49NWK6K/Priebe et al. - 2006 - Tuning for Spatiotemporal Frequency and Speed in D.pdf:application/pdf},
}

@article{Bohte2004,
	title = {The evidence for neural information processing with precise spike-times: {A} survey},
	volume = {3},
	doi = {10.1023/B:NACO.0000027755.02868.60},
	number = {2},
	journal = {Natural Computing},
	author = {Bohte, Sander M},
	year = {2004},
	note = {tex.ids= Bohte2004a
publisher: Springer},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {195--206},
}

@article{Butts2007,
	title = {Temporal precision in the neural code and the timescales of natural vision},
	volume = {449},
	doi = {10/fjwzhr},
	number = {7158},
	journal = {Nature},
	author = {Butts, Daniel A and Weng, Chong and Jin, Jianzhong and Yeh, Chun-I and Lesica, Nicholas A and Alonso, Jose-Manuel and Stanley, Garrett B},
	month = sep,
	year = {2007},
	note = {00313},
	keywords = {⛔ No INSPIRE recid found, Humanities and Social Sciences, multidisciplinary, Science},
	pages = {92--95},
	annote = {Number: 7158 Publisher: Nature Publishing Group},
	annote = {Number: 7158 Publisher: Nature Publishing Group},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/6TWZFUA5/Butts et al. - 2007 - Temporal precision in the neural code and the time.pdf:application/pdf},
}

@article{Luo2022,
	title = {Supervised learning in multilayer spiking neural networks with spike temporal error backpropagation},
	doi = {10.1109/TNNLS.2022.3164930},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Luo, Xiaoling and Qu, Hong and Wang, Yuchen and Yi, Zhang and Zhang, Jilun and Zhang, Malu},
	year = {2022},
	note = {tex.ids= Luo2022a},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Backpropagation, Biological system modeling, Delays, Heuristic algorithms, Membrane potentials, Neurons, Nonhomogeneous media, spike neural networks, spike neurons, supervised learning, synaptic delay plasticity.},
	pages = {1--13},
}

@article{Abeles1982,
	title = {Role of the cortical neuron: integrator or coincidence detector?},
	volume = {18},
	number = {1},
	journal = {Israel journal of medical sciences},
	author = {Abeles, Moshe},
	year = {1982},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	pages = {83--92},
}

@article{Mainen1995,
	title = {Reliability of spike timing in neocortical neurons.},
	volume = {268},
	doi = {10/b2mms6},
	number = {5216},
	journal = {Science (New York, N.Y.)},
	author = {Mainen, Z F and Sejnowski, T J},
	month = jun,
	year = {1995},
	note = {tex.ids= Mainen1995a},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {1503--1506},
}

@article{Hubel1968,
	title = {Receptive fields and functional architecture of monkey striate cortex},
	volume = {195},
	issn = {1469-7793},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1968.sp008455},
	doi = {10.1113/jphysiol.1968.sp008455},
	language = {english},
	number = {1},
	journal = {The Journal of Physiology},
	author = {Hubel, David H and Wiesel, Torsten N},
	year = {1968},
	pmcid = {PMC1557912},
	pmid = {4966457},
	note = {tex.ids= Hubel1968a
tex.bdsk-url-2: https://doi.org/10/gc8z3q},
	keywords = {⛔ No INSPIRE recid found, area-v1, bicv-motion, bicv-sparse},
	pages = {215--243},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/S6FYJ3C9/Hubel and Wiesel - 1968 - Receptive fields and functional architecture of mo.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/2LY62ZY6/Hubel and Wiesel - 1968 - Receptive fields and functional architecture of mo.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/6L89CMPR/jphysiol.1968.html:text/html},
}

@article{Boutin2022,
	title = {Pooling strategies in {V1} can account for the functional and structural diversity across species},
	volume = {18},
	copyright = {Licence Creative Commons Attribution - Pas d’utilisation commerciale - Pas de modification 4.0 International (CC-BY-NC-ND)},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010270},
	doi = {10.1371/journal.pcbi.1010270},
	abstract = {Neurons in the primary visual cortex are selective to orientation with various degrees of selectivity to the spatial phase, from high selectivity in simple cells to low selectivity in complex cells. Various computational models have suggested a possible link between the presence of phase invariant cells and the existence of orientation maps in higher mammals’ V1. These models, however, do not explain the emergence of complex cells in animals that do not show orientation maps. In this study, we build a theoretical model based on a convolutional network called Sparse Deep Predictive Coding (SDPC) and show that a single computational mechanism, pooling, allows the SDPC model to account for the emergence in V1 of complex cells with or without that of orientation maps, as observed in distinct species of mammals. In particular, we observed that pooling in the feature space is directly related to the orientation map formation while pooling in the retinotopic space is responsible for the emergence of a complex cells population. Introducing different forms of pooling in a predictive model of early visual processing as implemented in SDPC can therefore be viewed as a theoretical framework that explains the diversity of structural and functional phenomena observed in V1.},
	language = {en},
	number = {7},
	urldate = {2022-09-14},
	journal = {PLOS Computational Biology},
	author = {Boutin, Victor and Franciosini, Angelo and Chavane, Frédéric and Perrinet, Laurent U.},
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {⛔ No INSPIRE recid found, Coding mechanisms, Convolution, Neural networks, Neuronal tuning, Neurons, Neurophysiology, Visual cortex, Visual system},
	pages = {e1010270},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/84YZZP3J/Boutin et al. - 2022 - Pooling strategies in V1 can account for the funct.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/DGMCDKTT/article.html:text/html},
}

@article{Lamme2000,
	title = {The distinct modes of vision offered by feedforward and recurrent processing},
	volume = {23},
	issn = {0166-2236, 1878-108X},
	url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(00)01657-X},
	doi = {10.1016/s0166-2236(00)01657-x},
	language = {English},
	number = {11},
	urldate = {2019-03-18},
	journal = {Trends in Neurosciences},
	author = {Lamme, Victor A. F. and Roelfsema, Pieter R.},
	month = nov,
	year = {2000},
	pmid = {11074267},
	note = {tex.ids= Lamme2000a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {571--579},
}

@article{Vinje2000,
	title = {Sparse {Coding} and {Decorrelation} in {Primary} {Visual} {Cortex} {During} {Natural} {Vision}},
	volume = {287},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.287.5456.1273},
	doi = {10.1126/science.287.5456.1273},
	abstract = {Theoretical studies suggest that primary visual cortex (area V1) uses a sparse code to efficiently represent natural scenes. This issue was investigated by recording from V1 neurons in awake behaving macaques during both free viewing of natural scenes and conditions simulating natural vision. Stimulation of the nonclassical receptive field increases the selectivity and sparseness of individual V1 neurons, increases the sparseness of the population response distribution, and strongly decorrelates the responses of neuron pairs. These effects are due to both excitatory and suppressive modulation of the classical receptive field by the nonclassical receptive field and do not depend critically on the spatiotemporal structure of the stimuli. During natural vision, the classical and nonclassical receptive fields function together to form a sparse representation of the visual world. This sparse code may be computationally efficient for both early vision and higher visual processing.},
	language = {en},
	number = {5456},
	urldate = {2022-10-03},
	journal = {Science},
	author = {Vinje, William E. and Gallant, Jack L.},
	month = feb,
	year = {2000},
	pmid = {10678835},
	note = {tex.ids= Vinje2000},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, bicv-sparse, motion\_clouds, motion-clouds, natural\_scenes, natural-scenes, sanz12jnp, vacher14},
	pages = {1273--1276},
	annote = {l'excitation de non classical RF augmente la sparseness},
	annote = {Publisher: American Association for the Advancement of Science},
	annote = {Publisher: American Association for the Advancement of Science},
	annote = {tex.ids= Vinje2000},
	file = {Vinje and Gallant - 2000 - Sparse Coding and Decorrelation in Primary Visual .pdf:/Users/laurentperrinet/Zotero/storage/H6VS4BZP/Vinje and Gallant - 2000 - Sparse Coding and Decorrelation in Primary Visual .pdf:application/pdf},
}

@article{Gutig2014,
	series = {Theoretical and computational neuroscience},
	title = {To spike, or when to spike?},
	volume = {25},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438814000129},
	doi = {10.1016/j.conb.2014.01.004},
	abstract = {Recent experimental reports have suggested that cortical networks can operate in regimes were sensory information is encoded by relatively small populations of spikes and their precise relative timing. Combined with the discovery of spike timing dependent plasticity, these findings have sparked growing interest in the capabilities of neurons to encode and decode spike timing based neural representations. To address these questions, a novel family of methodologically diverse supervised learning algorithms for spiking neuron models has been developed. These models have demonstrated the high capacity of simple neural architectures to operate also beyond the regime of the well established independent rate codes and to utilize theoretical advantages of spike timing as an additional coding dimension.},
	language = {en},
	urldate = {2022-05-13},
	journal = {Current Opinion in Neurobiology},
	author = {Gütig, Robert},
	month = apr,
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {134--139},
	file = {ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/UK47EUTM/S0959438814000129.html:text/html},
}

@article{Grammont1999,
	title = {Precise spike synchronization in monkey motor cortex involved in preparation for movement},
	volume = {128},
	url = {https://doi.org/b67khx},
	doi = {10.1007/s002210050826},
	number = {1-2},
	journal = {Experimental Brain Research},
	author = {Grammont, Franck and Riehle, Alexa},
	month = sep,
	year = {1999},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s002210050826},
	keywords = {⛔ No INSPIRE recid found},
	pages = {118--122},
	file = {Grammont and Riehle - 1999 - Precise spike synchronization in monkey motor cort.pdf:/Users/laurentperrinet/Zotero/storage/NSWQJ52V/Grammont and Riehle - 1999 - Precise spike synchronization in monkey motor cort.pdf:application/pdf},
}

@article{Grammont2003,
	title = {Spike synchronization and firing rate in a population of motor cortical neurons in relation to movement direction and reaction time},
	volume = {88},
	url = {https://doi.org/ctvhsb},
	doi = {10.1007/s00422-002-0385-3},
	number = {5},
	journal = {Biological Cybernetics},
	author = {Grammont, F. and Riehle, A.},
	year = {2003},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s00422-002-0385-3},
	keywords = {⛔ No INSPIRE recid found},
	pages = {360--373},
}

@article{Gilson2010,
	title = {{STDP} in recurrent neuronal networks},
	volume = {4},
	url = {https://doi.org/c8ck59},
	doi = {10.3389/fncom.2010.00023},
	journal = {Frontiers in Computational Neuroscience},
	author = {Gilson, Matthieu},
	year = {2010},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fncom.2010.00023},
	keywords = {⛔ No INSPIRE recid found},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/XDEUVFW3/Gilson - 2010 - STDP in recurrent neuronal networks.pdf:application/pdf},
}

@article{Gewaltig1970,
	title = {Propagation of cortical synfire activity: survival probability in single trials and stability in the mean.},
	volume = {14},
	issn = {0893-6080},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/11665761},
	doi = {10.1016/s0893-6080(01)00070-3},
	abstract = {The synfire hypothesis states that under appropriate conditions volleys of synchronized spikes (pulse packets) can propagate through the cortical network by traveling along chains of groups of cortical neurons. Here, we present results from network simulations, taking full account of the variability in pulse packet realizations. We repeatedly stimulated a synfire chain of model neurons and estimated activity (a) and temporal jitter (sigma) of the spike response for each neuron group in the chain in many trials. The survival probability of the activity was assessed for each point in (a, sigma)-space. The results confirm and extend our earlier predictions based on single neuron properties and a deterministic state-space analysis [Diesmann, M., Gewaltig, M.-O., \& Aertsen, A. (1999). Stable propagation of synchronous spiking in cortical neural networks. Nature, 402, 529-533].},
	number = {6-7},
	journal = {Neural networks : the official journal of the International Neural Network Society},
	author = {Gewaltig, M O and Diesmann, M and Aertsen, A},
	month = jan,
	year = {1970},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:11665761},
	keywords = {⛔ No INSPIRE recid found, Action Potentials, Animals, Cell Membrane, Cerebral Cortex, Computer, Cortical dynamics, Humans, Integrate-and-fire neurons, Models, Nerve Net, Neural Networks, Neurons, Pulse packets, Single-trial analysis, Spike patterns, Spiking neurons, Statistical, Synaptic Transmission, Synfire chains, Variability},
	pages = {657--73},
}

@article{DiMauroAlfio2022,
	title = {{SNE}: an {Energy}-{Proportional} {Digital} {Accelerator} for {Sparse} {Event}-{Based} {Convolutions}},
	url = {https://doi.org/gp3m5v},
	doi = {10.3929/ethz-b-000543342},
	abstract = {Event-based sensors are drawing increasing attention due to their high temporal resolution, low power consumption, and low bandwidth. To efficiently extract semantically meaningful information from sparse data streams produced by such sensors, we present a 4.5TOP/s/W digital accelerator capable of performing 4-bits-quantized event-based convolutional neural networks (eCNN). Compared to standard convolutional engines, our accelerator performs a number of operations proportional to the number of events contained into the input data stream, ultimately achieving a high energy-to-information processing proportionality. On the IBM-DVS-Gesture dataset, we report 80uJ/inf to 261uJ/inf, respectively, when the input activity is 1.2\% and 4.9\%. Our accelerator consumes 0.221pJ/SOP, to the best of our knowledge it is the lowest energy/OP reported on a digital neuromorphic engine.},
	language = {en},
	journal = {ETH Zurich},
	author = {{Di Mauro, Alfio} and {Prasad, Arpan Suravi} and {Huang, Zhikai} and {Spallanzani, Matteo} and {Conti, Francesco} and {Benini, Luca}},
	year = {2022},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3929/ethz-b-000543342},
	keywords = {⛔ No INSPIRE recid found},
}

@article{Denker2018,
	title = {{LFP} beta amplitude is linked to mesoscopic spatio-temporal phase patterns},
	volume = {8},
	url = {https://doi.org/gc9xx6},
	doi = {10.1038/s41598-018-22990-7},
	language = {en},
	number = {1},
	journal = {Scientific Reports},
	author = {Denker, Michael and Zehl, Lyuba and Kilavik, Bjørg E. and Diesmann, Markus and Brochier, Thomas and Riehle, Alexa and Grün, Sonja},
	month = mar,
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/s41598-018-22990-7},
	keywords = {⛔ No INSPIRE recid found},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/2YF8V49F/Denker et al. - 2018 - LFP beta amplitude is linked to mesoscopic spatio-.pdf:application/pdf},
}

@article{deCharms1996,
	title = {Primary cortical representation of sounds by the coordination of action-potential timing},
	volume = {381},
	url = {https://doi.org/bctwmg},
	doi = {10.1038/381610a0},
	language = {en},
	number = {6583},
	journal = {Nature},
	author = {deCharms, R. Christopher and Merzenich, Michael M.},
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/381610a0},
	keywords = {⛔ No INSPIRE recid found, Humanities and Social Sciences, multidisciplinary, Science},
	pages = {610--613},
	annote = {Number: 6583 Publisher: Nature Publishing Group},
	annote = {Number: 6583 Publisher: Nature Publishing Group},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/RY57CX84/deCharms and Merzenich - 1996 - Primary cortical representation of sounds by the c.pdf:application/pdf},
}

@article{Davison2008,
	title = {{PyNN}: a common interface for neuronal network simulators},
	volume = {2},
	url = {https://doi.org/fh8h6j},
	doi = {10.3389/neuro.11.011.2008},
	journal = {Frontiers in Neuroinformatics},
	author = {Davison, Andrew P},
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/neuro.11.011.2008},
	keywords = {⛔ No INSPIRE recid found},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/ANFXWEYF/Davison - 2008 - PyNN a common interface for neuronal network simu.pdf:application/pdf},
}

@article{Chemla2019a,
	title = {Suppressive waves disambiguate the representation of long-range apparent motion in awake monkey {V1}},
	volume = {2792},
	url = {http://www.jneurosci.org/content/early/2019/03/18/JNEUROSCI.2792-18.2019},
	doi = {10.1523/JNEUROSCI.2792-18.2019},
	abstract = {The “apparent motion” illusion is evoked when stationary stimuli are successively flashed in spatially separated positions. It depends on the precise spatial and temporal separations of the stimuli. For large spatiotemporal separation, the long-range apparent motion (lrAM), it remains unclear how the visual system computes unambiguous motion signals. Here we investigated whether intracortical interactions within retinotopic maps could shape a global motion representation at the level of V1 population in response to a lrAM. In fixating monkeys, voltage-sensitive dye imaging revealed the emergence of a spatio-temporal representation of the motion trajectory at the scale of V1 population activity, shaped by systematic backward suppressive waves. We show that these waves are the expected emergent property of a recurrent gain control fed by the horizontal intra-cortical network. Such non-linearities explain away ambiguous correspondence problems of the stimulus along the motion path, preformating V1 population response for an optimal read-out by downstream areas.},
	urldate = {2018-07-27},
	journal = {Journal of Neuroscience},
	author = {Chemla, Sandrine and Reynaud, Alexandre and diVolo, Matteo and Zerlaut, Yann and Perrinet, Laurent U and Destexhe, Alain and Chavane, Frédéric Y},
	month = mar,
	year = {2019},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Chemla19},
	keywords = {⛔ No INSPIRE recid found},
	pages = {18},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Chemla19},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Chemla19},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/8S7PI8A6/Chemla et al. - 2019 - Suppressive waves disambiguate the representation .pdf:application/pdf},
}

@article{DAHLEM2009,
	title = {{DYNAMICS} {OF} {DELAY}-{COUPLED} {EXCITABLE} {NEURAL} {SYSTEMS}},
	volume = {19},
	url = {https://doi.org/d43v5b},
	doi = {10.1142/s0218127409023111},
	abstract = {{\textless}jats:p{\textgreater} We study the nonlinear dynamics of two delay-coupled neural systems each modeled by excitable dynamics of FitzHugh–Nagumo type and demonstrate that bistability between the stable fixed point and limit cycle oscillations occurs for sufficiently large delay times τ and coupling strength C. As the mechanism for these delay-induced oscillations, we identify a saddle-node bifurcation of limit cycles. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {02},
	journal = {International Journal of Bifurcation and Chaos},
	author = {DAHLEM, M. A. and HILLER, G. and PANCHUK, A. and SCHÖLL, E.},
	year = {2009},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1142/s0218127409023111},
	keywords = {⛔ No INSPIRE recid found},
	pages = {745--753},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/QQEZ9KMK/DAHLEM et al. - 2009 - DYNAMICS OF DELAY-COUPLED EXCITABLE NEURAL SYSTEMS.pdf:application/pdf},
}

@article{Chase2007,
	title = {First-spike latency information in single neurons increases when referenced to population onset},
	volume = {104},
	url = {https://doi.org/cm3b98},
	doi = {10.1073/pnas.0610368104},
	abstract = {{\textless}jats:p{\textgreater}It is well known that many stimulus parameters, such as sound location in the auditory system or contrast in the visual system, can modulate the timing of the first spike in sensory neurons. Could first-spike latency be a candidate neural code? Most studies measuring first-spike latency information assume that the brain has an independent reference for stimulus onset from which to extract latency. This assumption creates an obvious confound that casts doubt on the feasibility of first-spike latency codes. If latency is measured relative to an internal reference of stimulus onset calculated from the responses of the neural population, the information conveyed by the latency of single neurons might decrease because of correlated changes in latency across the population. Here we assess the effects of a realistic model of stimulus onset detection on the first-spike latency information conveyed by single neurons in the auditory system. Contrary to expectation, we find that on average, the information contained in single neurons does not decrease; in fact, the majority of neurons show a slight increase in the information conveyed by latency referenced to a population onset. Our results show that first-spike latency codes are a feasible mechanism for information transfer even when biologically plausible estimates of stimulus onset are taken into account.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {12},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Chase, Steven M. and Young, Eric D.},
	month = mar,
	year = {2007},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1073/pnas.0610368104},
	keywords = {⛔ No INSPIRE recid found},
	pages = {5175--5180},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/PHYZF2UV/Chase et Young - 2007 - First-spike latency information in single neurons .pdf:application/pdf},
}

@article{Bruno2006,
	title = {Cortex {Is} {Driven} by {Weak} but {Synchronously} {Active} {Thalamocortical} {Synapses}},
	volume = {312},
	url = {https://doi.org/c5575v},
	doi = {10.1126/science.1124593},
	abstract = {{\textless}jats:p{\textgreater}Sensory stimuli reach the brain via the thalamocortical projection, a group of axons thought to be among the most powerful in the neocortex. Surprisingly, these axons account for only ∼15\% of synapses onto cortical neurons. The thalamocortical pathway might thus achieve its effectiveness via high-efficacy thalamocortical synapses or via amplification within cortical layer 4. In rat somatosensory cortex, we measured in vivo the excitatory postsynaptic potential evoked by a single synaptic connection and found that thalamocortical synapses have low efficacy. Convergent inputs, however, are both numerous and synchronous, and intracortical amplification is not required. Our results suggest a mechanism of cortical activation by which thalamic input alone can drive cortex.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {5780},
	journal = {Science},
	author = {Bruno, Randy M. and Sakmann, Bert},
	year = {2006},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.1124593},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1622--1627},
}

@article{Bringuier1999,
	title = {Horizontal {Propagation} of {Visual} {Activity} in the {Synaptic} {Integration} {Field} of {Area} 17 {Neurons}},
	volume = {283},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/283/5402/695},
	doi = {10.1126/science.283.5402.695},
	abstract = {The receptive field of a visual neuron is classically defined as the region of space (or retina) where a visual stimulus evokes a change in its firing activity. At the cortical level, a challenging issue concerns the roles of feedforward, local recurrent, intracortical, and cortico-cortical feedback connectivity in receptive field properties. Intracellular recordings in cat area 17 showed that the visually evoked synaptic integration field extends over a much larger area than that established on the basis of spike activity. Synaptic depolarizing responses to stimuli flashed at increasing distances from the center of the receptive field decreased in strength, whereas their onset latency increased. These findings suggest that subthreshold responses in the unresponsive region surrounding the classical discharge field result from the integration of visual activation waves spread by slowly conducting horizontal axons within primary visual cortex.},
	number = {5402},
	urldate = {2019-02-07},
	journal = {Science},
	author = {Bringuier, Vincent and Chavane, Frédéric and Glaeser, Larry and Frégnac, Yves},
	month = jan,
	year = {1999},
	note = {00535
Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Bringuier99},
	keywords = {⛔ No INSPIRE recid found},
	pages = {695--699},
	annote = {00535 Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Bringuier99},
	annote = {00535 Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Bringuier99},
}

@article{Caporale2008,
	title = {Spike {Timing}–{Dependent} {Plasticity}: {A} {Hebbian} {Learning} {Rule}},
	volume = {31},
	url = {https://doi.org/fqxrgj},
	doi = {10.1146/annurev.neuro.31.060407.125639},
	abstract = {{\textless}jats:p{\textgreater} Spike timing–dependent plasticity (STDP) as a Hebbian synaptic learning rule has been demonstrated in various neural circuits over a wide spectrum of species, from insects to humans. The dependence of synaptic modification on the order of pre- and postsynaptic spiking within a critical window of tens of milliseconds has profound functional implications. Over the past decade, significant progress has been made in understanding the cellular mechanisms of STDP at both excitatory and inhibitory synapses and of the associated changes in neuronal excitability and synaptic integration. Beyond the basic asymmetric window, recent studies have also revealed several layers of complexity in STDP, including its dependence on dendritic location, the nonlinear integration of synaptic modification induced by complex spike trains, and the modulation of STDP by inhibitory and neuromodulatory inputs. Finally, the functional consequences of STDP have been examined directly in an increasing number of neural circuits in vivo. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Caporale, Natalia and Dan, Yang},
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1146/annurev.neuro.31.060407.125639},
	keywords = {⛔ No INSPIRE recid found},
	pages = {25--46},
}

@article{Brette2012,
	title = {Computing with {Neural} {Synchrony}},
	volume = {8},
	url = {https://doi.org/f32tvz},
	doi = {10.1371/journal.pcbi.1002561},
	language = {en},
	number = {6},
	journal = {PLoS Computational Biology},
	author = {Brette, Romain},
	editor = {Sporns, Olaf},
	year = {2012},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1371/journal.pcbi.1002561},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1002561},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/IRFRVZGQ/Brette - 2012 - Computing with Neural Synchrony.pdf:application/pdf},
}

@article{Bohte2002,
	title = {Error-backpropagation in temporally encoded networks of spiking neurons},
	volume = {48},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231201006580},
	doi = {10.1016/S0925-2312(01)00658-0},
	abstract = {For a network of spiking neurons that encodes information in the timing of individual spike times, we derive a supervised learning rule, SpikeProp, akin to traditional error-backpropagation. With this algorithm, we demonstrate how networks of spiking neurons with biologically reasonable action potentials can perform complex non-linear classification in fast temporal coding just as well as rate-coded networks. We perform experiments for the classical XOR problem, when posed in a temporal setting, as well as for a number of other benchmark datasets. Comparing the (implicit) number of spiking neurons required for the encoding of the interpolated XOR problem, the trained networks demonstrate that temporal coding is a viable code for fast neural information processing, and as such requires less neurons than instantaneous rate-coding. Furthermore, we find that reliable temporal computation in the spiking networks was only accomplished when using spike response functions with a time constant longer than the coding interval, as has been predicted by theoretical considerations.},
	language = {en},
	number = {1},
	urldate = {2022-09-28},
	journal = {Neurocomputing},
	author = {Bohte, Sander M. and Kok, Joost N. and La Poutré, Han},
	month = oct,
	year = {2002},
	note = {tex.ids= Bohte2002a},
	keywords = {⛔ No INSPIRE recid found, Error-backpropagation, Spiking neurons, Temporal coding},
	pages = {17--37},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/VMKDUWE7/Bohte et al. - 2002 - Error-backpropagation in temporally encoded networ.pdf:application/pdf},
}

@article{Benosman2014,
	title = {Event-{Based} {Visual} {Flow}},
	volume = {25},
	issn = {2162-237X, 2162-2388},
	url = {https://www.neuromorphic-vision.com/public/publications/3/publication.pdf},
	doi = {10.1109/tnnls.2013.2273537},
	abstract = {This paper introduces a new methodology to compute dense visual ﬂow using the precise timings of spikes from an asynchronous event-based retina. Biological retinas, and their artiﬁcial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual ﬂow from the local properties of events’ spatiotemporal space. We will show that precise visual ﬂow orientation and amplitude can be estimated using a local differential approach on the surface deﬁned by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-based acquisition that allows the computation of motion ﬂow with microsecond accuracy and at very low computational cost.},
	language = {en},
	number = {2},
	urldate = {2022-02-01},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Benosman, Ryad and Clercq, Charles and Lagorce, Xavier and {Sio-Hoi Ieng} and Bartolozzi, Chiara},
	month = feb,
	year = {2014},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {407--417},
}

@article{Azouz2008,
	title = {Stimulus-selective spiking is driven by the relative timing of synchronous excitation and disinhibition in cat striate neurons\textit{in vivo}},
	volume = {28},
	url = {https://doi.org/cbcr8h},
	doi = {10.1111/j.1460-9568.2008.06434.x},
	language = {en},
	number = {7},
	journal = {European Journal of Neuroscience},
	author = {Azouz, Rony and Gray, Charles M.},
	month = oct,
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1111/j.1460-9568.2008.06434.x},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1286--1300},
}

@article{Aviel2003,
	title = {On {Embedding} {Synfire} {Chains} in a {Balanced} {Network}},
	volume = {15},
	url = {https://doi.org/fgj3wf},
	doi = {10.1162/089976603321780290},
	abstract = {{\textless}jats:p{\textgreater} We investigate the formation of synfire waves in a balanced network of integrate-and-fire neurons. The synaptic connectivity of this network embodies synfire chains within a sparse random connectivity. This network can exhibit global oscillations but can also operate in an asynchronous activity mode. We analyze the correlations of two neurons in a pool as convenient indicators for the state of the network. We find, using different models, that these indicators depend on a scaling variable. {\textless}/jats:p{\textgreater}{\textless}jats:p{\textgreater} Beyond a critical point, strong correlations and large network oscillations are obtained. We looked for the conditions under which a synfire wave could be propagated on top of an otherwise asynchronous state of the network. This condition was found to be highly restrictive, requiring a large number of neurons for its implementation in our network. The results are based on analytic derivations and simulations. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {6},
	journal = {Neural Computation},
	author = {Aviel, Y. and Mehring, C. and Abeles, M. and Horn, D.},
	year = {2003},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1162/089976603321780290},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1321--1340},
}

@book{Abeles1991,
	address = {Cambridge ; New York},
	title = {Corticonics: neural circuits of the cerebral cortex},
	isbn = {978-0-521-37476-7},
	shorttitle = {Corticonics},
	publisher = {Cambridge University Press},
	author = {Abeles, Moshe},
	year = {1991},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: isbn:9780521376174},
	keywords = {⛔ No INSPIRE recid found},
}

@article{Dard2022,
	title = {The rapid developmental rise of somatic inhibition disengages hippocampal dynamics from self-motion},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.78116},
	doi = {10.7554/eLife.78116},
	abstract = {Early electrophysiological brain oscillations recorded in preterm babies and newborn rodents are initially mostly driven by bottom-up sensorimotor activity and only later can detach from external inputs. This is a hallmark of most developing brain areas, including the hippocampus, which, in the adult brain, functions in integrating external inputs onto internal dynamics. Such developmental disengagement from external inputs is likely a fundamental step for the proper development of cognitive internal models. Despite its importance, the developmental timeline and circuit basis for this disengagement remain unknown. To address this issue, we have investigated the daily evolution of CA1 dynamics and underlying circuits during the first two postnatal weeks of mouse development using two-photon calcium imaging in non-anesthetized pups. We show that the first postnatal week ends with an abrupt shift in the representation of self-motion in CA1. Indeed, most CA1 pyramidal cells switch from activated to inhibited by self-generated movements at the end of the first postnatal week, whereas the majority of GABAergic neurons remain positively modulated throughout this period. This rapid switch occurs within 2 days and follows the rapid anatomical and functional surge of local somatic GABAergic innervation. The observed change in dynamics is consistent with a two-population model undergoing a strengthening of inhibition. We propose that this abrupt developmental transition inaugurates the emergence of internal hippocampal dynamics.},
	urldate = {2022-10-05},
	journal = {eLife},
	author = {Dard, Robin F and Leprince, Erwan and Denis, Julien and Rao Balappa, Shrisha and Suchkov, Dmitrii and Boyce, Richard and Lopez, Catherine and Giorgi-Kurz, Marie and Szwagier, Tom and Dumont, Théo and Rouault, Hervé and Minlebaev, Marat and Baude, Agnès and Cossart, Rosa and Picardo, Michel A},
	editor = {Peyrache, Adrien and Colgin, Laura L and Butt, Simon JB},
	month = jul,
	year = {2022},
	doi = {10.1101/2021.06.08.447542},
	note = {tex.ids= Dard2021
publisher: eLife Sciences Publications, Ltd
section: New Results
type: article},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e78116},
	file = {2021.06.08.447542v1.full.pdf:/Users/laurentperrinet/Zotero/storage/YPKAWCF3/2021.06.08.447542v1.full.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/9SHFKCNA/Dard et al. - 2021 - The rapid developmental rise of somatic inhibition.pdf:application/pdf;Full Text PDF:/Users/laurentperrinet/Zotero/storage/LSVDSVBW/Dard et al. - 2022 - The rapid developmental rise of somatic inhibition.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/Y6V4T3XM/2021.06.08.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/2ZVWUDMN/Dard et al. - 2021 - The rapid developmental rise of somatic inhibition.pdf:application/pdf},
}

@article{Burkitt2021,
	title = {Predictive {Visual} {Motion} {Extrapolation} {Emerges} {Spontaneously} and without {Supervision} at {Each} {Layer} of a {Hierarchical} {Neural} {Network} with {Spike}-{Timing}-{Dependent} {Plasticity}},
	volume = {41},
	url = {https://doi.org/gjtwzk},
	doi = {10.1523/jneurosci.2017-20.2021},
	language = {en},
	number = {20},
	journal = {The Journal of Neuroscience},
	author = {Burkitt, Anthony N. and Hogendoorn, Hinze},
	year = {2021},
	pmid = {33888603},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.2017-20.2021
tex.ids= Burkitt21
publisher: Society for Neuroscience
section: Research Articles},
	keywords = {⛔ No INSPIRE recid found},
	pages = {4428--4438},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/KEPWF4TS/4428.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/BWN7CUKR/Burkitt et Hogendoorn - 2021 - Predictive Visual Motion Extrapolation Emerges Spo.pdf:application/pdf},
}

@article{Yu1996,
	title = {Temporal hierarchical control of singing in birds.},
	volume = {273},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/8791594},
	doi = {10.1126/science.273.5283.1871},
	abstract = {Songs of birds comprise hierarchical sets of vocal gestures. In zebra finches, songs include notes and syllables (groups of notes) delivered in fixed sequences. During singing, premotor neurons in the forebrain nucleus HVc exhibited reliable changes in activity rates whose patterns were uniquely associated with syllable identity. Neurons in the forebrain nucleus robustus archistriatalis, which receives input from the HVc, exhibited precisely timed and structured bursts of activity that were uniquely associated with note identity. Hence, units of vocal behavior are represented hierarchically in the avian forebrain. The representation of temporal sequences at each level of the hierarchy may be established by means of a decoding process involving interactions of higher level input with intrinsic local circuitry. Behavior is apparently represented by precise temporal patterning of spike trains at lower levels of the hierarchy.},
	number = {5283},
	journal = {Science (New York, N.Y.)},
	author = {Yu, A C and Margoliash, D},
	month = sep,
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:8791594},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1871--5},
}

@article{Weyl1916a,
	title = {Ueber die {Gleichverteilung} von {Zahlen} mod. {Eins}},
	volume = {77},
	url = {https://doi.org/crprvc},
	doi = {10.1007/bf01475864},
	language = {de},
	number = {3},
	journal = {Mathematische Annalen},
	author = {Weyl, Hermann},
	month = sep,
	year = {1916},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/bf01475864},
	keywords = {⛔ No INSPIRE recid found},
	pages = {313--352},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/XE8MQU4D/Weyl - 1916 - �ber die Gleichverteilung von Zahlen mod. Eins.pdf:application/pdf},
}

@article{Wild1993,
	title = {Descending projections of the songbird nucleus robustus archistriatalis.},
	volume = {338},
	issn = {0021-9967},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/8308169},
	doi = {10.1002/cne.903380207},
	abstract = {The descending, efferent projections of nucleus robustus archistriatalis were investigated in male zebra finches and greenfinches with injections of either biotinylated dextran amine or cholera toxin B-chain conjugated to horseradish peroxidase. The results show that in addition to the well-known projections to the tracheosyringeal motor nucleus and the dorsomedial nucleus of the intercollicular complex, there are other projections of comparable density to the ipsilateral nucleus ambiguus and nucleus retroambigualis. Within nucleus ambiguus, robustus axons terminate in close proximity to laryngeal motoneurons which were retrogradely labelled in the same bird by injections of cholera B-chain into the laryngeal muscles; and within nucleus retroambigualis robustus axons terminate in relation to bulbospinal neurons previously shown to project to regions of spinal cord containing motoneurons innervating abdominal expiratory muscles (J.M. Wild, Brain Res. 606:119-124, 1993). These projections of nucleus robustus thus seem well placed to coordinate syringeal, laryngeal, and expiratory muscle activity during vocalization. Other relatively sparse, but distinct, projections of nucleus robustus were found to nucleus dorsolateralis anterior thalami, pars medialis, to a narrow region between the superior olivary nucleus and the spinal lemniscus, and to the rostral ventrolateral medulla. Neurons in these last two locations were retrogradely labelled bilaterally following injections of cholera B-chain into nucleus retroambigualis of one side. Together with sparse contralateral projections of nucleus robustus to all brainstem targets receiving ipsilateral projections, potential pathways are thus identified by which the respiratory-vocal activity controlled by one side of the lower medulla can be influenced by the nucleus robustus of either side, thereby possibly bringing about bilateral coordination of respiratory-vocal output.},
	number = {2},
	journal = {The Journal of comparative neurology},
	author = {Wild, J M},
	year = {1993},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:8308169},
	keywords = {⛔ No INSPIRE recid found},
	pages = {225--41},
}

@article{Wehr1996,
	title = {Odour encoding by temporal sequences of firing in oscillating neural assemblies},
	volume = {384},
	url = {https://doi.org/b3t32c},
	doi = {10.1038/384162a0},
	language = {en},
	number = {6605},
	journal = {Nature},
	author = {Wehr, Michael and Laurent, Gilles},
	month = nov,
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/384162a0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {162--166},
}

@article{Torre2013,
	title = {Statistical evaluation of synchronous spike patterns extracted by frequent item set mining},
	volume = {7},
	url = {https://doi.org/gpshgq},
	doi = {10.3389/fncom.2013.00132},
	journal = {Frontiers in Computational Neuroscience},
	author = {Torre, Emiliano and Picado-Muiño, David and Denker, Michael and Borgelt, Christian and Grün, Sonja},
	year = {2013},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fncom.2013.00132},
	keywords = {⛔ No INSPIRE recid found},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/HSCGQZWA/Torre et al. - 2013 - Statistical evaluation of synchronous spike patter.pdf:application/pdf},
}

@article{Torre2016a,
	title = {{ASSET}: {Analysis} of {Sequences} of {Synchronous} {Events} in {Massively} {Parallel} {Spike} {Trains}},
	volume = {12},
	url = {https://doi.org/gnpx4q},
	doi = {10.1371/journal.pcbi.1004939},
	language = {en},
	number = {7},
	journal = {PLOS Computational Biology},
	author = {Torre, Emiliano and Canova, Carlos and Denker, Michael and Gerstein, George and Helias, Moritz and Grün, Sonja},
	editor = {Sporns, Olaf},
	year = {2016},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1371/journal.pcbi.1004939},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1004939},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/X72F5LNQ/Torre et al. - 2016 - ASSET Analysis of Sequences of Synchronous Events.pdf:application/pdf},
}

@article{Tolle2011,
	title = {The {Fourth} {Paradigm}: {Data}-{Intensive} {Scientific} {Discovery} [{Point} of {View}]},
	volume = {99},
	url = {https://doi.org/dfggjc},
	doi = {10.1109/jproc.2011.2155130},
	number = {8},
	journal = {Proceedings of the IEEE},
	author = {Tolle, Kristin M. and Tansley, D. Stewart W. and Hey, Anthony J. G.},
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1334--1337},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/6Q9A7FFW/Tolle et al. - 2011 - The Fourth Paradigm Data-Intensive Scientific Dis.pdf:application/pdf},
}

@inproceedings{Thanasoulis2021,
	title = {Delay-{Based} {Neural} {Computation}: {Pulse} {Routing} {Architecture} and {Benchmark} {Application} in {FPGA}},
	url = {https://doi.org/gn63rh},
	doi = {10.1109/icecs53924.2021.9665468},
	booktitle = {2021 28th {IEEE} {International} {Conference} on {Electronics}, {Circuits}, and {Systems} ({ICECS})},
	publisher = {IEEE},
	author = {Thanasoulis, Vasilis and Vogginger, Bernhard and Partzsch, Johannes and Mayr, Christian},
	month = nov,
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1109/icecs53924.2021.9665468
tex.ids= Thanasoulis2021a},
	keywords = {⛔ No INSPIRE recid found, Benchmark testing, Hardware, Multicast communication, Neuromorphic engineering, Neurons, Numerical simulation, Routing},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/HS5XQG68/9665468.html:text/html},
}

@article{Thorpe2001,
	title = {Seeking {Categories} in the {Brain}},
	volume = {291},
	url = {https://doi.org/bzn42k},
	doi = {10.1126/science.1058249},
	language = {en},
	number = {5502},
	journal = {Science},
	author = {Thorpe, Simon J. and Fabre-Thorpe, Michèle},
	month = jan,
	year = {2001},
	keywords = {⛔ No INSPIRE recid found},
	pages = {260--263},
}

@article{Thorpe1996,
	title = {Speed of processing in the human visual system},
	volume = {381},
	url = {https://doi.org/c4v35x},
	doi = {10.1038/381520a0},
	language = {en},
	number = {6582},
	journal = {Nature},
	author = {Thorpe, Simon and Fize, Denis and Marlot, Catherine},
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/381520a0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {520--522},
}

@article{Suthers2002,
	title = {Motor control of birdsong.},
	volume = {12},
	issn = {0959-4388},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/12490259},
	doi = {10.1016/s0959-4388(02)00386-0},
	abstract = {One of the challenges when considering the motor control of birdsong is to understand how such a wide variety of temporally and spectrally diverse vocalizations are learned and produced. A better understanding of central neural processing, together with direct endoscopic observations and physiological studies of peripheral motor function during singing, has resulted in the formation of new theoretical models of song production. Recent work suggests that it may be more profitable to focus on the temporal relationship between control parameters than to attempt to directly correlate neural processing with details of the acoustic output.},
	number = {6},
	journal = {Current opinion in neurobiology},
	author = {Suthers, Roderick A and Margoliash, Daniel},
	year = {2002},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:12490259},
	keywords = {⛔ No INSPIRE recid found},
	pages = {684--90},
}

@article{Stringer2021,
	title = {High-precision coding in visual cortex},
	volume = {184},
	url = {https://doi.org/gjqbjd},
	doi = {10.1016/j.cell.2021.03.042},
	language = {en},
	number = {10},
	journal = {Cell},
	author = {Stringer, Carsen and Michaelos, Michalis and Tsyboulski, Dmitri and Lindo, Sarah E. and Pachitariu, Marius},
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.cell.2021.03.042},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2767--2778.e15},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/FHN7UNKB/Stringer et al. - 2021 - High-precision coding in visual cortex.pdf:application/pdf},
}

@article{Stella2019,
	title = {3d-{SPADE}: {Significance} evaluation of spatio-temporal patterns of various temporal extents},
	volume = {185},
	url = {https://doi.org/gpshj2},
	doi = {10.1016/j.biosystems.2019.104022},
	language = {en},
	journal = {Biosystems},
	author = {Stella, Alessandra and Quaglio, Pietro and Torre, Emiliano and Grün, Sonja},
	month = nov,
	year = {2019},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.biosystems.2019.104022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {104022},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/QFJ45PBQ/Stella et al. - 2019 - 3d-SPADE Significance evaluation of spatio-tempor.pdf:application/pdf},
}

@article{Stella2022,
	title = {Comparing {Surrogates} to {Evaluate} {Precisely} {Timed} {Higher}-{Order} {Spike} {Correlations}},
	volume = {9},
	url = {https://doi.org/gqjvht},
	doi = {10.1523/eneuro.0505-21.2022},
	language = {en},
	number = {3},
	journal = {eneuro},
	author = {Stella, Alessandra and Bouss, Peter and Palm, Günther and Grün, Sonja},
	year = {2022},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/eneuro.0505-21.2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {ENEURO.0505--21.2022},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/8CC9VVLG/Stella et al. - 2022 - Comparing Surrogates to Evaluate Precisely Timed H.pdf:application/pdf},
}

@article{Schrader2008,
	title = {Detecting {Synfire} {Chain} {Activity} {Using} {Massively} {Parallel} {Spike} {Train} {Recording}},
	volume = {100},
	url = {https://doi.org/cvb22p},
	doi = {10.1152/jn.01245.2007},
	abstract = {{\textless}jats:p{\textgreater} The synfire chain model has been proposed as the substrate that underlies computational processes in the brain and has received extensive theoretical study. In this model cortical tissue is composed of a superposition of feedforward subnetworks (chains) each capable of transmitting packets of synchronized spikes with high reliability. Computations are then carried out by interactions of these chains. Experimental evidence for synfire chains has so far been limited to inference from detection of a few repeating spatiotemporal neuronal firing patterns in multiple single-unit recordings. Demonstration that such patterns actually come from synfire activity would require finding a meta organization among many detected patterns, as yet an untried approach. In contrast we present here a new method that directly visualizes the repetitive occurrence of synfire activity even in very large data sets of multiple single-unit recordings. We achieve reliability and sensitivity by appropriately averaging over neuron space (identities) and time. We test the method with data from a large-scale balanced recurrent network simulation containing 50 randomly activated synfire chains. The sensitivity is high enough to detect synfire chain activity in simultaneous single-unit recordings of 100 to 200 neurons from such data, enabling application to experimental data in the near future. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {4},
	journal = {Journal of Neurophysiology},
	author = {Schrader, Sven and Grün, Sonja and Diesmann, Markus and Gerstein, George L.},
	month = oct,
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1152/jn.01245.2007},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2165--2176},
}

@article{Singer1995,
	title = {Visual {Feature} {Integration} and the {Temporal} {Correlation} {Hypothesis}},
	volume = {18},
	url = {https://doi.org/cgx8jp},
	doi = {10.1146/annurev.ne.18.030195.003011},
	language = {en},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Singer, W and Gray, C M},
	month = mar,
	year = {1995},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1146/annurev.ne.18.030195.003011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {555--586},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/UNNCS4CK/Singer et Gray - 1995 - Visual Feature Integration and the Temporal Correl.pdf:application/pdf},
}

@article{Roelfsema1997,
	title = {Visuomotor integration is associated with zero time-lag synchronization among cortical areas},
	volume = {385},
	url = {https://doi.org/dp8q5v},
	doi = {10.1038/385157a0},
	language = {en},
	number = {6612},
	journal = {Nature},
	author = {Roelfsema, Pieter R. and Engel, Andreas K. and König, Peter and Singer, Wolf},
	month = jan,
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/385157a0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {157--161},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/4QF3B9CL/Roelfsema et al. - 1997 - Visuomotor integration is associated with zero tim.pdf:application/pdf},
}

@article{Quaglio2018,
	title = {Methods for identification of spike patterns in massively parallel spike trains},
	volume = {112},
	url = {https://doi.org/gdgckg},
	doi = {10.1007/s00422-018-0755-0},
	language = {en},
	number = {1-2},
	journal = {Biological Cybernetics},
	author = {Quaglio, Pietro and Rostami, Vahid and Torre, Emiliano and Grün, Sonja},
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s00422-018-0755-0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {57--80},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/MBN3RU83/Quaglio et al. - 2018 - Methods for identification of spike patterns in ma.pdf:application/pdf},
}

@article{Pfeil2013,
	title = {Six {Networks} on a {Universal} {Neuromorphic} {Computing} {Substrate}},
	volume = {7},
	url = {https://doi.org/gh4jg3},
	doi = {10.3389/fnins.2013.00011},
	journal = {Frontiers in Neuroscience},
	author = {Pfeil, Thomas and Grübl, Andreas and Jeltsch, Sebastian and Müller, Eric and Müller, Paul and Petrovici, Mihai A. and Schmuker, Michael and Brüderle, Daniel and Schemmel, Johannes and Meier, Karlheinz},
	year = {2013},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fnins.2013.00011},
	keywords = {⛔ No INSPIRE recid found},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/RL5XMN3V/Pfeil et al. - 2013 - Six Networks on a Universal Neuromorphic Computing.pdf:application/pdf},
}

@article{Perkel1967,
	title = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}: {I}. {The} {Single} {Spike} {Train}},
	volume = {7},
	issn = {0006-3495},
	shorttitle = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}},
	url = {https://www.sciencedirect.com/science/article/pii/S0006349567865962},
	doi = {10.1016/S0006-3495(67)86596-2},
	abstract = {In a growing class of neurophysiological experiments, the train of impulses (“spikes”) produced by a nerve cell is subjected to statistical treatment involving the time intervals between spikes. The statistical techniques available for the analysis of single spike trains are described and related to the underlying mathematical theory, that of stochastic point processes, i.e., of stochastic processes whose realizations may be described as series of point events occurring in time, separated by random intervals. For single stationary spike trains, several orders of complexity of statistical treatment are described; the major distinction is that between statistical measures that depend in an essential way on the serial order of interspike intervals and those that are order-independent. The interrelations among the several types of calculations are shown, and an attempt is made to ameliorate the current nomenclatural confusion in this field. Applications, interpretations, and potential difficulties of the statistical techniques are discussed, with special reference to types of spike trains encountered experimentally. Next, the related types of analysis are described for experiments which involve repeated presentations of a brief, isolated stimulus. Finally, the effects of nonstationarity, e.g. long-term changes in firing rate, on the various statistical measures are discussed. Several commonly observed patterns of spike activity are shown to be differentially sensitive to such changes. A companion paper covers the analysis of simultaneously observed spike trains.},
	language = {en},
	number = {4},
	urldate = {2022-10-04},
	journal = {Biophysical Journal},
	author = {Perkel, Donald H. and Gerstein, George L. and Moore, George P.},
	month = jul,
	year = {1967},
	keywords = {⛔ No INSPIRE recid found},
	pages = {391--418},
	file = {ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/VIS7UMV2/S0006349567865962.html:text/html},
}

@article{Perkel1967a,
	title = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}: {II}. {Simultaneous} {Spike} {Trains}},
	volume = {7},
	issn = {0006-3495},
	shorttitle = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}},
	url = {https://www.sciencedirect.com/science/article/pii/S0006349567865974},
	doi = {10.1016/S0006-3495(67)86597-4},
	abstract = {The statistical analysis of two simultaneously observed trains of neuronal spikes is described, using as a conceptual framework the theory of stochastic point processes. The first statistical question that arises is whether the observed trains are independent; statistical techniques for testing independence are developed around the notion that, under the null hypothesis, the times of spike occurrence in one train represent random instants in time with respect to the other. If the null hypothesis is rejected—if dependence is attributed to the trains—the problem then becomes that of characterizing the nature and source of the observed dependencies. Statistical signs of various classes of dependencies, including direct interaction and shared input, are discussed and illustrated through computer simulations of interacting neurons. The effects of nonstationarities on the statistical measures for simultaneous spike trains are also discussed. For two-train comparisons of irregularly discharging nerve cells, moderate nonstationarities are shown to have little effect on the detection of interactions. Combining repetitive stimulation and simultaneous recording of spike trains from two (or more) neurons yields additional clues as to possible modes of interaction among the monitored neurons; the theory presented is illustrated by an application to experimentally obtained data from auditory neurons. A companion paper covers the analysis of single spike trains.},
	language = {en},
	number = {4},
	urldate = {2022-10-04},
	journal = {Biophysical Journal},
	author = {Perkel, Donald H. and Gerstein, George L. and Moore, George P.},
	month = jul,
	year = {1967},
	keywords = {⛔ No INSPIRE recid found},
	pages = {419--440},
	file = {ScienceDirect Full Text PDF:/Users/laurentperrinet/Zotero/storage/CVDZ48MY/Perkel et al. - 1967 - Neuronal Spike Trains and Stochastic Point Process.pdf:application/pdf},
}

@article{Pachitariu2018,
	title = {Robustness of {Spike} {Deconvolution} for {Neuronal} {Calcium} {Imaging}},
	volume = {38},
	url = {https://doi.org/gd9mcx},
	doi = {10.1523/jneurosci.3339-17.2018},
	language = {en},
	number = {37},
	journal = {The Journal of Neuroscience},
	author = {Pachitariu, Marius and Stringer, Carsen and Harris, Kenneth D.},
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.3339-17.2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {7976--7985},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/NXMTLUJG/Pachitariu et al. - 2018 - Robustness of Spike Deconvolution for Neuronal Cal.pdf:application/pdf},
}

@article{Nowak1997,
	title = {Influence of low and high frequency inputs on spike timing in visual cortical neurons},
	volume = {7},
	url = {https://doi.org/fvjpx7},
	doi = {10.1093/cercor/7.6.487},
	number = {6},
	journal = {Cerebral Cortex},
	author = {Nowak, L.},
	month = sep,
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1093/cercor/7.6.487},
	keywords = {⛔ No INSPIRE recid found},
	pages = {487--501},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/QYAWWSYV/Nowak - 1997 - Influence of low and high frequency inputs on spik.pdf:application/pdf},
}

@incollection{Nowak1997a,
	title = {The {Timing} of {Information} {Transfer} in the {Visual} {System}},
	url = {https://doi.org/gpb33s},
	booktitle = {Extrastriate {Cortex} in {Primates}},
	publisher = {Springer US},
	author = {Nowak, Lionel G. and Bullier, Jean},
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/978-1-4757-9625-4\_5},
	keywords = {⛔ No INSPIRE recid found},
	pages = {205--241},
}

@article{Muller2014,
	title = {The stimulus-evoked population response in visual cortex of awake monkey is a propagating wave},
	volume = {5},
	issn = {2041-1723},
	doi = {10.1038/ncomms4675},
	abstract = {Propagating waves occur in many excitable media and were recently found in neural systems from retina to neocortex. While propagating waves are clearly present under anaesthesia, whether they also appear during awake and conscious states remains unclear. One possibility is that these waves are systematically missed in trial-averaged data, due to variability. Here we present a method for detecting propagating waves in noisy multichannel recordings. Applying this method to single-trial voltage-sensitive dye imaging data, we show that the stimulus-evoked population response in primary visual cortex of the awake monkey propagates as a travelling wave, with consistent dynamics across trials. A network model suggests that this reliability is the hallmark of the horizontal fibre network of superficial cortical layers. Propagating waves with similar properties occur independently in secondary visual cortex, but maintain precise phase relations with the waves in primary visual cortex. These results show that, in response to a visual stimulus, propagating waves are systematically evoked in several visual areas, generating a consistent spatiotemporal frame for further neuronal interactions.},
	journal = {Nature Communications},
	author = {Muller, Lyle and Reynaud, Alexandre and Chavane, Frédéric and Destexhe, Alain},
	year = {2014},
	note = {00068
Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Muller14},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3675},
	annote = {00068 Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Muller14},
	annote = {00068 Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Muller14},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/I2MWBMF6/Muller et al. - 2014 - The stimulus-evoked population response in visual .pdf:application/pdf},
}

@article{Muller2018,
	title = {Cortical travelling waves: {Mechanisms} and computational principles},
	issn = {1471-003X},
	shorttitle = {Cortical travelling waves},
	url = {http://www.nature.com/doifinder/10.1038/nrn.2018.20},
	doi = {10.1038/nrn.2018.20},
	abstract = {Advanced recording techniques have enabled the identification of travelling waves of neuronal activity in different areas of the cortex. Sejnowski and colleagues review these findings, consider the mechanisms by which travelling waves are generated and evaluate their possible roles in cortical function.},
	journal = {Nature Reviews Neuroscience},
	author = {Muller, Lyle and Chavane, Frédéric and Reynolds, John and Sejnowski, Terrence J.},
	month = mar,
	year = {2018},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Muller18},
	keywords = {⛔ No INSPIRE recid found},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Muller18},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Muller18},
	file = {Version acceptée:/Users/laurentperrinet/Zotero/storage/RHF9IW6U/Muller et al. - 2018 - Cortical travelling waves Mechanisms and computat.pdf:application/pdf},
}

@article{Miller2014,
	title = {Visual stimuli recruit intrinsically generated cortical ensembles},
	volume = {111},
	url = {https://doi.org/f6htkt},
	doi = {10.1073/pnas.1406077111},
	abstract = {{\textless}jats:title{\textgreater}Significance{\textless}/jats:title{\textgreater}
          {\textless}jats:p{\textgreater}This study demonstrates that neuronal groups or ensembles, rather than individual neurons, are emergent functional units of cortical activity. We show that in the presence and absence of visual stimulation, cortical activity is dominated by coactive groups of neurons forming ensembles. These ensembles are flexible and cannot be accounted for by the independent firing properties of neurons in isolation. Intrinsically generated ensembles and stimulus-evoked ensembles are similar, with one main difference: Whereas intrinsic ensembles recur at random time intervals, visually evoked ensembles are time-locked to stimuli. We propose that visual stimuli recruit endogenously generated ensembles to represent visual attributes.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {38},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Miller, Jae-eun Kang and Ayzenshtat, Inbal and Carrillo-Reid, Luis and Yuste, Rafael},
	month = sep,
	year = {2014},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1073/pnas.1406077111},
	keywords = {⛔ No INSPIRE recid found},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/UV33RQ2H/Miller et al. - 2014 - Visual stimuli recruit intrinsically generated cor.pdf:application/pdf},
}

@article{Markram1997a,
	title = {Regulation of {Synaptic} {Efficacy} by {Coincidence} of {Postsynaptic} {APs} and {EPSPs}},
	volume = {275},
	url = {https://doi.org/ftvvd8},
	doi = {10.1126/science.275.5297.213},
	abstract = {{\textless}jats:p{\textgreater}Activity-driven modifications in synaptic connections between neurons in the neocortex may occur during development and learning. In dual whole-cell voltage recordings from pyramidal neurons, the coincidence of postsynaptic action potentials (APs) and unitary excitatory postsynaptic potentials (EPSPs) was found to induce changes in EPSPs. Their average amplitudes were differentially up- or down-regulated, depending on the precise timing of postsynaptic APs relative to EPSPs. These observations suggest that APs propagating back into dendrites serve to modify single active synaptic connections, depending on the pattern of electrical activity in the pre- and postsynaptic neurons.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {5297},
	journal = {Science},
	author = {Markram, Henry and Lübke, Joachim and Frotscher, Michael and Sakmann, Bert},
	month = jan,
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.275.5297.213},
	keywords = {⛔ No INSPIRE recid found},
	pages = {213--215},
}

@article{MadadiAsl2022,
	title = {Delay-dependent transitions of phase synchronization and coupling symmetry between neurons shaped by spike-timing-dependent plasticity},
	issn = {1871-4099},
	url = {https://doi.org/10.1007/s11571-022-09850-x},
	doi = {10.1007/s11571-022-09850-x},
	abstract = {Synchronization plays a key role in learning and memory by facilitating the communication between neurons promoted by synaptic plasticity. Spike-timing-dependent plasticity (STDP) is a form of synaptic plasticity that modifies the strength of synaptic connections between neurons based on the coincidence of pre- and postsynaptic spikes. In this way, STDP simultaneously shapes the neuronal activity and synaptic connectivity in a feedback loop. However, transmission delays due to the physical distance between neurons affect neuronal synchronization and the symmetry of synaptic coupling. To address the question that how transmission delays and STDP can jointly determine the emergent pairwise activity-connectivity patterns, we studied phase synchronization properties and coupling symmetry between two bidirectionally coupled neurons using both phase oscillator and conductance-based neuron models. We show that depending on the range of transmission delays, the activity of the two-neuron motif can achieve an in-phase/anti-phase synchronized state and its connectivity can attain a symmetric/asymmetric coupling regime. The coevolutionary dynamics of the neuronal system and the synaptic weights due to STDP stabilizes the motif in either one of these states by transitions between in-phase/anti-phase synchronization states and symmetric/asymmetric coupling regimes at particular transmission delays. These transitions crucially depend on the phase response curve (PRC) of the neurons, but they are relatively robust to the heterogeneity of transmission delays and potentiation-depression imbalance of the STDP profile.},
	language = {en},
	urldate = {2022-09-18},
	journal = {Cognitive Neurodynamics},
	author = {Madadi Asl, Mojtaba and Ramezani Akbarabadi, Saeideh},
	month = jul,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found, Coupling symmetry, Spike-timing-dependent plasticity, Synaptic plasticity, Synchronization, Transmission delay},
}

@article{Levakova2015,
	title = {A review of the methods for neuronal response latency estimation},
	volume = {136},
	url = {https://doi.org/gpshjz},
	doi = {10.1016/j.biosystems.2015.04.008},
	language = {en},
	journal = {Biosystems},
	author = {Levakova, Marie and Tamborrino, Massimiliano and Ditlevsen, Susanne and Lansky, Petr},
	month = oct,
	year = {2015},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.biosystems.2015.04.008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {23--34},
}

@article{Kremkow2010,
	title = {Functional consequences of correlated excitatory and inhibitory conductances in cortical networks},
	volume = {28},
	url = {https://doi.org/c3wrbn},
	doi = {10.1007/s10827-010-0240-9},
	language = {en},
	number = {3},
	journal = {Journal of Computational Neuroscience},
	author = {Kremkow, Jens and Perrinet, Laurent U. and Masson, Guillaume S. and Aertsen, Ad},
	year = {2010},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s10827-010-0240-9},
	keywords = {⛔ No INSPIRE recid found},
	pages = {579--594},
}

@article{Kirchner2006,
	title = {Ultra-rapid object detection with saccadic eye movements: {Visual} processing speed revisited},
	volume = {46},
	issn = {0042-6989},
	shorttitle = {Ultra-rapid object detection with saccadic eye movements},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698905005110},
	doi = {10.1016/j.visres.2005.10.002},
	abstract = {Previous ultra-rapid go/no-go categorization studies with manual responses have demonstrated the remarkable speed and efficiency with which humans process natural scenes. Using a forced-choice saccade task we show here that when two scenes are simultaneously flashed in the left and right hemifields, human participants can reliably make saccades to the side containing an animal in as little as 120 ms. Low level differences between target and distractor images were unable to account for these exceptionally fast responses. The results suggest a very fast and unexpected route linking visual processing in the ventral stream with the programming of saccadic eye movements.},
	number = {11},
	journal = {Vision Research},
	author = {Kirchner, H and Thorpe, Sj},
	year = {2006},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Kirchner06},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1762--76},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Kirchner06},
	annote = {Loaded from an external bibliography file by Manubot. source\_bibliography: manual-references.bib standard\_id: Kirchner06},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/B8TXQQ5F/Kirchner et Thorpe - 2006 - Ultra-rapid object detection with saccadic eye mov.pdf:application/pdf},
}

@article{Kilavik2009,
	title = {Long-{Term} {Modifications} in {Motor} {Cortical} {Dynamics} {Induced} by {Intensive} {Practice}},
	volume = {29},
	url = {https://doi.org/bf84ps},
	doi = {10.1523/jneurosci.1554-09.2009},
	language = {en},
	number = {40},
	journal = {Journal of Neuroscience},
	author = {Kilavik, B. E. and Roux, S. and Ponce-Alvarez, A. and Confais, J. and Grun, S. and Riehle, A.},
	month = oct,
	year = {2009},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.1554-09.2009},
	keywords = {⛔ No INSPIRE recid found},
	pages = {12653--12663},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/D6IWG7M8/Kilavik et al. - 2009 - Long-Term Modifications in Motor Cortical Dynamics.pdf:application/pdf},
}

@article{Kheradpisheh2018,
	title = {{STDP}-based spiking deep convolutional neural networks for object recognition},
	volume = {99},
	url = {https://doi.org/gc6dqh},
	doi = {10.1016/j.neunet.2017.12.005},
	language = {en},
	journal = {Neural Networks},
	author = {Kheradpisheh, Saeed Reza and Ganjtabesh, Mohammad and Thorpe, Simon J. and Masquelier, Timothée},
	month = mar,
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neunet.2017.12.005},
	keywords = {⛔ No INSPIRE recid found},
	pages = {56--67},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/D7CZ9WR4/Kheradpisheh et al. - 2018 - STDP-based spiking deep convolutional neural netwo.pdf:application/pdf},
}

@article{Keysers2001,
	title = {The {Speed} of {Sight}},
	volume = {13},
	url = {https://doi.org/cfdjtg},
	doi = {10.1162/089892901564199},
	abstract = {{\textless}jats:title{\textgreater}Abstract{\textless}/jats:title{\textgreater}
               {\textless}jats:p{\textgreater}Macaque monkeys were presented with continuous rapid serial visual presentation (RSVP) sequences of unrelated naturalistic images at rates of 14-222 msec/image, while neurons that responded selectively to complex patterns (e.g., faces) were recorded in temporal cortex. Stimulus selectivity was preserved for 65\% of these neurons even at surprisingly fast presentation rates (14 msec/image or 72 images/sec). Five human subjects were asked to detect or remember images under equivalent conditions. Their performance in both tasks was above chance at all rates (14-111 msec/image). The performance of single neurons was comparable to that of humans and responded in a similar way to changes in presentation rate. The implications for the role of temporal cortex cells in perception are discussed.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {1},
	journal = {Journal of Cognitive Neuroscience},
	author = {Keysers, C. and Xiao, D.-K. and Földiák, P. and Perrett, D. I.},
	month = jan,
	year = {2001},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1162/089892901564199},
	keywords = {⛔ No INSPIRE recid found},
	pages = {90--101},
}

@article{Kenyon2004,
	title = {A theory of the {Benham} {Top} based on center–surround interactions in the parvocellular pathway},
	volume = {17},
	url = {https://doi.org/bjwzzt},
	doi = {10.1016/j.neunet.2004.05.005},
	language = {en},
	number = {5-6},
	journal = {Neural Networks},
	author = {Kenyon, Garrett T and Hill, Dan and Theiler, James and George, John S and Marshak, David W},
	year = {2004},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neunet.2004.05.005},
	keywords = {⛔ No INSPIRE recid found},
	pages = {773--786},
	file = {Version acceptée:/Users/laurentperrinet/Zotero/storage/8QCTGWG5/Kenyon et al. - 2004 - A theory of the Benham Top based on center–surroun.pdf:application/pdf},
}

@article{Johansson2004,
	title = {First spikes in ensembles of human tactile afferents code complex spatial fingertip events},
	volume = {7},
	url = {https://doi.org/dqstpm},
	doi = {10.1038/nn1177},
	language = {en},
	number = {2},
	journal = {Nature Neuroscience},
	author = {Johansson, Roland S and Birznieks, Ingvars},
	month = jan,
	year = {2004},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/nn1177},
	keywords = {⛔ No INSPIRE recid found},
	pages = {170--177},
}

@article{Harris2003,
	title = {Organization of cell assemblies in the hippocampus},
	volume = {424},
	url = {https://doi.org/bm3vgb},
	doi = {10.1038/nature01834},
	language = {en},
	number = {6948},
	journal = {Nature},
	author = {Harris, Kenneth D. and Csicsvari, Jozsef and Hirase, Hajime and Dragoi, George and Buzsáki, György},
	year = {2003},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/nature01834},
	keywords = {⛔ No INSPIRE recid found},
	pages = {552--556},
}

@article{Perrinet2001a,
	title = {Networks of integrate-and-fire neuron using rank order coding {A}: {How} to implement spike time dependent {Hebbian} plasticity},
	volume = {38-40},
	url = {https://doi.org/d5p6b2},
	doi = {10.1016/s0925-2312(01)00460-x},
	language = {en},
	journal = {Neurocomputing},
	author = {Perrinet, L. and Delorme, A. and Samuelides, M. and Thorpe, S.J.},
	year = {2001},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/s0925-2312(01)00460-x
tex.ids= Perrinet2001a},
	keywords = {⛔ No INSPIRE recid found, Hebb rule, Kinetic model, Rank order coding, Spike time dependent Hebbian plasticity, Spiking neural networks},
	pages = {817--822},
}

@article{Luczak2015,
	title = {Packet-based communication in the cortex.},
	volume = {16},
	issn = {1471-0048},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/26507295},
	doi = {10.1038/nrn4026},
	abstract = {Cortical circuits work through the generation of coordinated, large-scale activity patterns. In sensory systems, the onset of a discrete stimulus usually evokes a temporally organized packet of population activity lasting ∼50-200 ms. The structure of these packets is partially stereotypical, and variation in the exact timing and number of spikes within a packet conveys information about the identity of the stimulus. Similar packets also occur during ongoing stimuli and spontaneously. We suggest that such packets constitute the basic building blocks of cortical coding.},
	number = {12},
	journal = {Nature reviews. Neuroscience},
	author = {Luczak, Artur and McNaughton, Bruce L and Harris, Kenneth D},
	month = oct,
	year = {2015},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:26507295
tex.ids= Luczak15
number: 12
publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found, Cortex, Neural decoding, Neuronal physiology},
	pages = {745--55},
}

@article{Kremkow2016a,
	title = {Push-{Pull} {Receptive} {Field} {Organization} and {Synaptic} {Depression}: {Mechanisms} for {Reliably} {Encoding} {Naturalistic} {Stimuli} in {V1}},
	volume = {10},
	url = {https://doi.org/ggkdkh},
	doi = {10.3389/fncir.2016.00037},
	journal = {Frontiers in Neural Circuits},
	author = {Kremkow, Jens and Perrinet, Laurent U. and Monier, Cyril and Alonso, Jose-Manuel and Aertsen, Ad and Frégnac, Yves and Masson, Guillaume S.},
	year = {2016},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fncir.2016.00037
tex.ids= Kremkow2016
tex.date-modified: 2019-09-02 15:45:35 +0200
tex.grants: facets
tex.preprint: https://hal.archives-ouvertes.fr/hal-02062034
publisher: Frontiers
url: http://journal.frontiersin.org/article/10.3389/fncir.2016.00037/abstract},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, area V1, area-v1, Excitation/inhibition, natural visual stimuli, push-pull receptive field, RetinaClouds, Sensory coding, statistics of natural images, Visual Cortex},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/4RAGV43Q/Kremkow et al. - 2016 - Push-Pull Receptive Field Organization and Synapti.pdf:application/pdf},
}

@article{LeBec2022,
	title = {Horizontal connectivity in {V1}: {Prediction} of coherence in contour and motion integration},
	volume = {17},
	issn = {1932-6203},
	shorttitle = {Horizontal connectivity in {V1}},
	url = {https://dx.plos.org/10.1371/journal.pone.0268351},
	doi = {10.1371/journal.pone.0268351},
	abstract = {This study demonstrates the functional importance of the Surround context relayed laterally in V1 by the horizontal connectivity, in controlling the latency and the gain of the cortical response to the feedforward visual drive. We report here four main findings: 1) a centripetal apparent motion sequence results in a shortening of the spiking latency of V1 cells, when the orientation of the local inducer and the global motion axis are both co-aligned with the RF orientation preference; 2) this contextual effects grows with visual flow speed, peaking at 150–250°/s when it matches the propagation speed of horizontal connectivity (0.15–0.25 mm/ms); 3) For this speed range, the axial sensitivity of V1 cells is tilted by 90° to become co-aligned with the orientation preference axis; 4) the strength of modulation by the surround context correlates with the spatiotemporal coherence of the apparent motion flow. Our results suggest an internally-generated binding process, linking local (orientation /position) and global (motion/direction) features as early as V1. This long-range diffusion process constitutes a plausible substrate in V1 of the human psychophysical bias in speed estimation for collinear motion. Since it is demonstrated in the anesthetized cat, this novel form of contextual control of the cortical gain and phase is a built-in property in V1, whose expression does not require behavioral attention and top-down control from higher cortical areas. We propose that horizontal connectivity participates in the propagation of an internal “prediction” wave, shaped by visual experience, which links contour co-alignment and global axial motion at an apparent speed in the range of saccade-like eye movements.},
	language = {en},
	number = {7},
	urldate = {2022-09-26},
	journal = {PLOS ONE},
	author = {Le Bec, Benoit and Troncoso, Xoana G. and Desbois, Christophe and Passarelli, Yannick and Baudot, Pierre and Monier, Cyril and Pananceau, Marc and Frégnac, Yves},
	editor = {Charpier, Stéphane},
	month = jul,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e0268351},
	file = {Le Bec et al. - 2022 - Horizontal connectivity in V1 Prediction of coher.pdf:/Users/laurentperrinet/Zotero/storage/Q5T8PE4Y/Le Bec et al. - 2022 - Horizontal connectivity in V1 Prediction of coher.pdf:application/pdf},
}

@article{Khoei2013a,
	title = {Motion-based prediction explains the role of tracking in motion extrapolation},
	volume = {107},
	issn = {09284257},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092842571300051X},
	doi = {10.1016/j.jphysparis.2013.08.001},
	abstract = {During normal viewing, the continuous stream of visual input is regularly interrupted, for instance by blinks of the eye. Despite these frequents blanks (that is the transient absence of a raw sensory source), the visual system is most often able to maintain a continuous representation of motion. For instance, it maintains the movement of the eye such as to stabilize the image of an object. This ability suggests the existence of a generic neural mechanism of motion extrapolation to deal with fragmented inputs. In this paper, we have modeled how the visual system may extrapolate the trajectory of an object during a blank using motion-based prediction. This implies that using a prior on the coherency of motion, the system may integrate previous motion information even in the absence of a stimulus. In order to compare with experimental results, we simulated tracking velocity responses. We found that the response of the motion integration process to a blanked trajectory pauses at the onset of the blank, but that it quickly recovers the information on the trajectory after reappearance. This is compatible with behavioral and neural observations on motion extrapolation. To understand these mechanisms, we have recorded the response of the model to a noisy stimulus. Crucially, we found that motion-based prediction acted at the global level as a gain control mechanism and that we could switch from a smooth regime to a binary tracking behavior where the dot is tracked or lost. Our results imply that a local prior implementing motion-based prediction is sufﬁcient to explain a large range of neural and behavioral results at a more global level. We show that the tracking behavior deteriorates for sensory noise levels higher than a certain value, where motion coherency and predictability fail to hold longer. In particular, we found that motion-based prediction leads to the emergence of a tracking behavior only when enough information from the trajectory has been accumulated. Then, during tracking, trajectory estimation is robust to blanks even in the presence of relatively high levels of noise. Moreover, we found that tracking is necessary for motion extrapolation, this calls for further experimental work exploring the role of noise in motion extrapolation.},
	language = {en},
	number = {5},
	urldate = {2022-10-17},
	journal = {Journal of Physiology-Paris},
	author = {Khoei, Mina A. and Masson, Guillaume S. and Perrinet, Laurent U.},
	month = nov,
	year = {2013},
	keywords = {⛔ No INSPIRE recid found},
	pages = {409--420},
	file = {Khoei et al. - 2013 - Motion-based prediction explains the role of track.pdf:/Users/laurentperrinet/Zotero/storage/EMIFVJ2X/Khoei et al. - 2013 - Motion-based prediction explains the role of track.pdf:application/pdf},
}

@article{Ghosh2022,
	title = {The synchronized dynamics of time-varying networks},
	volume = {949},
	issn = {03701573},
	url = {http://arxiv.org/abs/2109.07618},
	doi = {10.1016/j.physrep.2021.10.006},
	abstract = {Over the past two decades, complex network theory provided the ideal framework for investigating the intimate relationships between the topological properties characterizing the wiring of connections among a system's unitary components and its emergent synchronized functioning. An increased number of setups from the real world found therefore a representation in term of graphs, while more and more sophisticated methods were developed with the aim of furnishing a realistic description of the connectivity patterns under study. In particular, a significant number of systems in physics, biology and social science features a time-varying nature of the interactions among their units. We here give a comprehensive review of the major results obtained by contemporary studies on the emergence of synchronization in time-varying networks. In particular, two paradigmatic frameworks will be described in details. The first encompasses those systems where the time dependence of the nodes' connections is due to adaptation, external forces, or any other process affecting each of the links of the network. The second framework, instead, corresponds to the case in which the structural evolution of the graph is due to the movement of the nodes, or agents, in physical spaces and to the fact that interactions may be ruled by space-dependent laws in a way that connections are continuously switched on and off in the course of the time. Finally, our report ends with a short discussion on promising directions and open problems for future studies.},
	urldate = {2022-10-17},
	journal = {Physics Reports},
	author = {Ghosh, Dibakar and Frasca, Mattia and Rizzo, Alessandro and Majhi, Soumen and Rakshit, Sarbendu and Alfaro-Bittner, Karin and Boccaletti, Stefano},
	month = feb,
	year = {2022},
	note = {arXiv:2109.07618 [physics]},
	keywords = {⛔ No INSPIRE recid found, Physics - Physics and Society},
	pages = {1--63},
	annote = {arXiv:2109.07618 [physics]},
	annote = {arXiv:2109.07618 [physics]},
	annote = {Comment: 76 pages, 34 figures},
	annote = {Comment: 76 pages, 34 figures},
}

@article{Lee2004,
	title = {A {Combinatorial} {Method} for {Analyzing} {Sequential} {Firing} {Patterns} {Involving} an {Arbitrary} {Number} of {Neurons} {Based} on {Relative} {Time} {Order}},
	volume = {92},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.01030.2003},
	doi = {10.1152/jn.01030.2003},
	abstract = {Information processing in the brain is believed to require coordinated activity across many neurons. With the recent development of techniques for simultaneously recording the spiking activity of large numbers of individual neurons, the search for complex multicell firing patterns that could help reveal this neural code has become possible. Here we develop a new approach for analyzing sequential firing patterns involving an arbitrary number of neurons based on relative firing order. Specifically, we develop a combinatorial method for quantifying the degree of matching between a “reference sequence” of N distinct “letters” (representing a particular target order of firing by N cells) and an arbitrarily long “word” composed of any subset of those letters including repeats (representing the relative time order of spikes in an arbitrary firing pattern). The method involves computing the probability that a random permutation of the word's letters would by chance alone match the reference sequence as well as or better than the actual word does, assuming all permutations were equally likely. Lower probabilities thus indicate better matching. The overall degree and statistical significance of sequence matching across a heterogeneous set of words (such as those produced during the course of an experiment) can be computed from the corresponding set of probabilities. This approach can reduce the sample size problem associated with analyzing complex firing patterns. The approach is general and thus applicable to other types of neural data beyond multiple spike trains, such as EEG events or imaging signals from multiple locations. We have recently applied this method to quantify memory traces of sequential experience in the rodent hippocampus during slow wave sleep.},
	language = {en},
	number = {4},
	urldate = {2022-10-17},
	journal = {Journal of Neurophysiology},
	author = {Lee, Albert K. and Wilson, Matthew A.},
	month = oct,
	year = {2004},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2555--2573},
}

@article{Nadasdy1999,
	title = {Replay and {Time} {Compression} of {Recurring} {Spike} {Sequences} in the {Hippocampus}},
	volume = {19},
	copyright = {Copyright © 1999 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/19/21/9497},
	doi = {10.1523/JNEUROSCI.19-21-09497.1999},
	abstract = {Information in neuronal networks may be represented by the spatiotemporal patterns of spikes. Here we examined the temporal coordination of pyramidal cell spikes in the rat hippocampus during slow-wave sleep. In addition, rats were trained to run in a defined position in space (running wheel) to activate a selected group of pyramidal cells. A template-matching method and a joint probability map method were used for sequence search. Repeating spike sequences in excess of chance occurrence were examined by comparing the number of repeating sequences in the original spike trains and in surrogate trains after Monte Carlo shuffling of the spikes. Four different shuffling procedures were used to control for the population dynamics of hippocampal neurons. Repeating spike sequences in the recorded cell assemblies were present in both the awake and sleeping animal in excess of what might be predicted by random variations. Spike sequences observed during wheel running were “replayed” at a faster timescale during single sharp-wave bursts of slow-wave sleep. We hypothesize that the endogenously expressed spike sequences during sleep reflect reactivation of the circuitry modified by previous experience. Reactivation of acquired sequences may serve to consolidate information.},
	language = {en},
	number = {21},
	urldate = {2022-10-17},
	journal = {Journal of Neuroscience},
	author = {Nádasdy, Zoltán and Hirase, Hajime and Czurkó, András and Csicsvari, Jozsef and Buzsáki, György},
	month = nov,
	year = {1999},
	pmid = {10531452},
	note = {Publisher: Society for Neuroscience
Section: ARTICLE},
	keywords = {⛔ No INSPIRE recid found, coding, decoding, memory, network, retrieval, sharp waves, sleep, θ},
	pages = {9497--9507},
	annote = {Publisher: Society for Neuroscience Section: ARTICLE},
	annote = {Publisher: Society for Neuroscience Section: ARTICLE},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/WPK6SWQ6/Nádasdy et al. - 1999 - Replay and Time Compression of Recurring Spike Seq.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/XY8NFG92/9497.html:text/html},
}

@article{Aronov2004,
	title = {Non-{Euclidean} properties of spike train metric spaces},
	volume = {69},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.69.061905},
	doi = {10.1103/PhysRevE.69.061905},
	abstract = {Quantifying the dissimilarity (or distance) between two sequences is essential to the study of action potential (spike) trains in neuroscience and genetic sequences in molecular biology. In neuroscience, traditional methods for sequence comparisons rely on techniques appropriate for multivariate data, which typically assume that the space of sequences is intrinsically Euclidean. More recently, metrics that do not make this assumption have been introduced for comparison of neural activity patterns. These metrics have a formal resemblance to those used in the comparison of genetic sequences. Yet the relationship between such metrics and the traditional Euclidean distances has remained unclear. We show, both analytically and computationally, that the geometries associated with metric spaces of event sequences are intrinsically non-Euclidean. Our results demonstrate that metric spaces enrich the study of neural activity patterns, since accounting for perceptual spaces requires a non-Euclidean geometry.},
	number = {6},
	urldate = {2022-10-17},
	journal = {Physical Review E},
	author = {Aronov, Dmitriy and Victor, Jonathan D.},
	month = jun,
	year = {2004},
	note = {Publisher: American Physical Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {061905},
	annote = {Publisher: American Physical Society},
	annote = {Publisher: American Physical Society},
	file = {APS Snapshot:/Users/laurentperrinet/Zotero/storage/Z7442CMX/PhysRevE.69.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/BCDP3E23/Aronov et Victor - 2004 - Non-Euclidean properties of spike train metric spa.pdf:application/pdf},
}

@article{Victor1996,
	title = {Nature and precision of temporal coding in visual cortex: a metric-space analysis},
	volume = {76},
	issn = {0022-3077, 1522-1598},
	shorttitle = {Nature and precision of temporal coding in visual cortex},
	url = {https://www.physiology.org/doi/10.1152/jn.1996.76.2.1310},
	doi = {10.1152/jn.1996.76.2.1310},
	abstract = {1. We recorded single-unit and multi-unit activity in response to transient presentation of texture and grating patterns at 25 sites within the parafoveal representation of V1, V2, and V3 of two awake monkeys trained to perform a fixation task. In grating experiments, stimuli varied in orientation, spatial frequency, or both. In texture experiments, stimuli varied in contrast, check size, texture type, or pairs of these attributes. 2. To examine the nature and precision of temporal coding, we compared individual responses elicited by each set of stimuli in terms of two families of metrics. One family of metrics, D(spike), was sensitive to the absolute spike time (following stimulus onset). The second family of metrics, D(interval), was sensitive to the pattern of interspike intervals. In each family, the metrics depend on a parameter q, which expresses the precision of temporal coding. For q = 0, both metrics collapse into the "spike count" metric D(Count), which is sensitive to the number of impulses but insensitive to their position in time. 3. Each of these metrics, with values of q ranging from 0 to 512/s, was used to calculate the distance between all pairs of spike trains within each dataset. The extent of stimulus-specific clustering manifest in these pairwise distances was quantified by an information measure. Chance clustering was estimated by applying the same procedure to synthetic data sets in which responses were assigned randomly to the input stimuli. 4. Of the 352 data sets, 170 showed evidence of tuning via the spike count (q = 0) metric, 294 showed evidence of tuning via the spike time metric, 272 showed evidence of tuning via the spike interval metric to the stimulus attribute (contrast, check size, orientation, spatial frequency, or texture type) under study. Across the entire dataset, the information not attributable to chance clustering averaged 0.042 bits for the spike count metric, 0.171 bits for the optimal spike time metric, and 0.107 bits for the optimal spike interval metric. 5. The reciprocal of the optimal cost q serves as a measure of the temporal precision of temporal coding. In V1 and V2, with both metrics, temporal precision was highest for contrast (ca. 10-30 ms) and lowest for texture type (ca. 100 ms). This systematic dependence of q on stimulus attribute provides a possible mechanism for the simultaneous representation of multiple stimulus attributes in one spike train. 6. Our findings are inconsistent with Poisson models of spike trains. Synthetic data sets in which firing rate was governed by a time-dependent Poisson process matched to the observed poststimulus time histogram (PSTH) overestimated clustering induced by D(count) and, for low values of q, D(spike)[q] and D(intervals)[q]. Synthetic data sets constructed from a modified Poisson process, which preserved not only the PSTH but also spike count statistics accounted for the clustering induced by D(count) but underestimated the clustering induced by D(spike)[q] and D(interval)[q].},
	language = {en},
	number = {2},
	urldate = {2022-10-17},
	journal = {Journal of Neurophysiology},
	author = {Victor, J. D. and Purpura, K. P.},
	month = aug,
	year = {1996},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1310--1326},
}

@article{vanRossum2001,
	title = {A novel spike distance},
	volume = {13},
	issn = {0899-7667},
	doi = {10.1162/089976601300014321},
	abstract = {The discrimination between two spike trains is a fundamental problem for both experimentalists and the nervous system itself. We introduce a measure for the distance between two spike trains. The distance has a time constant as a parameter. Depending on this parameter, the distance interpolates between a coincidence detector and a rate difference counter. The dependence of the distance on noise is studied with an integrate-and-fire model. For an intermediate range of the time constants, the distance depends linearly on the noise. This property can be used to determine the intrinsic noise of a neuron.},
	language = {eng},
	number = {4},
	journal = {Neural Computation},
	author = {van Rossum, M. C.},
	month = apr,
	year = {2001},
	pmid = {11255567},
	keywords = {⛔ No INSPIRE recid found, Algorithms, Evoked Potentials, Models, Models, Neurological, Neurological, Neurons, Poisson Distribution},
	pages = {751--763},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/BIK532W6/van Rossum - 2001 - A novel spike distance.pdf:application/pdf},
}

@article{Susi2021,
	title = {{nMNSD}-{A} {Spiking} {Neuron}-{Based} {Classifier} {That} {Combines} {Weight}-{Adjustment} and {Delay}-{Shift}},
	volume = {15},
	issn = {1662-4548},
	doi = {10.3389/fnins.2021.582608},
	abstract = {The recent "multi-neuronal spike sequence detector" (MNSD) architecture integrates the weight- and delay-adjustment methods by combining heterosynaptic plasticity with the neurocomputational feature spike latency, representing a new opportunity to understand the mechanisms underlying biological learning. Unfortunately, the range of problems to which this topology can be applied is limited because of the low cardinality of the parallel spike trains that it can process, and the lack of a visualization mechanism to understand its internal operation. We present here the nMNSD structure, which is a generalization of the MNSD to any number of inputs. The mathematical framework of the structure is introduced, together with the "trapezoid method," that is a reduced method to analyze the recognition mechanism operated by the nMNSD in response to a specific input parallel spike train. We apply the nMNSD to a classification problem previously faced with the classical MNSD from the same authors, showing the new possibilities the nMNSD opens, with associated improvement in classification performances. Finally, we benchmark the nMNSD on the classification of static inputs (MNIST database) obtaining state-of-the-art accuracies together with advantageous aspects in terms of time- and energy-efficiency if compared to similar classification methods.},
	language = {eng},
	journal = {Frontiers in Neuroscience},
	author = {Susi, Gianluca and Antón-Toro, Luis F. and Maestú, Fernando and Pereda, Ernesto and Mirasso, Claudio},
	year = {2021},
	pmid = {33679293},
	pmcid = {PMC7933525},
	keywords = {⛔ No INSPIRE recid found, classification, delay learning, heterosynaptic plasticity, MNIST database, MNSD, online learning, spike latency},
	pages = {582608},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/ZFP2IHC2/Susi et al. - 2021 - nMNSD-A Spiking Neuron-Based Classifier That Combi.pdf:application/pdf},
}

@article{Dugue2011,
	title = {The {Phase} of {Ongoing} {Oscillations} {Mediates} the {Causal} {Relation} between {Brain} {Excitation} and {Visual} {Perception}},
	volume = {31},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1161-11.2011},
	doi = {10.1523/JNEUROSCI.1161-11.2011},
	language = {en},
	number = {33},
	urldate = {2022-10-17},
	journal = {Journal of Neuroscience},
	author = {Dugue, L. and Marque, P. and VanRullen, R.},
	month = aug,
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {11889--11893},
	file = {Dugue et al. - 2011 - The Phase of Ongoing Oscillations Mediates the Cau.pdf:/Users/laurentperrinet/Zotero/storage/SJ8QVLL4/Dugue et al. - 2011 - The Phase of Ongoing Oscillations Mediates the Cau.pdf:application/pdf},
}

@article{Fries2005,
	title = {A mechanism for cognitive dynamics: neuronal communication through neuronal coherence},
	volume = {9},
	issn = {1364-6613},
	shorttitle = {A mechanism for cognitive dynamics},
	doi = {10.1016/j.tics.2005.08.011},
	abstract = {At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and fMRI has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility.},
	language = {eng},
	number = {10},
	journal = {Trends in Cognitive Sciences},
	author = {Fries, Pascal},
	month = oct,
	year = {2005},
	pmid = {16150631},
	keywords = {⛔ No INSPIRE recid found, Action Potentials, Animals, Biological Clocks, Brain, Cognition, Humans, Nerve Net, Neurons, Nonlinear Dynamics, Periodicity, Pyramidal Tracts, Synaptic Transmission},
	pages = {474--480},
}

@article{Pearce2009,
	title = {Marie-{Jean}-{Pierre} {Flourens} (1794–1867) and {Cortical} {Localization}},
	volume = {61},
	issn = {0014-3022, 1421-9913},
	url = {https://www.karger.com/Article/FullText/206858},
	doi = {10.1159/000206858},
	abstract = {The child prodigy Marie-Jean-Pierre Flourens received his medical degree at Montpellier when aged 19. As a young promising physician Flourens was asked to investigate Gall’s controversial views on cerebral localization. To test Gall’s assertions, Flourens developed ablation as a procedure to explore the workings of the brain. By removing anatomically defined areas of the brain of an animal and watching its behaviour, he thought he might localize certain functions. Flourens did not favour the idea of cerebral localization and concluded that the brain functioned as a whole and thus arose the concept of ‘cerebral equipotentiality’. This culminated in his 1824 Recherches expérimentales sur les propriétés et les fonctions du système nerveux. His techniques were, however, crude and imperfect, and his experiments were mainly on birds. Much criticism and debate ensued. A gifted man, Flourens also advanced the physiology of the vestibular apparatus and described the anaesthetic properties of ether.},
	language = {en},
	number = {5},
	urldate = {2022-10-10},
	journal = {European Neurology},
	author = {Pearce, J.M.S.},
	year = {2009},
	keywords = {⛔ No INSPIRE recid found},
	pages = {311--314},
	file = {Pearce - 2009 - Marie-Jean-Pierre Flourens (1794–1867) and Cortica.pdf:/Users/laurentperrinet/Zotero/storage/5GZXXD46/Pearce - 2009 - Marie-Jean-Pierre Flourens (1794–1867) and Cortica.pdf:application/pdf},
}

@article{Adrian1926,
	title = {The impulses produced by sensory nerve endings},
	volume = {61},
	issn = {0022-3751},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1514868/},
	abstract = {Images
null},
	number = {4},
	urldate = {2022-10-10},
	journal = {The Journal of Physiology},
	author = {Adrian, E. D. and Zotterman, Yngve},
	month = aug,
	year = {1926},
	pmid = {16993807},
	pmcid = {PMC1514868},
	keywords = {⛔ No INSPIRE recid found},
	pages = {465--483},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/DATN8P3Z/Adrian et Zotterman - 1926 - The impulses produced by sensory nerve endings.pdf:application/pdf},
}

@article{Piccolino1997,
	title = {Luigi {Galvani} and animal electricity: two centuries after the foundation of electrophysiology},
	volume = {20},
	issn = {0166-2236},
	shorttitle = {Luigi {Galvani} and animal electricity},
	url = {https://www.sciencedirect.com/science/article/pii/S0166223697011016},
	doi = {10.1016/S0166-2236(97)01101-6},
	abstract = {Luigi Galvani and his famous experiments on frogs carried out in the second half of the 18th century belong more to legend than to the history of science. Galvani not only laid the foundations of a new science, electrophysiology, but also opened the way for the invention of the electric battery, and thus for the development of the physical investigations of electricity. However, in spite of the widespread celebration of his work, Galvani's scientific endeavours have been largely misrepresented in the history of science. The scholar of Bologna has a stereotyped image as an `occasional' scientist, who started his studies by chance, largely ignored the scientific theories of his time and wandered aimlessly in mental elaborations until the physicist of Pavia, Alessandro Volta, entered the field, correctly interpreted Galvani's results and eventually developed the electric battery. With the present understanding of electrical phenomena in excitable membranes, it is now time to reconsider the real matter raised by Galvani's discoveries and by his hypothesis of an intrinsic `animal electricity', and to make a clearer evaluation of a revolutionary phase of scientific progress.},
	language = {en},
	number = {10},
	urldate = {2022-10-10},
	journal = {Trends in Neurosciences},
	author = {Piccolino, Marco},
	month = oct,
	year = {1997},
	keywords = {⛔ No INSPIRE recid found, animal electricity, electrophysiology, Galvani, history of science, nervous signalling, Volta},
	pages = {443--448},
	file = {ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/NZUCGFNR/S0166223697011016.html:text/html},
}

@article{Rueckauer2017,
	title = {Conversion of {Continuous}-{Valued} {Deep} {Networks} to {Efficient} {Event}-{Driven} {Networks} for {Image} {Classification}},
	volume = {11},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2017.00682},
	doi = {10.3389/fnins.2017.00682},
	abstract = {Spiking neural networks (SNNs) can potentially offer an efficient way of doing inference because the neurons in the networks are sparsely activated and computations are event-driven. Previous work showed that simple continuous-valued deep Convolutional Neural Networks (CNNs) can be converted into accurate spiking equivalents. These networks did not include certain common operations such as max-pooling, softmax, batch-normalization and Inception-modules. This paper presents spiking equivalents of these operations therefore allowing conversion of nearly arbitrary CNN architectures. We show conversion of popular CNN architectures, including VGG-16 and Inception-v3, into SNNs that produce the best results reported to date on MNIST, CIFAR-10 and the challenging ImageNet dataset. SNNs can trade off classification error rate against the number of available operations whereas deep continuous-valued neural networks require a fixed number of operations to achieve their classification error rate. From the examples of LeNet for MNIST and BinaryNet for CIFAR-10, we show that with an increase in error rate of a few percentage points, the SNNs can achieve more than 2x reductions in operations compared to the original CNNs. This highlights the potential of SNNs in particular when deployed on power-efficient neuromorphic spiking neuron chips, for use in embedded applications.},
	urldate = {2022-10-25},
	journal = {Frontiers in Neuroscience},
	author = {Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},
	year = {2017},
	keywords = {⛔ No INSPIRE recid found},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/UYBX6EXN/Rueckauer et al. - 2017 - Conversion of Continuous-Valued Deep Networks to E.pdf:application/pdf},
}

@article{Simoncini2012,
	title = {More is not always better: adaptive gain control explains dissociation between perception and action},
	volume = {15},
	doi = {10.1038/nn.3229},
	number = {11},
	journal = {Nature neuroscience},
	author = {Simoncini, Claudio and Perrinet, Laurent U and Montagnini, Anna and Mamassian, Pascal and Masson, Guillaume S},
	year = {2012},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, activeₑyeₘovements, bicv-sparse, eye-movements, eyeₘovements, free energy, freemove, gain$_{\textrm{c}}$ontrol, perrinetadamsfriston14, pursuit, sanz12jnp, smooth-pursuit-eye-movements, spem, vacher14},
	pages = {1596--1603},
	annote = {Publisher: Nature Publishing Group},
}

@article{Leon2012,
	title = {Motion clouds: model-based stimulus synthesis of natural-like random textures for the study of motion perception},
	volume = {107},
	doi = {10.1152/jn.00737.2011},
	number = {11},
	journal = {Journal of neurophysiology},
	author = {Leon, Paula Sanz and Vanzetta, Ivo and Masson, Guillaume S and Perrinet, Laurent U},
	year = {2012},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, anr-trax, bicv-sparse, Eye movements, kaplan13, log-gabor, Low-level sensory systems, Motion detection, motion-clouds, Natural scenes, Optimal stimulation, perrinetadamsfriston14, Python, sanz12jnp, vacher14},
	pages = {3217--3226},
	annote = {Publisher: American Physiological Society Bethesda, MD},
}

@book{FLOURENS1842,
	title = {Recherches expérimentales sur les propriétés et les fonctions du système nerveux, dans les animaux vertébrés},
	language = {fr},
	publisher = {J.-B. Balliere},
	author = {FLOURENS, Marie Jean Pierre},
	year = {1842},
	keywords = {⛔ No INSPIRE recid found},
}

@article{Bonilla2022,
	title = {Analyzing time-to-first-spike coding schemes},
	volume = {16},
	url = {https://hal.archives-ouvertes.fr/hal-03796195},
	doi = {10.3389/fnins.2022.971937},
	abstract = {Spiking neural networks (SNNs) using time-to-first-spike (TTFS) codes, in which neurons fire at most once, are appealing for rapid and low power processing. In this theoretical paper, we focus on information coding and decoding in those networks, and introduce a new unifying mathematical framework that allows the comparison of various coding schemes. In an early proposal, called rank-order coding (ROC), neurons are maximally activated when inputs arrive in the order of their synaptic weights, thanks to a shunting inhibition mechanism that progressively desensitizes the neurons as spikes arrive. In another proposal, called NoM coding, only the first N spikes of M input neurons are propagated, and these “first spike patterns” can be readout by downstream neurons with homogeneous weights and no desensitization: as a result, the exact order between the first spikes does not matter. This paper also introduces a third option—“Ranked-NoM” (R-NoM), which combines features from both ROC and NoM coding schemes: only the first N input spikes are propagated, but their order is readout by downstream neurons thanks to inhomogeneous weights and linear desensitization. The unifying mathematical framework allows the three codes to be compared in terms of discriminability, which measures to what extent a neuron responds more strongly to its preferred input spike pattern than to random patterns. This discriminability turns out to be much higher for R-NoM than for the other codes, especially in the early phase of the responses. We also argue that R-NoM is much more hardware-friendly than the original ROC proposal, although NoM remains the easiest to implement in hardware because it only requires binary synapses.},
	urldate = {2022-11-08},
	journal = {Frontiers in Neuroscience},
	author = {Bonilla, Lina and Gautrais, Jacques and Thorpe, Simon and Masquelier, Timothée},
	year = {2022},
	note = {Publisher: Frontiers},
	keywords = {⛔ No INSPIRE recid found},
	annote = {Publisher: Frontiers},
	annote = {Publisher: Frontiers},
	file = {HAL PDF Full Text:/Users/laurentperrinet/Zotero/storage/9BFILRH9/Bonilla et al. - 2022 - Analyzing time-to-first-spike coding schemes.pdf:application/pdf},
}

@article{Schmolesky1998,
	title = {Signal timing across the macaque visual system},
	volume = {79},
	issn = {0022-3077},
	doi = {10.1152/jn.1998.79.6.3272},
	abstract = {The onset latencies of single-unit responses evoked by flashing visual stimuli were measured in the parvocellular (P) and magnocellular (M) layers of the dorsal lateral geniculate nucleus (LGNd) and in cortical visual areas V1, V2, V3, V4, middle temporal area (MT), medial superior temporal area (MST), and in the frontal eye field (FEF) in individual anesthetized monkeys. Identical procedures were carried out to assess latencies in each area, often in the same monkey, thereby permitting direct comparisons of timing across areas. This study presents the visual flash-evoked latencies for cells in areas where such data are common (V1 and V2), and are therefore a good standard, and also in areas where such data are sparse (LGNd M and P layers, MT, V4) or entirely lacking (V3, MST, and FEF in anesthetized preparation). Visual-evoked onset latencies were, on average, 17 ms shorter in the LGNd M layers than in the LGNd P layers. Visual responses occurred in V1 before any other cortical area. The next wave of activation occurred concurrently in areas V3, MT, MST, and FEF. Visual response latencies in areas V2 and V4 were progressively later and more broadly distributed. These differences in the time course of activation across the dorsal and ventral streams provide important temporal constraints on theories of visual processing.},
	language = {eng},
	number = {6},
	journal = {Journal of Neurophysiology},
	author = {Schmolesky, M. T. and Wang, Y. and Hanes, D. P. and Thompson, K. G. and Leutgeb, S. and Schall, J. D. and Leventhal, A. G.},
	month = jun,
	year = {1998},
	pmid = {9636126},
	keywords = {⛔ No INSPIRE recid found, Animals, Evoked Potentials, Evoked Potentials, Visual, Macaca, Neurons, Ocular, Photic Stimulation, Signal Transduction, Time Factors, Vision, Vision, Ocular, Visual, Visual Cortex},
	pages = {3272--3278},
	file = {JNP3272.pdf:/Users/laurentperrinet/Zotero/storage/83TB6VVK/JNP3272.pdf:application/pdf},
}

@article{Roy2019,
	title = {Towards spike-based machine intelligence with neuromorphic computing},
	volume = {575},
	copyright = {2019 Springer Nature Limited},
	issn = {1476-4687},
	url = {http://www.nature.com/articles/s41586-019-1677-2},
	doi = {10.1038/s41586-019-1677-2},
	abstract = {Guided by brain-like ‘spiking’ computational frameworks, neuromorphic computing—brain-inspired computing for machine intelligence—promises to realize artificial intelligence while reducing the energy requirements of computing platforms. This interdisciplinary field began with the implementation of silicon circuits for biological neural routines, but has evolved to encompass the hardware implementation of algorithms with spike-based encoding and event-driven representations. Here we provide an overview of the developments in neuromorphic computing for both algorithms and hardware and highlight the fundamentals of learning and hardware frameworks. We discuss the main challenges and the future prospects of neuromorphic computing, with emphasis on algorithm–hardware codesign.},
	language = {en},
	number = {7784},
	urldate = {2021-03-23},
	journal = {Nature},
	author = {Roy, Kaushik and Jaiswal, Akhilesh and Panda, Priyadarshini},
	month = nov,
	year = {2019},
	note = {Number: 7784
Publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found, Electrical and electronic engineering, Nanoscience and technology},
	pages = {607--617},
	annote = {Number: 7784 Publisher: Nature Publishing Group},
	annote = {Number: 7784 Publisher: Nature Publishing Group},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/RDFF2DKS/Roy et al. - 2019 - Towards spike-based machine intelligence with neur.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/S2JA58KV/s41586-019-1677-2.html:text/html},
}

@article{Christensen2022,
	title = {2022 roadmap on neuromorphic computing and engineering},
	issn = {2634-4386},
	url = {http://iopscience.iop.org/article/10.1088/2634-4386/ac4a83},
	doi = {10.1088/2634-4386/ac4a83},
	abstract = {Modern computation based on the von Neumann architecture is today a mature cutting-edge science. In the Von Neumann architecture, processing and memory units are implemented as separate blocks interchanging data intensively and continuously. This data transfer is responsible for a large part of the power consumption. The next generation computer technology is expected to solve problems at the exascale with 1018 calculations each second. Even though these future computers will be incredibly powerful, if they are based on von Neumann type architectures, they will consume between 20 and 30 megawatts of power and will not have intrinsic physically built-in capabilities to learn or deal with complex data as our brain does. These needs can be addressed by neuromorphic computing systems which are inspired by the biological concepts of the human brain. This new generation of computers has the potential to be used for the storage and processing of large amounts of digital information with much lower power consumption than conventional processors. Among their potential future applications, an important niche is moving the control from data centers to edge devices. The aim of this Roadmap is to present a snapshot of the present state of neuromorphic technology and provide an opinion on the challenges and opportunities that the future holds in the major areas of neuromorphic technology, namely materials, devices, neuromorphic circuits, neuromorphic algorithms, applications, and ethics. The Roadmap is a collection of perspectives where leading researchers in the neuromorphic community provide their own view about the current state and the future challenges for each research area. We hope that this Roadmap will be a useful resource by providing a concise yet comprehensive introduction to readers outside this field, for those who are just entering the field, as well as providing future perspectives for those who are well established in the neuromorphic computing community.},
	language = {en},
	urldate = {2022-01-13},
	journal = {Neuromorphic Computing and Engineering},
	author = {Christensen, Dennis Valbjørn and Dittmann, Regina and Linares-Barranco, Bernabe and Sebastian, Abu and Le Gallo, Manuel and Redaelli, Andrea and Slesazeck, Stefan and Mikolajick, Thomas and Spiga, Sabina and Menzel, Stephan and Valov, Ilia and Milano, Gianluca and Ricciardi, Carlo and Liang, Shi-Jun and Miao, Feng and Lanza, Mario and Quill, Tyler J. and Keene, Scott Tom and Salleo, Alberto and Grollier, Julie and Markovic, Danijela and Mizrahi, Alice and Yao, Peng and Yang, J. Joshua and Indiveri, Giacomo and Strachan, John Paul and Datta, Suman and Vianello, Elisa and Valentian, Alexandre and Feldmann, Johannes and Li, Xuan and Pernice, Wolfram HP and Bhaskaran, Harish and Furber, Steve and Neftci, Emre and Scherr, Franz and Maass, Wolfgang and Ramaswamy, Srikanth and Tapson, Jonathan and Panda, Priyadarshini and Kim, Youngeun and Tanaka, Gouhei and Thorpe, Simon and Bartolozzi, Chiara and Cleland, Thomas A and Posch, Christoph and Liu, Shih-Chii and Panuccio, Gabriella and Mahmud, Mufti and Mazumder, Arnab Neelim and Hosseini, Morteza and Mohsenin, Tinoosh and Donati, Elisa and Tolu, Silvia and Galeazzi, Roberto and Christensen, Martin Ejsing and Holm, Sune and Ielmini, Daniele and Pryds, Nini},
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	file = {IOP Full Text PDF:/Users/laurentperrinet/Zotero/storage/6HDSG67J/Christensen et al. - 2022 - 2022 roadmap on neuromorphic computing and enginee.pdf:application/pdf},
}

@article{Olshausen2017,
	title = {Sparse codes from memristor grids},
	volume = {12},
	issn = {1748-3395},
	url = {http://www.nature.com/articles/nnano.2017.112},
	doi = {10.1038/nnano.2017.112},
	abstract = {The adjustable resistive state of memristors makes it possible to implement sparse coding algorithms naturally and efficiently.},
	language = {en},
	number = {8},
	urldate = {2021-11-25},
	journal = {Nature Nanotechnology},
	author = {Olshausen, Bruno A. and Rozell, Christopher J.},
	month = aug,
	year = {2017},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 8
Primary\_atype: News \& Views
Publisher: Nature Publishing Group
Subject\_term: Computer science;Electrical and electronic engineering;Network models
Subject\_term\_id: computer-science;electrical-and-electronic-engineering;network-models},
	keywords = {⛔ No INSPIRE recid found, Computer science, Electrical and electronic engineering, Network models},
	pages = {722--723},
	annote = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 8 Primary\_atype: News \& Views Publisher: Nature Publishing Group Subject\_term: Computer science;Electrical and electronic engineering;Network models Subject\_term\_id: computer-science;electrical-and-electronic-engineering;network-models},
	annote = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 8 Primary\_atype: News \& Views Publisher: Nature Publishing Group Subject\_term: Computer science;Electrical and electronic engineering;Network models Subject\_term\_id: computer-science;electrical-and-electronic-engineering;network-models},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/JA97Y22U/Olshausen et Rozell - 2017 - Sparse codes from memristor grids.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/TQK3IMZM/nnano.2017.html:text/html},
}

@article{Gallego2022,
	title = {Event-{Based} {Vision}: {A} {Survey}},
	volume = {44},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Event-{Based} {Vision}},
	url = {https://ieeexplore.ieee.org/document/9138762/},
	doi = {10.1109/TPAMI.2020.3008413},
	abstract = {Event cameras are bio-inspired sensors that differ from conventional frame cameras: Instead of capturing images at a ﬁxed rate, they asynchronously measure per-pixel brightness changes, and output a stream of events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order of ms), very high dynamic range (140 dB versus 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision in challenging scenarios for traditional cameras, such as low-latency, high speed, and high dynamic range. However, novel methods are required to process the unconventional output of these sensors in order to unlock their potential. This paper provides a comprehensive overview of the emerging ﬁeld of event-based vision, with a focus on the applications and the algorithms developed to unlock the outstanding properties of event cameras. We present event cameras from their working principle, the actual sensors that are available and the tasks that they have been used for, from low-level vision (feature detection and tracking, optic ﬂow, etc.) to high-level vision (reconstruction, segmentation, recognition). We also discuss the techniques developed to process events, including learning-based techniques, as well as specialized processors for these novel sensors, such as spiking neural networks. Additionally, we highlight the challenges that remain to be tackled and the opportunities that lie ahead in the search for a more efﬁcient, bio-inspired way for machines to perceive and interact with the world.},
	language = {en},
	number = {1},
	urldate = {2022-07-19},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Gallego, Guillermo and Delbruck, Tobi and Orchard, Garrick and Bartolozzi, Chiara and Taba, Brian and Censi, Andrea and Leutenegger, Stefan and Davison, Andrew J. and Conradt, Jorg and Daniilidis, Kostas and Scaramuzza, Davide},
	month = jan,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {154--180},
	file = {Gallego et al. - 2022 - Event-Based Vision A Survey.pdf:/Users/laurentperrinet/Zotero/storage/8TCSL4E7/Gallego et al. - 2022 - Event-Based Vision A Survey.pdf:application/pdf},
}

@article{Goltz2020,
	title = {Fast and deep: energy-efficient neuromorphic learning with first-spike times},
	shorttitle = {Fast and deep},
	url = {http://arxiv.org/abs/1912.11443},
	abstract = {For a biological agent operating under environmental pressure, energy consumption and reaction times are of critical importance. Similarly, engineered systems also strive for short time-to-solution and low energy-to-solution characteristics. At the level of neuronal implementation, this implies achieving the desired results with as few and as early spikes as possible. In the time-to-first-spike-coding framework, both of these goals are inherently emerging features of learning. Here, we describe a rigorous derivation of learning such first-spike times in networks of leaky integrate-and-fire neurons, relying solely on input and output spike times, and show how it can implement error backpropagation in hierarchical spiking networks. Furthermore, we emulate our framework on the BrainScaleS-2 neuromorphic system and demonstrate its capability of harnessing the chip's speed and energy characteristics. Finally, we examine how our approach generalizes to other neuromorphic platforms by studying how its performance is affected by typical distortive effects induced by neuromorphic substrates.},
	urldate = {2021-03-02},
	journal = {arXiv:1912.11443 [cs, q-bio, stat]},
	author = {Göltz, Julian and Kriener, Laura and Baumbach, Andreas and Billaudelle, Sebastian and Breitwieser, Oliver and Cramer, Benjamin and Dold, Dominik and Kungl, Akos Ferenc and Senn, Walter and Schemmel, Johannes and Meier, Karlheinz and Petrovici, Mihai Alexandru},
	month = nov,
	year = {2020},
	note = {arXiv: 1912.11443},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Emerging Technologies, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
	annote = {arXiv: 1912.11443},
	annote = {arXiv: 1912.11443},
	annote = {Comment: 20 pages, 8 figures},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/VY96WPFQ/Göltz et al. - 2020 - Fast and deep energy-efficient neuromorphic learn.pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/DYT798QZ/1912.html:text/html},
}

@article{Seidl2010,
	title = {Mechanisms for adjusting interaural time differences to achieve binaural coincidence detection},
	volume = {30},
	issn = {1529-2401},
	doi = {10.1523/JNEUROSCI.3464-09.2010},
	abstract = {Understanding binaural perception requires detailed analyses of the neural circuitry responsible for the computation of interaural time differences (ITDs). In the avian brainstem, this circuit consists of internal axonal delay lines innervating an array of coincidence detector neurons that encode external ITDs. Nucleus magnocellularis (NM) neurons project to the dorsal dendritic field of the ipsilateral nucleus laminaris (NL) and to the ventral field of the contralateral NL. Contralateral-projecting axons form a delay line system along a band of NL neurons. Binaural acoustic signals in the form of phase-locked action potentials from NM cells arrive at NL and establish a topographic map of sound source location along the azimuth. These pathways are assumed to represent a circuit similar to the Jeffress model of sound localization, establishing a place code along an isofrequency contour of NL. Three-dimensional measurements of axon lengths reveal major discrepancies with the current model; the temporal offset based on conduction length alone makes encoding of physiological ITDs impossible. However, axon diameter and distances between Nodes of Ranvier also influence signal propagation times along an axon. Our measurements of these parameters reveal that diameter and internode distance can compensate for the temporal offset inferred from axon lengths alone. Together with other recent studies, these unexpected results should inspire new thinking on the cellular biology, evolution, and plasticity of the circuitry underlying low-frequency sound localization in both birds and mammals.},
	language = {eng},
	number = {1},
	journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	author = {Seidl, Armin H. and Rubel, Edwin W. and Harris, David M.},
	month = jan,
	year = {2010},
	pmid = {20053889},
	pmcid = {PMC2822993},
	keywords = {⛔ No INSPIRE recid found, Acoustic Stimulation, Animals, Animals, Newborn, Auditory Pathways, Auditory Perception, Brain Stem, Chickens, itd, Nerve Net, Newborn, Sound Localization, Time Factors},
	pages = {70--80},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/65CBZIT2/Seidl et al. - 2010 - Mechanisms for adjusting interaural time differenc.pdf:application/pdf},
}

@article{Maro2020,
	title = {Event-{Based} {Gesture} {Recognition} {With} {Dynamic} {Background} {Suppression} {Using} {Smartphone} {Computational} {Capabilities}},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2020.00275/full?report=reader},
	doi = {10.3389/fnins.2020.00275},
	abstract = {In this paper, we introduce a framework for dynamic gesture recognition with background suppression operating on the output of a moving event-based camera. The system is developed to operate in real-time using only the computational capabilities of a mobile phone. It introduces a new development around the concept of time-surfaces. It also presents a novel event-based methodology to dynamically remove backgrounds that uses the high temporal resolution properties of event-based cameras. To our knowledge, this is the first Android event-based framework for vision-based recognition of {\textbackslash}textit\{dynamic\} gestures running on a smartphone without off-board processing. We assess the performances by considering several scenarios in both indoors and outdoors, for static and dynamic conditions, in uncontrolled lighting conditions. We also introduce a new event-based dataset for gesture recognition with static and dynamic backgrounds (made publicly available). The set of gestures has been selected following a clinical trial to allow human-machine interaction for the visually impaired and older adults. We finally report comparisons with prior work that addressed event-based gesture recognition reporting comparable results, without the use of advanced classification techniques nor power greedy hardware.},
	language = {English},
	urldate = {2021-01-15},
	journal = {Frontiers in Neuroscience},
	author = {Maro, Jean-Matthieu and Ieng, Sio-Hoi and Benosman, Ryad},
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Background suppression, Background Suppression, Dynamic gesture recognition, Dynamic Gesture Recognition, dynamic vision sensor (DVS), Dynamic Vision Sensor (Dvs), event-based, Event-based, gesture recognition, Gesture Recognition, mobile device, Mobile Device, Neuromorphic, smartphone, Smartphone},
	annote = {Publisher: Frontiers},
	annote = {Publisher: Frontiers},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/PS4BNIL6/Maro et al. - 2020 - Event-Based Gesture Recognition With Dynamic Backg.pdf:application/pdf},
}

@techreport{Chintaluri2022,
	type = {preprint},
	title = {Metabolically driven action potentials serve neuronal energy homeostasis and protect from reactive oxygen species},
	url = {http://biorxiv.org/lookup/doi/10.1101/2022.10.16.512428},
	abstract = {So-called spontaneous neuronal activity is a central hallmark of most nervous systems. Such non-causal firing is contrary to the tenet of spikes as a means of communication, and its origin and purpose remain unclear. Here, we propose that non-input driven firing can serve as a release valve to protect neurons from the toxic conditions arising in mitochondria from lower-than-baseline energy consumption. We built a framework of models that incorporate homeostatic control of metabolic products–ATP, ADP, and reactive oxygen species, among others–by way of changes in firing. Our theory can account for key features of neuronal activity observed in many experiments in studies ranging from ion channels function all the way to resting state dynamics. We propose an integrated, crucial role for metabolic spiking that bridges the gap between metabolic homeostasis and neuronal function. Finally, we make testable predictions to validate or falsify our theory.},
	language = {en},
	urldate = {2022-11-07},
	institution = {Neuroscience},
	author = {Chintaluri, Chaitanya and Vogels, Tim P.},
	month = oct,
	year = {2022},
	doi = {10.1101/2022.10.16.512428},
	keywords = {⛔ No INSPIRE recid found},
	file = {Chintaluri et Vogels - 2022 - Metabolically driven action potentials serve neuro.pdf:/Users/laurentperrinet/Zotero/storage/K5TMEHAH/Chintaluri et Vogels - 2022 - Metabolically driven action potentials serve neuro.pdf:application/pdf},
}

@inproceedings{Grimaldi2022a,
	title = {Learning hetero-synaptic delays for motion detection in a single layer of spiking neurons},
	doi = {10.1109/ICIP46576.2022.9897394},
	abstract = {The response of a biological neuron depends on the precise timing of afferent spikes. This temporal aspect of the neuronal code is essential in understanding information processing in neurobiology and applies particularly well to the output of neuromorphic hardware such as event-based cameras. However, most artificial neuronal models do not take advantage of this minute temporal dimension and here, we develop a model for the efficient detection of temporal spiking motifs based on a layer of neurons with hetero-synaptic delays. Indeed, the variety of synaptic delays on the dendritic tree allows to synchronize synaptic inputs as they reach the basal dendritic tree. We show this can be formalized as a time-invariant logistic regression which can be trained using labelled data. We apply this model to solve the specific computer vision problem of motion detection, and demonstrate its application to synthetic naturalistic videos transformed into event streams similar to the output of event-based cameras. In particular, we quantify how its accuracy can vary with the total computational load. This end-to-end event-driven computational brick could help improve the performance of future Spiking Neural Network (SNN) algorithms and their prospective use in neuromorphic chips.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Grimaldi, Antoine and Perrinet, Laurent U},
	month = oct,
	year = {2022},
	note = {ISSN: 2381-8549},
	keywords = {⛔ No INSPIRE recid found, Biological neural networks, Cameras, Delays, efficient coding, event-based computations, logistic regression, motion detection, Motion detection, Neuromorphics, Neurons, spiking neural networks, Synchronization, time code},
	pages = {3591--3595},
	annote = {ISSN: 2381-8549},
	annote = {ISSN: 2381-8549},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/PUDHNDMC/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/laurentperrinet/Zotero/storage/L42SR4NW/Grimaldi et Perrinet - 2022 - Learning hetero-synaptic delays for motion detecti.pdf:application/pdf;Submitted Version:/Users/laurentperrinet/Zotero/storage/IQFK3P2I/Grimaldi and Perrinet - 2022 - Learning hetero-synaptic delays for motion detecti.pdf:application/pdf},
}

@article{Lichtsteiner2008,
	title = {A 128x128, 120 {dB} 15 ms {Latency} {Asynchronous} {Temporal} {Contrast} {Vision} {Sensor}},
	volume = {2},
	issn = {0018-9200, 1558-173X},
	url = {https://www.infona.pl//resource/bwmeta1.element.ieee-art-000004444573},
	doi = {10.1109/JSSC.2007.914337},
	abstract = {This paper describes a 128 times 128 pixel CMOS vision sensor. Each pixel independently and in continuous time quantizes local relative intensity changes to generate spike events. These events appear at the output of the sensor as an asynchronous stream of digital pixel addresses. These address-events signify scene reflectance change and have sub-millisecond timing precision. The output data rate depends on the dynamic content of the scene and is typically orders of magnitude lower than those of conventional frame-based imagers. By combining an active continuous-time front-end logarithmic photoreceptor with a self-timed switched-capacitor differencing circuit, the sensor achieves an array mismatch of 2.1\% in relative intensity event threshold and a pixel bandwidth of 3 kHz under 1 klux scene illumination. Dynamic range is \&amp;gt; 120 dB and chip power consumption is 23 mW. Event latency shows weak light dependency with a minimum of 15 mus at \&amp;gt; 1 klux pixel illumination. The sensor is built in a 0.35 mum 4M2P process. It has 40times40 mum\&lt;sup\&gt;2\&lt;/sup\&gt; pixels with 9.4\% fill factor. By providing high pixel bandwidth, wide dynamic range, and precisely timed sparse digital output, this silicon retina provides an attractive combination of characteristics for low-latency dynamic vision under uncontrolled illumination with low post-processing requirements.},
	language = {English},
	number = {43},
	urldate = {2022-11-08},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Lichtsteiner, P. and Posch, C. and Delbruck, T.},
	year = {2008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {566--576},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/LHBXUCFK/bwmeta1.element.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/58VZIUQX/Lichtsteiner et al. - 2008 - A 128\$times\$.pdf:application/pdf},
}

@article{Jazayeri2006,
	title = {Optimal representation of sensory information by neural populations},
	volume = {9},
	doi = {10.1038/nn1691},
	number = {5},
	journal = {Nature neuroscience},
	author = {Jazayeri, Mehrdad and Movshon, J. Anthony},
	year = {2006},
	note = {Publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found},
	pages = {690--696},
	annote = {Publisher: Nature Publishing Group},
	annote = {Publisher: Nature Publishing Group},
}

@article{Carr,
	title = {Processing of {Temporal} {Information} in the {Brain}},
	language = {en},
	author = {Carr, C E},
	keywords = {⛔ No INSPIRE recid found},
	pages = {21},
	file = {Carr - Processing of Temporal Information in the Brain.pdf:/Users/laurentperrinet/Zotero/storage/VY9PNC9Q/Carr - Processing of Temporal Information in the Brain.pdf:application/pdf;Carr - Processing of Temporal Information in the Brain.pdf:/Users/laurentperrinet/Zotero/storage/QFCSMMW2/Carr - Processing of Temporal Information in the Brain.pdf:application/pdf},
}

@article{Coull2022,
	title = {The distinction between temporal order and duration processing, and implications for schizophrenia},
	volume = {1},
	number = {5},
	journal = {Nature Reviews Psychology},
	author = {Coull, Jennifer T. and Giersch, Anne},
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found},
	pages = {257--271},
	annote = {Publisher: Nature Publishing Group},
	annote = {Publisher: Nature Publishing Group},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/JC8APIW2/s44159-022-00038-y.html:text/html},
}

@article{Camon2019,
	title = {The {Timing} of {Sensory}-{Guided} {Behavioral} {Response} is {Represented} in the {Mouse} {Primary} {Somatosensory} {Cortex}},
	volume = {29},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhy169},
	doi = {10.1093/cercor/bhy169},
	abstract = {Whisker-guided decision making in mice is thought to critically depend on
information processing occurring in the primary somatosensory cortex. However,
it is not clear if neuronal activity in this “early”
sensory region contains information about the timing and speed of motor
response. To address this question we designed a new task in which freely moving
mice learned to associate a whisker stimulus to reward delivery. The task was
tailored in such a way that a wide range of delays between whisker stimulation
and reward collection were observed due to differences of motivation and
perception. After training, mice were anesthetized and neuronal responses evoked
by stimulating trained and untrained whiskers were recorded across several
cortical columns of barrel cortex. We found a strong correlation between the
delay of the mouse behavioral response and the timing of multiunit activity
evoked by the trained whisker, outside its principal cortical column, in layers
4 and 5A but not in layer 2/3. Circuit mapping ex vivo revealed this effect was
associated with a weakening of layer 4 to layer 2/3 projection. We conclude that
the processes controlling the propagation of key sensory inputs to naive
cortical columns and the timing of sensory-guided action are linked.},
	number = {7},
	urldate = {2022-11-16},
	journal = {Cerebral Cortex},
	author = {Camon, Jérémy and Hugues, Sandrine and Erlandson, Melissa A and Robbe, David and Lagoun, Sabria and Marouane, Emna and Bureau, Ingrid},
	month = jul,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3034--3047},
}

@article{Neckar2019,
	title = {Braindrop: {A} mixed-signal neuromorphic architecture with a dynamical systems-based programming model},
	volume = {107},
	doi = {10.1109/JPROC.2018.2881432},
	number = {1},
	journal = {Proceedings of the IEEE},
	author = {Neckar, Alexander and Fok, Sam and Benjamin, Ben V. and Stewart, Terrence C. and Oza, Nick N. and Voelker, Aaron R. and Eliasmith, Chris and Manohar, Rajit and Boahen, Kwabena},
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {144--164},
}

@article{Young1938,
	title = {The {Functioning} of the {Giant} {Nerve} {Fibres} of the {Squid}},
	volume = {15},
	issn = {0022-0949},
	url = {https://doi.org/10.1242/jeb.15.2.170},
	doi = {10.1242/jeb.15.2.170},
	abstract = {1. Stimulation of single giant nerve fibres in the stellar nerves of the squid (Loligo pealii) shows them to be motor axons which produce contraction of the circular fibres of the mantle muscles.2. When a stellar nerve is stimulated with condenser discharges a maximal response is obtained at threshold voltage. No increase of response is obtained by further increase in the strength of stimulation except for an occasional slight increase at about ten times threshold voltage probably due to repetitive firing. It therefore appears that the stimulus produces a single impulse in the giant fibre, and that this is capable of exciting contraction in all the muscle fibres which it reaches. This confirms the conclusion reached on histological grounds that in spite of their syncytial nature each of the giant nerve fibres is a single functional unit.3. Since there are about ten giant fibres on each side the mantle is divided into 20 neuromotor units, each nerve fibre innervating an enormous number of muscle fibres. The existence of these units can also very readily be demonstrated by the fact that threshold electrical stimulation at any point within the territory innervated by each single giant fibre sets up a contraction of the muscle fibres of all parts of the territory with which the stimulated area is in connexion through the nerve.4. Stimulation of the smaller fibres in a stellar nerve after destruction of the giant fibre also causes contraction of the circular muscles of the mantle. The amount of this contraction increases progressively with increased voltage, presumably on account of the stimulation of more and more nerve fibres. The maximum tension developed in this way is always very much less than that produced by stimulation of the giant fibres.5. The mantle is therefore provided with a double mechanism of expiratory contraction, maximal contractions being produced by single impulses in the giant fibres and graded contractions by those in the smaller fibres of the nerve. Presumably the former contractions are those involved in rapid movement, the latter in respiration.6. There are also radial muscles, running through the thickness of the mantle, whose contractions effect the inspiration by making the cavity larger.},
	number = {2},
	urldate = {2022-11-13},
	journal = {Journal of Experimental Biology},
	author = {Young, J. Z.},
	month = apr,
	year = {1938},
	keywords = {⛔ No INSPIRE recid found},
	pages = {170--185},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/3GVEM97H/YOUNG - 1938 - The Functioning of the Giant Nerve Fibres of the S.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/8USIL797/The-Functioning-of-the-Giant-Nerve-Fibres-of-the.html:text/html},
}

@inproceedings{Wang2014,
	title = {An {FPGA} design framework for large-scale spiking neural networks},
	doi = {10.1109/ISCAS.2014.6865169},
	abstract = {We present an FPGA design framework for large-scale spiking neural networks, particularly the ones with a high-density of connections or all-to-all connections. The proposed FPGA design framework is based on a reconfigurable neural layer, which is implemented using a time-multiplexing approach to achieve up to 200,000 virtual neurons with one physical neuron using only a fraction of the hardware resources in commercial-off-the-shelf FPGAs (even entry level ones). Rather than using a mathematical computational model, the physical neuron was efficiently implemented with a conductance-based model, of which the parameters were randomised between neurons to emulate the variance in biological neurons. Besides these building blocks, the proposed time-multiplexed reconfigurable neural layer has an address buffer, which will generate a fixed random weight for each connection on the fly for incoming spikes. This structure effectively reduces the usage of memory. After presenting the architecture of the proposed neural layer, we present a network with 23 proposed neural layers, each containing 64k neurons, yielding 1.5 M neurons and 92 G synapses with a total spike throughput of 1.2T spikes/s, while running in real-time on a Virtex 6 FPGA.},
	booktitle = {2014 {IEEE} {International} {Symposium} on {Circuits} and {Systems} ({ISCAS})},
	author = {Wang, Runchun and Hamilton, Tara Julia and Tapson, Jonathan and van Schaik, André},
	month = jun,
	year = {2014},
	note = {ISSN: 2158-1525},
	keywords = {⛔ No INSPIRE recid found, Arrays, Biological neural networks, Biological system modeling, Digital signal processing, Field programmable gate arrays, Generators, Neurons},
	pages = {457--460},
	annote = {ISSN: 2158-1525},
	annote = {ISSN: 2158-1525},
}

@inproceedings{Diehl2014,
	address = {Beijing, China},
	title = {Efficient implementation of {STDP} rules on {SpiNNaker} neuromorphic hardware},
	isbn = {978-1-4799-1484-5 978-1-4799-6627-1},
	url = {https://ieeexplore.ieee.org/document/6889876},
	doi = {10.1109/IJCNN.2014.6889876},
	abstract = {Recent development of neuromorphic hardware offers great potential to speed up simulations of neural networks. SpiNNaker is a neuromorphic hardware and software system designed to be scalable and ﬂexible enough to implement a variety of different types of simulations of neural systems, including spiking simulations with plasticity and learning. Spiketiming dependent plasticity (STDP) rules are the most common form of learning used in spiking networks. However, to date very few such rules have been implemented on SpiNNaker, in part because implementations must be designed to ﬁt the specialized nature of the hardware. Here we explain how general STDP rules can be efﬁciently implemented in the SpiNNaker system. We give two examples of applications of the implemented rule: learning of a temporal sequence, and balancing inhibition and excitation of a neural network. Comparing the results from the SpiNNaker system to a conventional double-precision simulation, we ﬁnd that the network behavior is comparable, and the ﬁnal weights differ by less than 3\% between the two simulations, while the SpiNNaker simulation runs much faster, since it runs in real time, independent of network size.},
	language = {en},
	urldate = {2022-11-14},
	booktitle = {2014 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Diehl, Peter U. and Cook, Matthew},
	month = jul,
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {4288--4295},
}

@inproceedings{Farquhar2006,
	address = {Island of Kos, Greece},
	title = {A {Field} {Programmable} {Neural} {Array}},
	isbn = {978-0-7803-9389-9},
	url = {http://ieeexplore.ieee.org/document/1693534/},
	doi = {10.1109/ISCAS.2006.1693534},
	language = {en},
	urldate = {2022-11-14},
	booktitle = {2006 {IEEE} {International} {Symposium} on {Circuits} and {Systems}},
	publisher = {IEEE},
	author = {Farquhar, E. and Gordon, C. and Hasler, P.},
	year = {2006},
	keywords = {⛔ No INSPIRE recid found},
	pages = {4114--4117},
	file = {Farquhar et al. - 2006 - A Field Programmable Neural Array.pdf:/Users/laurentperrinet/Zotero/storage/V7L9V8J5/Farquhar et al. - 2006 - A Field Programmable Neural Array.pdf:application/pdf},
}

@incollection{Liu2009a,
	address = {Berlin, Heidelberg},
	title = {{FPAA} {Based} on {Integration} of {CMOS} and {Nanojunction} {Devices} for {Neuromorphic} {Applications}},
	volume = {3},
	isbn = {978-3-642-02426-9 978-3-642-02427-6},
	url = {http://link.springer.com/10.1007/978-3-642-02427-6_9},
	abstract = {In this paper, a novel field programmable analog arrays (FPAA) architecture, namely, NueroFPAA, is introduced to utilize nanodevices to build a programmable neuromorphic system. By using nanodevices as programmable components, the proposed FPAA can achieve high-density and low-power operations for neuromorphic applications. The routing and function blocks of the FPAA are specifically designed so that this proposed architecture can support large-scale neuromorphic design as well as various analog circuitries.},
	language = {en},
	urldate = {2022-11-14},
	booktitle = {Nano-{Net}},
	publisher = {Springer Berlin Heidelberg},
	author = {Liu, Ming and Yu, Hua and Wang, Wei},
	editor = {Cheng, Maggie},
	year = {2009},
	keywords = {⛔ No INSPIRE recid found},
	pages = {44--48},
	file = {Liu et al. - 2009 - FPAA Based on Integration of CMOS and Nanojunction.pdf:/Users/laurentperrinet/Zotero/storage/T2XACFAX/Liu et al. - 2009 - FPAA Based on Integration of CMOS and Nanojunction.pdf:application/pdf},
}

@article{Markram2011,
	series = {Proceedings of the 2nd {European} {Future} {Technologies} {Conference} and {Exhibition} 2011 ({FET} 11)},
	title = {Introducing the {Human} {Brain} {Project}},
	volume = {7},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050911006806},
	doi = {10.1016/j.procs.2011.12.015},
	abstract = {The Human Brain Project (HBP) is a candidate project in the European Union's FET Flagship Program, funded by the ICT Program in the Seventh Framework Program. The project will develop a new integrated strategy for understanding the human brain and a novel research platform that will integrate all the data and knowledge we can acquire about the structure and function of the brain and use it to build unifying models that can be validated by simulations running on supercomputers. The project will drive the development of supercomputing for the life sciences, generate new neuroscientific data as a benchmark for modeling, develop radically new tools for informatics, modeling and simulation, and build virtual laboratories for collaborative basic and clinical studies, drug simulation and virtual prototyping of neuroprosthetic, neuromorphic, and robotic devices.},
	language = {en},
	urldate = {2022-11-14},
	journal = {Procedia Computer Science},
	author = {Markram, Henry and Meier, Karlheinz and Lippert, Thomas and Grillner, Sten and Frackowiak, Richard and Dehaene, Stanislas and Knoll, Alois and Sompolinsky, Haim and Verstreken, Kris and DeFelipe, Javier and Grant, Seth and Changeux, Jean-Pierre and Saria, Alois},
	month = jan,
	year = {2011},
	keywords = {⛔ No INSPIRE recid found, HPC, Human brain, medicine, modeling, neuroinformatics, neuromorphics, neuroprosthetics, neurorobotics, neuroscience, simulation, supercomputing},
	pages = {39--42},
	file = {ScienceDirect Full Text PDF:/Users/laurentperrinet/Zotero/storage/6QQGAJCQ/Markram et al. - 2011 - Introducing the Human Brain Project.pdf:application/pdf;ScienceDirect Snapshot:/Users/laurentperrinet/Zotero/storage/SEUEK83J/S1877050911006806.html:text/html},
}

@inproceedings{Schemmel2010,
	title = {A wafer-scale neuromorphic hardware system for large-scale neural modeling},
	doi = {10.1109/ISCAS.2010.5536970},
	abstract = {Modeling neural tissue is an important tool to investigate biological neural networks. Until recently, most of this modeling has been done using numerical methods. In the European research project "FACETS" this computational approach is complemented by different kinds of neuromorphic systems. A special emphasis lies in the usability of these systems for neuroscience. To accomplish this goal an integrated software/hardware framework has been developed which is centered around a unified neural system description language, called PyNN, that allows the scientist to describe a model and execute it in a transparent fashion on either a neuromorphic hardware system or a numerical simulator. A very large analog neuromorphic hardware system developed within FACETS is able to use complex neural models as well as realistic network topologies, i.e. it can realize more than 10000 synapses per neuron, to allow the direct execution of models which previously could have been simulated numerically only.},
	booktitle = {2010 {IEEE} {International} {Symposium} on {Circuits} and {Systems} ({ISCAS})},
	author = {Schemmel, Johannes and Brüderle, Daniel and Grübl, Andreas and Hock, Matthias and Meier, Karlheinz and Millner, Sebastian},
	month = may,
	year = {2010},
	note = {ISSN: 2158-1525},
	keywords = {⛔ No INSPIRE recid found, Biological neural networks, Biological system modeling, Biological tissues, Biology computing, Hardware, Large-scale systems, Neuromorphics, Numerical simulation, Semiconductor device modeling, Usability},
	pages = {1947--1950},
	annote = {ISSN: 2158-1525},
	annote = {ISSN: 2158-1525},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/5XM4AB9D/Schemmel et al. - 2010 - A wafer-scale neuromorphic hardware system for lar.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/L7UEJLGS/5536970.html:text/html},
}

@article{Diesmann2003,
	title = {{NEST}: {An} {Environment} for {Neural} {Systems} {Simulations}},
	abstract = {NEST is a framework for simulating large, structured neuronal systems. It is designed to investigate the functional behavior of neuronal systems in the context of their anatomical, morphological, and electrophysiological properties. NEST aims at large networks, while maintaining an appropriate degree of biological detail. This is achieved by combining a broad range of abstraction levels in a single network simulation. Great biological detail is then maintained only at the points of interest, while the rest of the system can be modeled by more abstract components. Here, we describe the conception of NEST and illustrate its key features. We demonstrate that software design and organizational aspects were of equal importance for the success of the project.},
	language = {en},
	journal = {GWDG-Bericht Nr. 58 Theo Plesser, Volker Macho (Hrsg.)},
	author = {Diesmann, Markus and Gewaltig, Marc-Oliver},
	year = {2003},
	keywords = {⛔ No INSPIRE recid found},
	pages = {29},
	file = {Diesmann and Gewaltig - NEST An Environment for Neural Systems Simulation.pdf:/Users/laurentperrinet/Zotero/storage/SYYUMHQK/Diesmann and Gewaltig - NEST An Environment for Neural Systems Simulation.pdf:application/pdf},
}

@article{Benjamin2014,
	title = {Neurogrid: {A} {Mixed}-{Analog}-{Digital} {Multichip} {System} for {Large}-{Scale} {Neural} {Simulations}},
	volume = {102},
	issn = {1558-2256},
	shorttitle = {Neurogrid},
	doi = {10.1109/JPROC.2014.2313565},
	abstract = {In this paper, we describe the design of Neurogrid, a neuromorphic system for simulating large-scale neural models in real time. Neuromorphic systems realize the function of biological neural systems by emulating their structure. Designers of such systems face three major design choices: 1) whether to emulate the four neural elements-axonal arbor, synapse, dendritic tree, and soma-with dedicated or shared electronic circuits; 2) whether to implement these electronic circuits in an analog or digital manner; and 3) whether to interconnect arrays of these silicon neurons with a mesh or a tree network. The choices we made were: 1) we emulated all neural elements except the soma with shared electronic circuits; this choice maximized the number of synaptic connections; 2) we realized all electronic circuits except those for axonal arbors in an analog manner; this choice maximized energy efficiency; and 3) we interconnected neural arrays in a tree network; this choice maximized throughput. These three choices made it possible to simulate a million neurons with billions of synaptic connections in real time-for the first time-using 16 Neurocores integrated on a board that consumes three watts.},
	number = {5},
	journal = {Proceedings of the IEEE},
	author = {Benjamin, Ben Varkey and Gao, Peiran and McQuinn, Emmett and Choudhary, Swadesh and Chandrasekaran, Anand R. and Bussat, Jean-Marie and Alvarez-Icaza, Rodrigo and Arthur, John V. and Merolla, Paul A. and Boahen, Kwabena},
	month = may,
	year = {2014},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {⛔ No INSPIRE recid found, Analog circuits, application specific integrated circuits, asynchronous circuits, brain modeling, computational neuroscience, Computer architecture, Electronic circuits, Integrated circuit modeling, interconnection networks, mixed analog-digital integrated circuits, Nerve fibers, neural network hardware, Neural networks, neuromorphic electronic systems, Neuroscience, Random access memory, Synchronous digital hierarchy},
	pages = {699--716},
	annote = {Conference Name: Proceedings of the IEEE},
	annote = {Conference Name: Proceedings of the IEEE},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/E7HLTW33/6805187.html:text/html},
}

@book{Mead1989,
	title = {Analog {VLSI} {Implementation} of {Neural} {Systems}},
	isbn = {978-0-7923-9040-4},
	abstract = {This volume contains the proceedings of a workshop on Analog Integrated Neural Systems held May 8, 1989, in connection with the International Symposium on Circuits and Systems. The presentations were chosen to encompass the entire range of topics currently under study in this exciting new discipline. Stringent acceptance requirements were placed on contributions: (1) each description was required to include detailed characterization of a working chip, and (2) each design was not to have been published previously. In several cases, the status of the project was not known until a few weeks before the meeting date. As a result, some of the most recent innovative work in the field was presented. Because this discipline is evolving rapidly, each project is very much a work in progress. Authors were asked to devote considerable attention to the shortcomings of their designs, as well as to the notable successes they achieved. In this way, other workers can now avoid stumbling into the same traps, and evolution can proceed more rapidly (and less painfully). The chapters in this volume are presented in the same order as the corresponding presentations at the workshop. The first two chapters are concerned with fmding solutions to complex optimization problems under a predefmed set of constraints. The first chapter reports what is, to the best of our knowledge, the first neural-chip design. In each case, the physics of the underlying electronic medium is used to represent a cost function in a natural way, using only nearest-neighbor connectivity.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Mead, Carver and Ismail, Mohammed},
	month = aug,
	year = {1989},
	note = {Google-Books-ID: 9e29dOiXeiMC},
	keywords = {⛔ No INSPIRE recid found, Computers / CAD-CAM, Computers / Computer Vision \& Pattern Recognition, Technology \& Engineering / Electrical, Technology \& Engineering / Electronics / Circuits / General, Technology \& Engineering / Electronics / General, Technology \& Engineering / Imaging Systems},
	annote = {Google-Books-ID: 9e29dOiXeiMC},
	annote = {Google-Books-ID: 9e29dOiXeiMC},
}

@article{Spencer2018,
	title = {Compensation for {Traveling} {Wave} {Delay} {Through} {Selection} of {Dendritic} {Delays} {Using} {Spike}-{Timing}-{Dependent} {Plasticity} in a {Model} of the {Auditory} {Brainstem}},
	volume = {12},
	issn = {1662-5188},
	doi = {10.3389/fncom.2018.00036},
	abstract = {Asynchrony among synaptic inputs may prevent a neuron from responding to behaviorally relevant sensory stimuli. For example, "octopus cells" are monaural neurons in the auditory brainstem of mammals that receive input from auditory nerve fibers (ANFs) representing a broad band of sound frequencies. Octopus cells are known to respond with finely timed action potentials at the onset of sounds despite the fact that due to the traveling wave delay in the cochlea, synaptic input from the auditory nerve is temporally diffuse. This paper provides a proof of principle that the octopus cells' dendritic delay may provide compensation for this input asynchrony, and that synaptic weights may be adjusted by a spike-timing dependent plasticity (STDP) learning rule. This paper used a leaky integrate and fire model of an octopus cell modified to include a "rate threshold," a property that is known to create the appropriate onset response in octopus cells. Repeated audio click stimuli were passed to a realistic auditory nerve model which provided the synaptic input to the octopus cell model. A genetic algorithm was used to find the parameters of the STDP learning rule that reproduced the microscopically observed synaptic connectivity. With these selected parameter values it was shown that the STDP learning rule was capable of adjusting the values of a large number of input synaptic weights, creating a configuration that compensated the traveling wave delay of the cochlea.},
	language = {eng},
	journal = {Frontiers in Computational Neuroscience},
	author = {Spencer, Martin J. and Meffin, Hamish and Burkitt, Anthony N. and Grayden, David B.},
	year = {2018},
	pmid = {29922141},
	pmcid = {PMC5996126},
	keywords = {⛔ No INSPIRE recid found, auditory brainstem, cochlear nucleus, dendritic delay, octopus cells, spike-timing dependent plasticity},
	pages = {36},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/CCJE4SLH/Spencer et al. - 2018 - Compensation for Traveling Wave Delay Through Sele.pdf:application/pdf},
}

@article{Gibson2014a,
	title = {Neuronal {Activity} {Promotes} {Oligodendrogenesis} and {Adaptive} {Myelination} in the {Mammalian} {Brain}},
	volume = {344},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4096908/},
	doi = {10.1126/science.1252304},
	abstract = {Myelination of the central nervous system requires the generation of functionally mature oligodendrocytes from oligodendrocyte precursor cells (OPCs). Electrically active neurons may influence OPC function and selectively instruct myelination of an active neural circuit. In this work, we use optogenetic stimulation of the premotor cortex in awake, behaving mice to demonstrate that neuronal activity elicits a mitogenic response of neural progenitor cells and OPCs, promotes oligodendrogenesis, and increases myelination within the deep layers of the premotor cortex and subcortical white matter. We further show that this neuronal activity–regulated oligodendrogenesis and myelination is associated with improved motor function of the corresponding limb. Oligodendrogenesis and myelination appear necessary for the observed functional improvement, as epigenetic blockade of oligodendrocyte differentiation and myelin changes prevents the activity-regulated behavioral improvement.},
	number = {6183},
	urldate = {2022-11-13},
	journal = {Science (New York, N.Y.)},
	author = {Gibson, Erin M. and Purger, David and Mount, Christopher W. and Goldstein, Andrea K. and Lin, Grant L. and Wood, Lauren S. and Inema, Ingrid and Miller, Sarah E. and Bieri, Gregor and Zuchero, J. Bradley and Barres, Ben A. and Woo, Pamelyn J. and Vogel, Hannes and Monje, Michelle},
	month = may,
	year = {2014},
	pmid = {24727982},
	pmcid = {PMC4096908},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1252304},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/K5RPKA8W/Gibson et al. - 2014 - Neuronal Activity Promotes Oligodendrogenesis and .pdf:application/pdf},
}

@article{Cullen2021,
	title = {Periaxonal and nodal plasticities modulate action potential conduction in the adult mouse brain},
	volume = {34},
	issn = {2211-1247},
	url = {https://www.cell.com/cell-reports/abstract/S2211-1247(20)31630-2},
	doi = {10.1016/j.celrep.2020.108641},
	language = {English},
	number = {3},
	urldate = {2022-11-13},
	journal = {Cell Reports},
	author = {Cullen, Carlie L. and Pepper, Renee E. and Clutterbuck, Mackenzie T. and Pitman, Kimberley A. and Oorschot, Viola and Auderset, Loic and Tang, Alexander D. and Ramm, Georg and Emery, Ben and Rodger, Jennifer and Jolivet, Renaud B. and Young, Kaylene M.},
	month = jan,
	year = {2021},
	pmid = {33472075},
	note = {Publisher: Elsevier},
	keywords = {⛔ No INSPIRE recid found, action potential, computational modeling, conduction velocity, myelin, node of Ranvier, oligodendrocyte, periaxonal space, plasticity, spatial learning, transcranial magnetic stimulation},
	annote = {Publisher: Elsevier},
	annote = {Publisher: Elsevier},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/E3WHE26F/Cullen et al. - 2021 - Periaxonal and nodal plasticities modulate action .pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/IKQ2DWYS/S2211-1247(20)31630-2.html:text/html},
}

@article{Nave2006,
	title = {Axonal regulation of myelination by neuregulin 1},
	volume = {16},
	issn = {0959-4388},
	doi = {10.1016/j.conb.2006.08.008},
	abstract = {Neuregulins comprise a family of epidermal growth factor-like ligands that interact with ErbB receptor tyrosine kinases to control many aspects of neural development. One of the most dramatic effects of neuregulin-1 is on glial cell differentiation. The membrane-bound neuregulin-1 type III isoform is an axonal ligand for glial ErbB receptors that regulates the early Schwann cell lineage, including the generation of precursors. Recent studies have shown that the amount of neuregulin-1 type III expressed on axons also dictates the glial phenotype, with a threshold level triggering Schwann cell myelination. Remarkably, neuregulin-1 type III also regulates Schwann cell membrane growth to adjust myelin sheath thickness to match axon caliber precisely. Whether this signaling system operates in central nervous system myelination remains an open question of major importance for human demyelinating diseases.},
	language = {eng},
	number = {5},
	journal = {Current Opinion in Neurobiology},
	author = {Nave, Klaus-Armin and Salzer, James L.},
	month = oct,
	year = {2006},
	pmid = {16962312},
	keywords = {⛔ No INSPIRE recid found, Animals, Axons, Cell Differentiation, Cell Lineage, ErbB-2, ErbB-3, Humans, Myelin Sheath, Neuregulin-1, Neuroglia, Protein Isoforms, Receptor, Receptor, ErbB-2, Receptor, ErbB-3, Signal Transduction, Stem Cells},
	pages = {492--500},
}

@article{Baraban2018,
	title = {Ca2+ activity signatures of myelin sheath formation and growth in vivo},
	volume = {21},
	issn = {1097-6256},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5742537/},
	doi = {10.1038/s41593-017-0040-x},
	abstract = {During myelination, individual oligodendrocytes initially over-produce short myelin sheaths that are either retracted or stabilised. By live imaging oligodendrocyte Ca2+ activity in vivo, we find that high-amplitude long-duration Ca2+ transients in sheaths prefigure retractions, mediated by calpain. Following stabilisation, myelin sheaths grow along axons, and we find that higher frequency Ca2+ transient activity in sheaths precedes faster elongation. Our data implicate local Ca2+ signalling in regulating distinct stages of myelination.},
	number = {1},
	urldate = {2022-11-13},
	journal = {Nature neuroscience},
	author = {Baraban, Marion and Koudelka, Sigrid and Lyons, David A},
	month = jan,
	year = {2018},
	pmid = {29230058},
	pmcid = {PMC5742537},
	keywords = {⛔ No INSPIRE recid found},
	pages = {19--23},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/7Q4KGYXB/Baraban et al. - 2018 - Ca2+ activity signatures of myelin sheath formatio.pdf:application/pdf},
}

@article{Kuhn2019,
	title = {Oligodendrocytes in {Development}, {Myelin} {Generation} and {Beyond}},
	volume = {8},
	issn = {2073-4409},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6912544/},
	doi = {10.3390/cells8111424},
	abstract = {Oligodendrocytes are the myelinating cells of the central nervous system (CNS) that are generated from oligodendrocyte progenitor cells (OPC). OPC are distributed throughout the CNS and represent a pool of migratory and proliferative adult progenitor cells that can differentiate into oligodendrocytes. The central function of oligodendrocytes is to generate myelin, which is an extended membrane from the cell that wraps tightly around axons. Due to this energy consuming process and the associated high metabolic turnover oligodendrocytes are vulnerable to cytotoxic and excitotoxic factors. Oligodendrocyte pathology is therefore evident in a range of disorders including multiple sclerosis, schizophrenia and Alzheimer’s disease. Deceased oligodendrocytes can be replenished from the adult OPC pool and lost myelin can be regenerated during remyelination, which can prevent axonal degeneration and can restore function. Cell population studies have recently identified novel immunomodulatory functions of oligodendrocytes, the implications of which, e.g., for diseases with primary oligodendrocyte pathology, are not yet clear. Here, we review the journey of oligodendrocytes from the embryonic stage to their role in homeostasis and their fate in disease. We will also discuss the most common models used to study oligodendrocytes and describe newly discovered functions of oligodendrocytes.},
	number = {11},
	urldate = {2022-11-13},
	journal = {Cells},
	author = {Kuhn, Sarah and Gritti, Laura and Crooks, Daniel and Dombrowski, Yvonne},
	month = nov,
	year = {2019},
	pmid = {31726662},
	pmcid = {PMC6912544},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1424},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/CWBQKURX/Kuhn et al. - 2019 - Oligodendrocytes in Development, Myelin Generation.pdf:application/pdf},
}

@article{Xue2021,
	title = {Demyelination of the {Optic} {Nerve}: {An} {Underlying} {Factor} in {Glaucoma}?},
	volume = {13},
	issn = {1663-4365},
	shorttitle = {Demyelination of the {Optic} {Nerve}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8593209/},
	doi = {10.3389/fnagi.2021.701322},
	abstract = {Neurodegenerative disorders are characterized by typical neuronal degeneration and axonal loss in the central nervous system (CNS). Demyelination occurs when myelin or oligodendrocytes experience damage. Pathological changes in demyelination contribute to neurodegenerative diseases and worsen clinical symptoms during disease progression. Glaucoma is a neurodegenerative disease characterized by progressive degeneration of retinal ganglion cells (RGCs) and the optic nerve. Since it is not yet well understood, we hypothesized that demyelination could play a significant role in glaucoma. Therefore, this study started with the morphological and functional manifestations of demyelination in the CNS. Then, we discussed the main mechanisms of demyelination in terms of oxidative stress, mitochondrial damage, and immuno-inflammatory responses. Finally, we summarized the existing research on the relationship between optic nerve demyelination and glaucoma, aiming to inspire effective treatment plans for glaucoma in the future.},
	urldate = {2022-11-13},
	journal = {Frontiers in Aging Neuroscience},
	author = {Xue, Jingfei and Zhu, Yingting and Liu, Zhe and Lin, Jicheng and Li, Yangjiani and Li, Yiqing and Zhuo, Yehong},
	month = nov,
	year = {2021},
	pmid = {34795572},
	pmcid = {PMC8593209},
	keywords = {⛔ No INSPIRE recid found},
	pages = {701322},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/9P5SADV4/Xue et al. - 2021 - Demyelination of the Optic Nerve An Underlying Fa.pdf:application/pdf},
}

@article{Wan2020,
	title = {Impaired {Postnatal} {Myelination} in a {Conditional} {Knockout} {Mouse} for the {Ferritin} {Heavy} {Chain} in {Oligodendroglial} {Cells}},
	volume = {40},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7531557/},
	doi = {10.1523/JNEUROSCI.1281-20.2020},
	abstract = {To define the importance of iron storage in oligodendrocyte development and function, the ferritin heavy subunit (Fth) was specifically deleted in oligodendroglial cells. Blocking Fth synthesis in Sox10 or NG2-positive oligodendrocytes during the first or the third postnatal week significantly reduces oligodendrocyte iron storage and maturation. The brain of Fth KO animals presented an important decrease in the expression of myelin proteins and a substantial reduction in the percentage of myelinated axons. This hypomyelination was accompanied by a decline in the number of myelinating oligodendrocytes and with a reduction in proliferating oligodendrocyte progenitor cells (OPCs). Importantly, deleting Fth in Sox10-positive oligodendroglial cells after postnatal day 60 has no effect on myelin production and/or oligodendrocyte quantities. We also tested the capacity of Fth-deficient OPCs to remyelinate the adult brain in the cuprizone model of myelin injury and repair. Fth deletion in NG2-positive OPCs significantly reduces the number of mature oligodendrocytes and myelin production throughout the remyelination process. Furthermore, the corpus callosum of Fth KO animals presented a significant decrease in the percentage of remyelinated axons and a substantial reduction in the average myelin thickness. These results indicate that Fth synthesis during the first three postnatal weeks is important for an appropriate oligodendrocyte development, and suggest that Fth iron storage in adult OPCs is also essential for an effective remyelination of the mouse brain., SIGNIFICANCE STATEMENT To define the importance of iron storage in oligodendrocyte function, we have deleted the ferritin heavy chain (Fth) specifically in the oligodendrocyte lineage. Fth ablation in oligodendroglial cells throughout early postnatal development significantly reduces oligodendrocyte maturation and myelination. In contrast, deletion of Fth in oligodendroglial cells after postnatal day 60 has no effect on myelin production and/or oligodendrocyte numbers. We have also tested the consequences of disrupting Fth iron storage in oligodendrocyte progenitor cells (OPCs) after demyelination. We have found that Fth deletion in NG2-positive OPCs significantly delays the remyelination process in the adult brain. Therefore, Fth iron storage is essential for early oligodendrocyte development as well as for OPC maturation in the demyelinated adult brain.},
	number = {40},
	urldate = {2022-11-14},
	journal = {The Journal of Neuroscience},
	author = {Wan, Rensheng and Cheli, Veronica T. and Santiago-González, Diara A. and Rosenblum, Shaina L. and Wan, Qiuchen and Paez, Pablo M.},
	month = sep,
	year = {2020},
	pmid = {32868463},
	pmcid = {PMC7531557},
	keywords = {⛔ No INSPIRE recid found},
	pages = {7609--7624},
}

@article{Pan2020,
	title = {Preservation of a remote fear memory requires new myelin formation},
	volume = {23},
	issn = {1546-1726},
	doi = {10.1038/s41593-019-0582-1},
	abstract = {Experience-dependent myelination is hypothesized to shape neural circuit function and subsequent behavioral output. Using a contextual fear memory task in mice, we demonstrate that fear learning induces oligodendrocyte precursor cells to proliferate and differentiate into myelinating oligodendrocytes in the medial prefrontal cortex. Transgenic animals that cannot form new myelin exhibit deficient remote, but not recent, fear memory recall. Recording population calcium dynamics by fiber photometry, we observe that the neuronal response to conditioned context cues evolves over time in the medial prefrontal cortex, but not in animals that cannot form new myelin. Finally, we demonstrate that pharmacological induction of new myelin formation with clemastine fumarate improves remote memory recall and promotes fear generalization. Thus, bidirectional manipulation of myelin plasticity functionally affects behavior and neurophysiology, which suggests that neural activity during fear learning instructs the formation of new myelin, which in turn supports the consolidation and/or retrieval of remote fear memories.},
	language = {eng},
	number = {4},
	journal = {Nature Neuroscience},
	author = {Pan, Simon and Mayoral, Sonia R. and Choi, Hye Sun and Chan, Jonah R. and Kheirbek, Mazen A.},
	month = apr,
	year = {2020},
	pmid = {32042175},
	pmcid = {PMC7213814},
	keywords = {⛔ No INSPIRE recid found, Animals, Cell Proliferation, Classical, Conditioning, Conditioning, Classical, Fear, Long-Term, Memory, Memory, Long-Term, Mice, Mice, Transgenic, Myelin Sheath, Oligodendrocyte Precursor Cells, Oligodendrocyte Transcription Factor 2, Prefrontal Cortex, Transgenic},
	pages = {487--499},
	file = {Version acceptée:/Users/laurentperrinet/Zotero/storage/66VMB7WA/Pan et al. - 2020 - Preservation of a remote fear memory requires new .pdf:application/pdf},
}

@article{Steadman2020,
	title = {Disruption of {Oligodendrogenesis} {Impairs} {Memory} {Consolidation} in {Adult} {Mice}},
	volume = {105},
	issn = {0896-6273},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7579726/},
	doi = {10.1016/j.neuron.2019.10.013},
	abstract = {The generation of myelin-forming oligodendrocytes persists throughout life and is regulated by neural activity. Here we tested whether experience-driven changes in oligodendrogenesis are important for memory consolidation. We found that water maze learning promotes oligodendrogenesis and de
novo myelination in the cortex and associated white matter tracts. Preventing these learning-induced increases in oligodendrogenesis without affecting existing oligodendrocytes impaired memory consolidation of water maze, as well as contextual fear, memories. These results suggest that de
novo myelination tunes activated circuits, promoting coordinated activity that is important for memory consolidation. Consistent with this, contextual fear learning increased the coupling of hippocampal sharp wave ripples and cortical spindles, and these learning-induced increases in ripple-spindle coupling were blocked when oligodendrogenesis was suppressed. Our results identify a non-neuronal form of plasticity that remodels hippocampal-cortical networks following learning and is required for memory consolidation., 
          
        , Experience-dependent de
novo myelination may fine-tune activated circuits by promoting brain synchrony, important for memory consolidation. Steadman et al. find that blocking this form of adaptive myelination prevents learning-induced increases in coordinated activity and impairs memory consolidation.},
	number = {1},
	urldate = {2022-11-14},
	journal = {Neuron},
	author = {Steadman, Patrick E. and Xia, Frances and Ahmed, Moriam and Mocle, Andrew J. and Penning, Amber R.A. and Geraghty, Anna C. and Steenland, Hendrik W. and Monje, Michelle and Josselyn, Sheena A. and Frankland, Paul W.},
	month = jan,
	year = {2020},
	pmid = {31753579},
	pmcid = {PMC7579726},
	keywords = {⛔ No INSPIRE recid found},
	pages = {150--164.e6},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/2IVWUSHT/Steadman et al. - 2020 - Disruption of Oligodendrogenesis Impairs Memory Co.pdf:application/pdf},
}

@article{Duncan2021,
	title = {Neuron-{Oligodendrocyte} {Interactions} in the {Structure} and {Integrity} of {Axons}},
	volume = {9},
	issn = {2296-634X},
	url = {https://www.frontiersin.org/articles/10.3389/fcell.2021.653101},
	doi = {10.3389/fcell.2021.653101},
	abstract = {The myelination of axons by oligodendrocytes is a highly complex cell-to-cell interaction. Oligodendrocytes and axons have a reciprocal signaling relationship in which oligodendrocytes receive cues from axons that direct their myelination, and oligodendrocytes subsequently shape axonal structure and conduction. Oligodendrocytes are necessary for the maturation of excitatory domains on the axon including nodes of Ranvier, help buffer potassium, and support neuronal energy metabolism. Disruption of the oligodendrocyte-axon unit in traumatic injuries, Alzheimer’s disease and demyelinating diseases such as multiple sclerosis results in axonal dysfunction and can culminate in neurodegeneration. In this review, we discuss the mechanisms by which demyelination and loss of oligodendrocytes compromise axons. We highlight the intra-axonal cascades initiated by demyelination that can result in irreversible axonal damage. Both the restoration of oligodendrocyte myelination or neuroprotective therapies targeting these intra-axonal cascades are likely to have therapeutic potential in disorders in which oligodendrocyte support of axons is disrupted.},
	urldate = {2022-11-13},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Duncan, Greg J. and Simkins, Tyrell J. and Emery, Ben},
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/YQ9Y3XQ6/Duncan et al. - 2021 - Neuron-Oligodendrocyte Interactions in the Structu.pdf:application/pdf},
}

@article{MadadiAsl2018,
	title = {Dendritic and {Axonal} {Propagation} {Delays} {May} {Shape} {Neuronal} {Networks} {With} {Plastic} {Synapses}},
	volume = {9},
	issn = {1664-042X},
	doi = {10.3389/fphys.2018.01849},
	abstract = {Biological neuronal networks are highly adaptive and plastic. For instance, spike-timing-dependent plasticity (STDP) is a core mechanism which adapts the synaptic strengths based on the relative timing of pre- and postsynaptic spikes. In various fields of physiology, time delays cause a plethora of biologically relevant dynamical phenomena. However, time delays increase the complexity of model systems together with the computational and theoretical analysis burden. Accordingly, in computational neuronal network studies propagation delays were often neglected. As a downside, a classic STDP rule in oscillatory neurons without propagation delays is unable to give rise to bidirectional synaptic couplings, i.e., loops or uncoupled states. This is at variance with basic experimental results. In this mini review, we focus on recent theoretical studies focusing on how things change in the presence of propagation delays. Realistic propagation delays may lead to the emergence of neuronal activity and synaptic connectivity patterns, which cannot be captured by classic STDP models. In fact, propagation delays determine the inventory of attractor states and shape their basins of attractions. The results reviewed here enable to overcome fundamental discrepancies between theory and experiments. Furthermore, these findings are relevant for the development of therapeutic brain stimulation techniques aiming at shifting the diseased brain to more favorable attractor states.},
	language = {eng},
	journal = {Frontiers in Physiology},
	author = {Madadi Asl, Mojtaba and Valizadeh, Alireza and Tass, Peter A.},
	year = {2018},
	pmid = {30618847},
	pmcid = {PMC6307091},
	keywords = {⛔ No INSPIRE recid found, living systems, mathematical modeling, propagation delays, spike-timing-dependent plasticity, synchronization},
	pages = {1849},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/K6CU5AU8/Madadi Asl et al. - 2018 - Dendritic and Axonal Propagation Delays May Shape .pdf:application/pdf},
}

@article{Furber2013,
	title = {Overview of the {SpiNNaker} {System} {Architecture}},
	volume = {62},
	issn = {0018-9340},
	url = {http://ieeexplore.ieee.org/document/6226357/},
	doi = {10.1109/TC.2012.142},
	number = {12},
	urldate = {2022-11-13},
	journal = {IEEE Transactions on Computers},
	author = {Furber, Steve B. and Lester, David R. and Plana, Luis A. and Garside, Jim D. and Painkras, Eustace and Temple, Steve and Brown, Andrew D.},
	month = dec,
	year = {2013},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2454--2467},
	file = {Accepted Version:/Users/laurentperrinet/Zotero/storage/94WATZXM/Furber et al. - 2013 - Overview of the SpiNNaker System Architecture.pdf:application/pdf},
}

@article{Merolla2014,
	title = {A million spiking-neuron integrated circuit with a scalable communication network and interface},
	volume = {345},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.1254642},
	doi = {10.1126/science.1254642},
	abstract = {Modeling computer chips on real brains
            
              Computers are nowhere near as versatile as our own brains. Merolla
              et al.
              applied our present knowledge of the structure and function of the brain to design a new computer chip that uses the same wiring rules and architecture. The flexible, scalable chip operated efficiently in real time, while using very little power.
            
            
              Science
              , this issue p.
              668
            
          , 
            A large-scale computer chip mimics many features of a real brain.
          , 
            Inspired by the brain’s structure, we have developed an efficient, scalable, and flexible non–von Neumann architecture that leverages contemporary silicon technology. To demonstrate, we built a 5.4-billion-transistor chip with 4096 neurosynaptic cores interconnected via an intrachip network that integrates 1 million programmable spiking neurons and 256 million configurable synapses. Chips can be tiled in two dimensions via an interchip communication interface, seamlessly scaling the architecture to a cortexlike sheet of arbitrary size. The architecture is well suited to many applications that use complex neural networks in real time, for example, multiobject detection and classification. With 400-pixel-by-240-pixel video input at 30 frames per second, the chip consumes 63 milliwatts.},
	language = {en},
	number = {6197},
	urldate = {2022-11-13},
	journal = {Science},
	author = {Merolla, Paul A. and Arthur, John V. and Alvarez-Icaza, Rodrigo and Cassidy, Andrew S. and Sawada, Jun and Akopyan, Filipp and Jackson, Bryan L. and Imam, Nabil and Guo, Chen and Nakamura, Yutaka and Brezzo, Bernard and Vo, Ivan and Esser, Steven K. and Appuswamy, Rathinakumar and Taba, Brian and Amir, Arnon and Flickner, Myron D. and Risk, William P. and Manohar, Rajit and Modha, Dharmendra S.},
	month = aug,
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {668--673},
}

@book{Furber2020,
	title = {{SpiNNaker}: {A} {Spiking} {Neural} {Network} {Architecture}},
	isbn = {978-1-68083-652-3 978-1-68083-653-0},
	shorttitle = {{SpiNNaker}},
	url = {https://nowpublishers.com/article/BookDetails/9781680836523},
	urldate = {2022-11-13},
	publisher = {Now Publishers},
	editor = {Furber, Steve and Bogdan, Petrut},
	year = {2020},
	doi = {10.1561/9781680836523},
	keywords = {⛔ No INSPIRE recid found},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/ABFZ4KGY/Furber and Bogdan - 2020 - SpiNNaker A Spiking Neural Network Architecture.pdf:application/pdf},
}

@article{Davies2018,
	title = {Loihi: {A} {Neuromorphic} {Manycore} {Processor} with {On}-{Chip} {Learning}},
	volume = {38},
	issn = {0272-1732, 1937-4143},
	shorttitle = {Loihi},
	url = {https://ieeexplore.ieee.org/document/8259423/},
	doi = {10.1109/MM.2018.112130359},
	number = {1},
	urldate = {2022-11-13},
	journal = {IEEE Micro},
	author = {Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain, Shweta and Liao, Yuyun and Lin, Chit-Kwan and Lines, Andrew and Liu, Ruokun and Mathaikutty, Deepak and McCoy, Steven and Paul, Arnab and Tse, Jonathan and Venkataramanan, Guruguhanathan and Weng, Yi-Hsin and Wild, Andreas and Yang, Yoonseok and Wang, Hong},
	month = jan,
	year = {2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {82--99},
}

@article{Schuman2017,
	title = {A {Survey} of {Neuromorphic} {Computing} and {Neural} {Networks} in {Hardware}},
	url = {http://arxiv.org/abs/1705.06963},
	abstract = {Neuromorphic computing has come to refer to a variety of brain-inspired computers, devices, and models that contrast the pervasive von Neumann computer architecture. This biologically inspired approach has created highly connected synthetic neurons and synapses that can be used to model neuroscience theories as well as solve challenging machine learning problems. The promise of the technology is to create a brain-like ability to learn and adapt, but the technical challenges are significant, starting with an accurate neuroscience model of how the brain works, to finding materials and engineering breakthroughs to build devices to support these models, to creating a programming framework so the systems can learn, to creating applications with brain-like capabilities. In this work, we provide a comprehensive survey of the research and motivations for neuromorphic computing over its history. We begin with a 35-year review of the motivations and drivers of neuromorphic computing, then look at the major research areas of the field, which we define as neuro-inspired models, algorithms and learning approaches, hardware and devices, supporting systems, and finally applications. We conclude with a broad discussion on the major research topics that need to be addressed in the coming years to see the promise of neuromorphic computing fulfilled. The goals of this work are to provide an exhaustive review of the research conducted in neuromorphic computing since the inception of the term, and to motivate further work by illuminating gaps in the field where new research is needed.},
	urldate = {2021-03-25},
	journal = {arXiv:1705.06963 [cs]},
	author = {Schuman, Catherine D. and Potok, Thomas E. and Patton, Robert M. and Birdwell, J. Douglas and Dean, Mark E. and Rose, Garrett S. and Plank, James S.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.06963},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Neural and Evolutionary Computing},
	annote = {arXiv: 1705.06963},
	annote = {arXiv: 1705.06963},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/IE9A5G9V/Schuman et al. - 2017 - A Survey of Neuromorphic Computing and Neural Netw.pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/8AXIBLT4/1705.html:text/html},
}

@inproceedings{Pfeil2013a,
	title = {Neuromorphic learning towards nano second precision},
	doi = {10.1109/IJCNN.2013.6706828},
	abstract = {Temporal coding is one approach to representing information in spiking neural networks. An example of its application is the location of sounds by barn owls that requires especially precise temporal coding. Dependent upon the azimuthal angle, the arrival times of sound signals are shifted between both ears. In order to determine these interaural time differences, the phase difference of the signals is measured. We implemented this biologically inspired network on a neuromorphic hardware system and demonstrate spike-timing dependent plasticity on an analog, highly accelerated hardware substrate. Our neuromorphic implementation enables the resolution of time differences of less than 50 ns. On-chip Hebbian learning mechanisms select inputs from a pool of neurons which code for the same sound frequency. Hence, noise caused by different synaptic delays across these inputs is reduced. Furthermore, learning compensates for variations on neuronal and synaptic parameters caused by device mismatch intrinsic to the neuromorphic substrate.},
	booktitle = {The 2013 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Pfeil, Thomas and Scherzer, Anne-Christine and Schemmel, Johannes and Meier, Karlheinz},
	month = aug,
	year = {2013},
	note = {ISSN: 2161-4407},
	keywords = {⛔ No INSPIRE recid found, Delays, Emulation, Hardware, Neuromorphics, Neurons, System-on-chip, Vectors},
	pages = {1--5},
	annote = {ISSN: 2161-4407},
	annote = {ISSN: 2161-4407},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/E92BFDJY/6706828.html:text/html;Version soumise:/Users/laurentperrinet/Zotero/storage/W52LGEBI/Pfeil et al. - 2013 - Neuromorphic learning towards nano second precisio.pdf:application/pdf},
}

@article{Bartolozzi2007,
	title = {Synaptic {Dynamics} in {Analog} {VLSI}},
	volume = {19},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/19/10/2581-2603/7219},
	doi = {10.1162/neco.2007.19.10.2581},
	abstract = {Synapses are crucial elements for computation and information transfer in both real and artificial neural systems. Recent experimental findings and theoretical models of pulse-based neural networks suggest that synaptic dynamics can play a crucial role for learning neural codes and encoding spatio-temporal spike patterns. Within the context of hardware implementations of pulse based neural networks, several analog VLSI circuits modeling synaptic functionality have been proposed. We present an overview of previously proposed circuits and describe a novel analog VLSI synaptic circuit suitable for integration in large VLSI spike-based neural systems. The circuit proposed is based on a computational model that fits the real post-synaptic currents with exponentials. We present experimental data showing how the circuit exhibits realistic dynamics and show how it can be connected to additional modules for implementing a wide range of synaptic properties.},
	language = {en},
	number = {10},
	urldate = {2022-11-10},
	journal = {Neural Computation},
	author = {Bartolozzi, Chiara and Indiveri, Giacomo},
	month = oct,
	year = {2007},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2581--2603},
	file = {Bartolozzi et Indiveri - 2007 - Synaptic Dynamics in Analog VLSI.pdf:/Users/laurentperrinet/Zotero/storage/BIBHZQD6/Bartolozzi et Indiveri - 2007 - Synaptic Dynamics in Analog VLSI.pdf:application/pdf},
}

@article{Chan2007,
	title = {{AER} {EAR}: {A} {Matched} {Silicon} {Cochlea} {Pair} {With} {Address} {Event} {Representation} {Interface}},
	volume = {54},
	issn = {1558-0806},
	shorttitle = {{AER} {EAR}},
	doi = {10.1109/TCSI.2006.887979},
	abstract = {In this paper, we present an analog integrated circuit containing a matched pair of silicon cochleae and an address event interface. Each section of the cochlea, modeled by a second-order low-pass filter, is followed by a simplified inner hair cell circuit and a spiking neuron circuit. When the neuron spikes, an address event is generated on the asynchronous data bus. We present the results of the chip characterization and the results of an interaural time difference based sound localization experiment using the address event representation (AER) EAR. The chip was fabricated in a 3-metal 2-poly 0.5-mum CMOS process},
	number = {1},
	journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	author = {Chan, Vincent and Liu, Shih-Chii and van Schaik, Andr},
	month = jan,
	year = {2007},
	note = {Conference Name: IEEE Transactions on Circuits and Systems I: Regular Papers},
	keywords = {⛔ No INSPIRE recid found, Analog integrated circuits, Biological system modeling, Circuits, Ear, Low pass filters, neuromorphic engineering, Neuromorphics, Neurons, Protocols, Silicon, silicon cochlea, sound localization, Timing, Transmitters},
	pages = {48--59},
	annote = {Conference Name: IEEE Transactions on Circuits and Systems I: Regular Papers},
	annote = {Conference Name: IEEE Transactions on Circuits and Systems I: Regular Papers},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/5NIICG4A/4061005.html:text/html},
}

@inproceedings{Tschechne2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Bio-{Inspired} {Optic} {Flow} from {Event}-{Based} {Neuromorphic} {Sensor} {Input}},
	isbn = {978-3-319-11656-3},
	doi = {10.1007/978-3-319-11656-3_16},
	abstract = {Computational models of visual processing often use frame-based image acquisition techniques to process a temporally changing stimulus. This approach is unlike biological mechanisms that are spike-based and independent of individual frames. The neuromorphic Dynamic Vision Sensor (DVS) [Lichtsteiner et al., 2008] provides a stream of independent visual events that indicate local illumination changes, resembling spiking neurons at a retinal level. We introduce a new approach for the modelling of cortical mechanisms of motion detection along the dorsal pathway using this type of representation. Our model combines filters with spatio-temporal tunings also found in visual cortex to yield spatio-temporal and direction specificity. We probe our model with recordings of test stimuli, articulated motion and ego-motion. We show how our approach robustly estimates optic flow and also demonstrate how this output can be used for classification purposes.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} in {Pattern} {Recognition}},
	publisher = {Springer International Publishing},
	author = {Tschechne, Stephan and Sailer, Roman and Neumann, Heiko},
	editor = {El Gayar, Neamat and Schwenker, Friedhelm and Suen, Cheng},
	year = {2014},
	keywords = {⛔ No INSPIRE recid found, Classification, Event-Vision, Neural Model, Optic Flow},
	pages = {171--182},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/VC57J6DZ/Tschechne et al. - 2014 - Bio-Inspired Optic Flow from Event-Based Neuromorp.pdf:application/pdf},
}

@article{Kaiser2022,
	series = {Dendritic contributions to biological and artificial computations},
	title = {Emulating {Dendritic} {Computing} {Paradigms} on {Analog} {Neuromorphic} {Hardware}},
	volume = {489},
	issn = {0306-4522},
	url = {https://www.sciencedirect.com/science/article/pii/S0306452221004218},
	doi = {10.1016/j.neuroscience.2021.08.013},
	abstract = {BrainScaleS-2 is an accelerated and highly configurable neuromorphic system with physical models of neurons and synapses. Beyond networks of spiking point neurons, it allows for the implementation of user-defined neuron morphologies. Both passive propagation of electric signals between compartments as well as dendritic spikes and plateau potentials can be emulated. In this paper, three multi-compartment neuron morphologies are chosen to demonstrate passive propagation of postsynaptic potentials, spatio-temporal coincidence detection of synaptic inputs in a dendritic branch, and the replication of the BAC burst firing mechanism found in layer 5 pyramidal neurons of the neocortex.},
	language = {en},
	urldate = {2022-11-10},
	journal = {Neuroscience},
	author = {Kaiser, Jakob and Billaudelle, Sebastian and Müller, Eric and Tetzlaff, Christian and Schemmel, Johannes and Schmitt, Sebastian},
	month = may,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found, accelerated technology, AdEx neuron model, mixed-signal neuromorphic, multi-compartmental models, physical model},
	pages = {290--300},
	file = {ScienceDirect Full Text PDF:/Users/laurentperrinet/Zotero/storage/FQ6VKS9E/Kaiser et al. - 2022 - Emulating Dendritic Computing Paradigms on Analog .pdf:application/pdf},
}

@article{Rajendran2019,
	title = {Low-{Power} {Neuromorphic} {Hardware} for {Signal} {Processing} {Applications}: {A} {Review} of {Architectural} and {System}-{Level} {Design} {Approaches}},
	volume = {36},
	issn = {1558-0792},
	shorttitle = {Low-{Power} {Neuromorphic} {Hardware} for {Signal} {Processing} {Applications}},
	doi = {10.1109/MSP.2019.2933719},
	abstract = {Machine learning has emerged as the dominant tool for implementing complex cognitive tasks that require supervised, unsupervised, and reinforcement learning. While the resulting machines have demonstrated in some cases even superhuman performance, their energy consumption has often proved to be prohibitive in the absence of costly supercomputers. Most state-of-the-art machine-learning solutions are based on memoryless models of neurons. This is unlike the neurons in the human brain that encode and process information using temporal information in spike events. The different computing principles underlying biological neurons and how they combine together to efficiently process information is believed to be a key factor behind their superior efficiency compared to current machine-learning systems.},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Rajendran, Bipin and Sebastian, Abu and Schmuker, Michael and Srinivasa, Narayan and Eleftheriou, Evangelos},
	month = nov,
	year = {2019},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {⛔ No INSPIRE recid found, Encoding, Hardware, Mathematical model, Neuromorphics, Neurons, Signal processing algorithms, Synapses},
	pages = {97--110},
	annote = {Conference Name: IEEE Signal Processing Magazine},
	annote = {Conference Name: IEEE Signal Processing Magazine},
	file = {Version soumise:/Users/laurentperrinet/Zotero/storage/R3R5XWJE/Rajendran et al. - 2019 - Low-Power Neuromorphic Hardware for Signal Process.pdf:application/pdf},
}

@inproceedings{Hill2017,
	title = {A {Spike}-{Timing} {Neuromorphic} {Architecture}},
	doi = {10.1109/ICRC.2017.8123631},
	abstract = {Unlike general purpose computer architectures that are comprised of complex processor cores and sequential computation, the brain is innately parallel and contains highly complex connections between computational units (neurons). Key to the architecture of the brain is a functionality enabled by the combined effect of spiking communication and sparse connectivity with unique variable efficacies and temporal latencies. Utilizing these neuroscience principles, we have developed the Spiking Temporal Processing Unit (STPU) architecture which is well-suited for areas such as pattern recognition and natural language processing. In this paper, we formally describe the STPU, implement the STPU on a field programmable gate array, and show measured performance data.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Rebooting} {Computing} ({ICRC})},
	author = {Hill, Aaron J. and Donaldson, Jonathon W. and Rothganger, Fredrick H. and Vineyard, Craig M. and Follett, David R. and Follett, Pamela L. and Smith, Michael R. and Verzi, Stephen J. and Severa, William and Wang, Felix and Aimone, James B. and Naegle, John H. and James, Conrad D.},
	month = nov,
	year = {2017},
	keywords = {⛔ No INSPIRE recid found, Biological system modeling, Computer architecture, Delays, Neuromorphics, Neurons},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/UZJRYR7Q/8123631.html:text/html},
}

@article{Schuman2022,
	title = {Opportunities for neuromorphic computing algorithms and applications},
	volume = {2},
	copyright = {2022 Springer Nature America, Inc.},
	issn = {2662-8457},
	url = {http://www.nature.com/articles/s43588-021-00184-y},
	doi = {10.1038/s43588-021-00184-y},
	abstract = {Neuromorphic computing technologies will be important for the future of computing, but much of the work in neuromorphic computing has focused on hardware development. Here, we review recent results in neuromorphic computing algorithms and applications. We highlight characteristics of neuromorphic computing technologies that make them attractive for the future of computing and we discuss opportunities for future development of algorithms and applications on these systems.},
	language = {en},
	number = {1},
	urldate = {2022-11-10},
	journal = {Nature Computational Science},
	author = {Schuman, Catherine D. and Kulkarni, Shruti R. and Parsa, Maryam and Mitchell, J. Parker and Date, Prasanna and Kay, Bill},
	month = jan,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found, Computational science, Computer science},
	pages = {10--19},
	annote = {Number: 1 Publisher: Nature Publishing Group},
	annote = {Number: 1 Publisher: Nature Publishing Group},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/JYAJWGBY/Schuman et al. - 2022 - Opportunities for neuromorphic computing algorithm.pdf:application/pdf},
}

@article{Nieters2017,
	title = {Neuromorphic computation in multi-delay coupled models},
	volume = {61},
	issn = {0018-8646},
	doi = {10.1147/JRD.2017.2664698},
	abstract = {Neuromorphic computing provides a promising platform for processing high-dimensional noisy signals on dedicated hardware. Using design elements inspired by neurobiological findings and advances in machine learning methodology, delay-coupled systems have recently been developed in the field of neuromorphic computing. Delayed feedback connections enable such systems to generate a complex representation of injected input in the internal state of single nodes, which in our context refer to hardware components with nonlinear behavior and without any memory. In contrast to classical combinatorial circuits or feed-forward networks, this state is not distributed in space but in time. Hardware implementations with low hardware component counts are therefore particularly easy to design for delay-coupled systems. In this paper, we present an argument for using delay-coupled reservoirs using multiple feedback terms with different delays. We present a theoretical analysis of the resulting system, discuss surprising effects pertaining to the precise choice of delays, and provide a guideline for the optimal design of such systems.},
	number = {2/3},
	journal = {IBM Journal of Research and Development},
	author = {Nieters, P. and Leugering, J. and Pipa, G.},
	month = mar,
	year = {2017},
	note = {Conference Name: IBM Journal of Research and Development},
	keywords = {⛔ No INSPIRE recid found, Biological neural networks, Computational modeling, Computer architecture, Learning systems, Neuromorphics, Noise measurement},
	pages = {8:7--8:9},
	annote = {Conference Name: IBM Journal of Research and Development},
	annote = {Conference Name: IBM Journal of Research and Development},
}

@article{Liang2022,
	title = {A {Neuromorphic} {Model} {With} {Delay}-{Based} {Reservoir} for {Continuous} {Ventricular} {Heartbeat} {Detection}},
	volume = {69},
	issn = {1558-2531},
	doi = {10.1109/TBME.2021.3129306},
	abstract = {There is a growing interest in neuromorphic hardware since it offers a more intuitive way to achieve bio-inspired algorithms. This paper presents a neuromorphic model for intelligently processing continuous electrocardiogram (ECG) signal. This model aims to develop a hardware-based signal processing model and avoid employing digitally intensive operations, such as signal segmentation and feature extraction, which are not desired in an analogue neuromorphic system. We apply delay-based reservoir computing as the information processing core, along with a novel training and labelling method. Different from the conventional ECG classification techniques, this computation model is a end-to-end dynamic system that mimics the real-time signal flow in neuromorphic hardware. The input is the raw ECG stream, while the amplitude of the output represents the risk factor of a ventricular ectopic heartbeat. The intrinsic memristive property of the reservoir empowers the system to retain the historical ECG information for high-dimensional mapping. This model was evaluated with the MIT-BIH database under the inter-patient paradigm and yields 81\% sensitivity and 98\% accuracy. Under this architecture, the minimum size of memory required in the inference process can be as low as 3.1 MegaByte(MB) because the majority of the computation takes place in the analogue domain. Such computational modelling boosts memory efficiency by simplifying the computing procedure and minimizing the required memory for future wearable devices.},
	number = {6},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Liang, Xiangpeng and Li, Haobo and Vuckovic, Aleksandra and Mercer, John and Heidari, Hadi},
	month = jun,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {⛔ No INSPIRE recid found, Computational modeling, Continuous ventricular heartbeat detection, Databases, delay-based reservoir computing, Electrocardiography, Heart beat, Memory efficient analogue computing, Neuromorphics, Neurons, Physical neural network, Reservoirs},
	pages = {1837--1849},
	annote = {Conference Name: IEEE Transactions on Biomedical Engineering},
	annote = {Conference Name: IEEE Transactions on Biomedical Engineering},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/TREGFVNB/9622153.html:text/html;IEEE Xplore Full Text PDF:/Users/laurentperrinet/Zotero/storage/WU7GJPXN/Liang et al. - 2022 - A Neuromorphic Model With Delay-Based Reservoir fo.pdf:application/pdf},
}

@inproceedings{Hussain2012,
	title = {{DELTRON}: {Neuromorphic} architectures for delay based learning},
	shorttitle = {{DELTRON}},
	doi = {10.1109/APCCAS.2012.6419032},
	abstract = {We present a neuromorphic spiking neural network, the DELTRON, that can remember and store patterns by changing the delays of every connection as opposed to modifying the weights. The advantage of this architecture over traditional weight based ones is simpler hardware implementation without multipliers or digital-analog converters (DACs). The name is derived due to similarity in the learning rule with an earlier architecture called Tempotron. We present simulations of memory capacity of the DELTRON for different random spatio-temporal spike patterns and also present SPICE simulation results of the core circuits involved in a reconfigurable mixed signal implementation of this architecture.},
	booktitle = {2012 {IEEE} {Asia} {Pacific} {Conference} on {Circuits} and {Systems}},
	author = {Hussain, Shaista and Basu, Arindam and Wang, Mark and Hamilton, Tara Julia},
	month = dec,
	year = {2012},
	keywords = {⛔ No INSPIRE recid found, Computer architecture, Delay, Nerve fibers, Neuromorphics, Registers, Training},
	pages = {304--307},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/U7JED5V2/6419032.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/EFX4BLM6/Hussain et al. - 2012 - DELTRON Neuromorphic architectures for delay base.pdf:application/pdf},
}

@article{Renner2022,
	title = {Sparse {Vector} {Binding} on {Spiking} {Neuromorphic} {Hardware} {Using} {Synaptic} {Delays}},
	copyright = {info:eu-repo/semantics/closedAccess},
	url = {https://www.zora.uzh.ch/id/eprint/219676/},
	doi = {10.1145/3546790.3546820},
	abstract = {Vector Symbolic Architectures (VSA) were first proposed as connectionist models for symbolic reasoning, leveraging parallel and in-memory computing in brains and neuromorphic hardware that enable low-power, low-latency applications.
Symbols are defined in VSAs as points/vectors in a high-dimensional neural state-space.
For spiking neuromorphic hardware (and brains), particularly sparse representations are of interest, as they minimize the number of costly spikes. Furthermore, sparse representations can be efficiently stored in simple Hebbian auto-associative memories, which provide error correction in VSAs. 
However, the binding of spatially sparse representations is computationally expensive because it is not local to corresponding pairs of neurons as in VSAs with dense vectors.
Here, we present the first implementation of a sparse VSA on spiking neuromorphic hardware, specifically Intel's neuromorphic research chip Loihi.
To reduce the cost of binding, a delay line and coincidence detection are used, trading off space with time.
We show as proof of principle that our network on Loihi can perform the binding operation of a classical analogical reasoning task and discuss the cost of different sparse binding operations.
The proposed binding mechanism can be used as a building block for VSA-based architectures on neuromorphic hardware.},
	language = {eng},
	urldate = {2022-11-10},
	journal = {Proceedings of the International Conference on Neuromorphic Systems},
	author = {Renner, Alpha and Sandamirskaya, Yulia and Sommer, Friedrich T. and Frady, E. Paxon},
	month = jul,
	year = {2022},
	note = {Conference Name: ICONS 2022: International Conference on Neuromorphic Systems 2022
Meeting Name: ICONS 2022: International Conference on Neuromorphic Systems 2022
Place: Knoxville, TN, USA
Publisher: ACM Digital library},
	keywords = {⛔ No INSPIRE recid found, Binding, Coincidence detection, Hyperdimensional Computing, Neuromorphic Hardware, Sparse distributed code, Spiking Neural Networks, Vector Symbolic Architecture (VSA)},
	annote = {Conference Name: ICONS 2022: International Conference on Neuromorphic Systems 2022 Meeting Name: ICONS 2022: International Conference on Neuromorphic Systems 2022 Place: Knoxville, TN, USA Publisher: ACM Digital library},
	annote = {Conference Name: ICONS 2022: International Conference on Neuromorphic Systems 2022 Meeting Name: ICONS 2022: International Conference on Neuromorphic Systems 2022 Place: Knoxville, TN, USA Publisher: ACM Digital library},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/DF7PM4F7/Renner et al. - 2022 - Sparse Vector Binding on Spiking Neuromorphic Hard.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/XZ2CDM2M/219676.html:text/html;Texte intégral:/Users/laurentperrinet/Zotero/storage/4AAHUJY4/Renner et al. - 2022 - Sparse Vector Binding on Spiking Neuromorphic Hard.pdf:application/pdf},
}

@article{Sandamirskaya2022,
	title = {Neuromorphic computing hardware and neural architectures for robotics},
	volume = {7},
	url = {https://www.science.org/doi/abs/10.1126/scirobotics.abl8419},
	doi = {10.1126/scirobotics.abl8419},
	abstract = {Neuromorphic hardware enables fast and power-efficient neural network–based artificial intelligence that is well suited to solving robotic tasks. Neuromorphic algorithms can be further developed following neural computing principles and neural network architectures inspired by biological neural systems. In this Viewpoint, we provide an overview of recent insights from neuroscience that could enhance signal processing in artificial neural networks on chip and unlock innovative applications in robotics and autonomous intelligent systems. These insights uncover computing principles, primitives, and algorithms on different levels of abstraction and call for more research into the basis of neural computation and neuronally inspired computing hardware.},
	number = {67},
	urldate = {2022-11-10},
	journal = {Science Robotics},
	author = {Sandamirskaya, Yulia and Kaboli, Mohsen and Conradt, Jorg and Celikel, Tansu},
	month = jun,
	year = {2022},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {eabl8419},
	annote = {Publisher: American Association for the Advancement of Science},
	annote = {Publisher: American Association for the Advancement of Science},
}

@article{Markovic2020,
	title = {Physics for neuromorphic computing},
	volume = {2},
	copyright = {2020 Springer Nature Limited},
	issn = {2522-5820},
	url = {http://www.nature.com/articles/s42254-020-0208-2},
	doi = {10.1038/s42254-020-0208-2},
	abstract = {Neuromorphic computing takes inspiration from the brain to create energy-efficient hardware for information processing, capable of highly sophisticated tasks. Systems built with standard electronics achieve gains in speed and energy by mimicking the distributed topology of the brain. Scaling-up such systems and improving their energy usage, speed and performance by several orders of magnitude requires a revolution in hardware. We discuss how including more physics in the algorithms and nanoscale materials used for data processing could have a major impact in the field of neuromorphic computing. We review striking results that leverage physics to enhance the computing capabilities of artificial neural networks, using resistive switching materials, photonics, spintronics and other technologies. We discuss the paths that could lead these approaches to maturity, towards low-power, miniaturized chips that could infer and learn in real time.},
	language = {en},
	number = {9},
	urldate = {2022-11-10},
	journal = {Nature Reviews Physics},
	author = {Marković, Danijela and Mizrahi, Alice and Querlioz, Damien and Grollier, Julie},
	month = sep,
	year = {2020},
	note = {Number: 9
Publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found, Electronics, Nanoscale devices, photonics and device physics},
	pages = {499--510},
	annote = {Number: 9 Publisher: Nature Publishing Group},
	annote = {Number: 9 Publisher: Nature Publishing Group},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/T42B3TWW/s42254-020-0208-2.html:text/html;Version soumise:/Users/laurentperrinet/Zotero/storage/7JQK8LC9/Marković et al. - 2020 - Physics for neuromorphic computing.pdf:application/pdf},
}

@inproceedings{Stoffregen2019,
	title = {Event-{Based} {Motion} {Segmentation} by {Motion} {Compensation}},
	doi = {10.1109/ICCV.2019.00734},
	abstract = {In contrast to traditional cameras, whose pixels have a common exposure time, event-based cameras are novel bio-inspired sensors whose pixels work independently and asynchronously output intensity changes (called "events"), with microsecond resolution. Since events are caused by the apparent motion of objects, event-based cameras sample visual information based on the scene dynamics and are, therefore, a more natural fit than traditional cameras to acquire motion, especially at high speeds, where traditional cameras suffer from motion blur. However, distinguishing between events caused by different moving objects and by the camera's ego-motion is a challenging task. We present the first per-event segmentation method for splitting a scene into independently moving objects. Our method jointly estimates the event-object associations (i.e., segmentation) and the motion parameters of the objects (or the background) by maximization of an objective function, which builds upon recent results on event-based motion-compensation. We provide a thorough evaluation of our method on a public dataset, outperforming the state-of-the-art by as much as 10\%. We also show the first quantitative evaluation of a segmentation algorithm for event cameras, yielding around 90\% accuracy at 4 pixels relative displacement.},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Stoffregen, Timo and Gallego, Guillermo and Drummond, Tom and Kleeman, Lindsay and Scaramuzza, Davide},
	month = oct,
	year = {2019},
	note = {ISSN: 2380-7504},
	keywords = {⛔ No INSPIRE recid found, Cameras, Computer vision, Image segmentation, Motion compensation, Motion segmentation, Robot vision systems, Tracking},
	pages = {7243--7252},
	annote = {ISSN: 2380-7504},
	annote = {ISSN: 2380-7504},
	file = {IEEE Xplore Abstract Record:/Users/laurentperrinet/Zotero/storage/AJRMJFNJ/9010722.html:text/html;Version acceptée:/Users/laurentperrinet/Zotero/storage/SGYHZUPF/Stoffregen et al. - 2019 - Event-Based Motion Segmentation by Motion Compensa.pdf:application/pdf},
}

@article{Hidalgo-Carrio2020,
	title = {Learning {Monocular} {Dense} {Depth} from {Events}},
	url = {http://arxiv.org/abs/2010.08350},
	abstract = {Event cameras are novel sensors that output brightness changes in the form of a stream of asynchronous events instead of intensity frames. Compared to conventional image sensors, they offer significant advantages: high temporal resolution, high dynamic range, no motion blur, and much lower bandwidth. Recently, learning-based approaches have been applied to event-based data, thus unlocking their potential and making significant progress in a variety of tasks, such as monocular depth prediction. Most existing approaches use standard feed-forward architectures to generate network predictions, which do not leverage the temporal consistency presents in the event stream. We propose a recurrent architecture to solve this task and show significant improvement over standard feed-forward methods. In particular, our method generates dense depth predictions using a monocular setup, which has not been shown previously. We pretrain our model using a new dataset containing events and depth maps recorded in the CARLA simulator. We test our method on the Multi Vehicle Stereo Event Camera Dataset (MVSEC). Quantitative experiments show up to 50\% improvement in average depth error with respect to previous event-based methods.},
	urldate = {2021-01-22},
	journal = {arXiv:2010.08350 [cs]},
	author = {Hidalgo-Carrió, Javier and Gehrig, Daniel and Scaramuzza, Davide},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.08350},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {arXiv: 2010.08350},
	annote = {arXiv: 2010.08350},
	annote = {Comment: IEEE International Conference on 3D Vision (3DV), 2020},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/JW796T67/Hidalgo-Carrió et al. - 2020 - Learning Monocular Dense Depth from Events.pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/R3H5688U/2010.html:text/html},
}

@article{Perez-Cerda2015,
	title = {Pío del {Río} {Hortega} and the discovery of the oligodendrocytes},
	volume = {9},
	issn = {1662-5129},
	doi = {10.3389/fnana.2015.00092},
	abstract = {Pío del Río Hortega (1882-1945) discovered microglia and oligodendrocytes (OLGs), and after Ramón y Cajal, was the most prominent figure of the Spanish school of neurology. He began his scientific career with Nicolás Achúcarro from whom he learned the use of metallic impregnation techniques suitable to study non-neuronal cells. Later on, he joined Cajal's laboratory. and Subsequently, he created his own group, where he continued to develop other innovative modifications of silver staining methods that revolutionized the study of glial cells a century ago. He was also interested in neuropathology and became a leading authority on Central Nervous System (CNS) tumors. In parallel to this clinical activity, del Río Hortega rendered the first systematic description of a major polymorphism present in a subtype of macroglial cells that he named as oligodendroglia and later OLGs. He established their ectodermal origin and suggested that they built the myelin sheath of CNS axons, just as Schwann cells did in the periphery. Notably, he also suggested the trophic role of OLGs for neuronal functionality, an idea that has been substantiated in the last few years. Del Río Hortega became internationally recognized and established an important neurohistological school with outstanding pupils from Spain and abroad, which nearly disappeared after his exile due to the Spanish civil war. Yet, the difficulty of metal impregnation methods and their variability in results, delayed for some decades the confirmation of his great insights into oligodendrocyte biology until the development of electron microscopy and immunohistochemistry. This review aims at summarizing the pioneer and essential contributions of del Río Hortega to the current knowledge of oligodendrocyte structure and function, and to provide a hint of the scientific personality of this extraordinary and insufficiently recognized man.},
	language = {eng},
	journal = {Frontiers in Neuroanatomy},
	author = {Pérez-Cerdá, Fernando and Sánchez-Gómez, María Victoria and Matute, Carlos},
	year = {2015},
	pmid = {26217196},
	pmcid = {PMC4493393},
	keywords = {⛔ No INSPIRE recid found, Del Río Hortega, myelin sheath, oligodendrocyte precursor cell (OPC), oligodendroglia, Ramón y Cajal},
	pages = {92},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/D62FKKRY/Pérez-Cerdá et al. - 2015 - Pío del Río Hortega and the discovery of the oligo.pdf:application/pdf},
}

@article{Stetson1992,
	title = {Effects of age, sex, and anthropometric factors on nerve conduction measures},
	volume = {15},
	issn = {1097-4598},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mus.880151007},
	doi = {10.1002/mus.880151007},
	abstract = {Associations among measures of median, ulnar, and sural nerve conduction and age, skin temperature, sex, and anthropometric factors were evaluated in a population of 105 healthy, asymptomatic adults without occupational exposure to highly repetitive or forceful hand exertions. Height was negatively associated with sensory amplitude in all nerves tested (P {\textless} 0.001), and positively associated with median and ulnar sensory distal latencies (P {\textless} 0.01) and sural latency (P {\textless} 0.001). Index finger circumference was negatively associated with median and ulnar sensory amplitudes (P {\textless} 0.05). Sex, in isolation from highly correlated anthropometric factors such as height, was not found to be a significant predictor of median or ulnar nerve conduction measures. Equations using age, height, and finger circumference for prediction of normal values are presented. Failure to adjust normal nerve conduction values for these factors decreases the diagnostic specificity and sensitivity of the described measures, and may result in misclassification of individuals. © 1992 John Wiley \& Sons, Inc.},
	language = {en},
	number = {10},
	urldate = {2022-11-10},
	journal = {Muscle \& Nerve},
	author = {Stetson, Diana S. and Albers, James W. and Silverstein, Barbara A. and Wolfe, Robert A.},
	year = {1992},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mus.880151007},
	keywords = {⛔ No INSPIRE recid found, age, anthropometry, height, nerve conduction studies, normal values},
	pages = {1095--1104},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mus.880151007},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mus.880151007},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/F4LZV8YQ/mus.html:text/html;Version soumise:/Users/laurentperrinet/Zotero/storage/C4AJHEK4/Stetson et al. - 1992 - Effects of age, sex, and anthropometric factors on.pdf:application/pdf},
}

@article{Simons2016,
	title = {Oligodendrocytes: {Myelination} and {Axonal} {Support}},
	volume = {8},
	issn = {1943-0264},
	shorttitle = {Oligodendrocytes},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4691794/},
	doi = {10.1101/cshperspect.a020479},
	abstract = {Myelinated nerve fibers have evolved to enable fast and efficient transduction of electrical signals in the nervous system. To act as an electric insulator, the myelin sheath is formed as a multilamellar membrane structure by the spiral wrapping and subsequent compaction of the oligodendroglial plasma membrane around central nervous system (CNS) axons. Current evidence indicates that the myelin sheath is more than an inert insulating membrane structure. Oligodendrocytes are metabolically active and functionally connected to the subjacent axon via cytoplasmic-rich myelinic channels for movement of macromolecules to and from the internodal periaxonal space under the myelin sheath. This review summarizes our current understanding of how myelin is generated and also the role of oligodendrocytes in supporting the long-term integrity of myelinated axons., The myelin sheath is more than an inert insulating membrane structure. Oligodendrocytes in the sheath are connected to the subjacent axon via cytoplasmic-rich myelinic channels, and they actively support the integrity of the neuron.},
	number = {1},
	urldate = {2022-11-10},
	journal = {Cold Spring Harbor Perspectives in Biology},
	author = {Simons, Mikael and Nave, Klaus-Armin},
	month = jan,
	year = {2016},
	pmid = {26101081},
	pmcid = {PMC4691794},
	keywords = {⛔ No INSPIRE recid found},
	pages = {a020479},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/KD3GDFC5/Simons et Nave - 2016 - Oligodendrocytes Myelination and Axonal Support.pdf:application/pdf;PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/QYZNSJF5/Simons et Nave - 2016 - Oligodendrocytes Myelination and Axonal Support.pdf:application/pdf},
}

@article{VonHelmholz1850,
	title = {Messungen über den zeitlichen {Verlauf} der {Zuckung} animalischer {Muskeln} und die {Fortpflanzungsgeschwindigkeit} der {Reizung} in den {Nerven}},
	volume = {17},
	url = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2346292},
	language = {deu},
	urldate = {2022-11-09},
	journal = {Archiv für Anatomie, Physiologie und wissenschaftliche Medicin},
	author = {Von Helmholz, H.},
	year = {1850},
	keywords = {⛔ No INSPIRE recid found},
	pages = {176--364},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/X7IVIG9W/Von Helmholz - 1850 - Messungen über den zeitlichen Verlauf der Zuckung .pdf:application/pdf},
}

@article{Peyrard2020,
	title = {How is information transmitted in a nerve?},
	volume = {46},
	issn = {0092-0606},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7719126/},
	doi = {10.1007/s10867-020-09557-2},
	abstract = {In the last 15 years, a debate has emerged about the validity of the famous Hodgkin-Huxley model for nerve impulse. Mechanical models have been proposed. This note reviews the experimental properties of the nerve impulse and discusses the proposed alternatives. The experimental data, which rule out some of the alternative suggestions, show that while the Hodgkin-Huxley model may not be complete, it nevertheless includes essential features that should not be overlooked in the attempts made to improve, or supersede, it.},
	number = {4},
	urldate = {2022-11-08},
	journal = {Journal of Biological Physics},
	author = {Peyrard, Michel},
	month = dec,
	year = {2020},
	pmid = {33037976},
	pmcid = {PMC7719126},
	keywords = {⛔ No INSPIRE recid found},
	pages = {327--341},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/EQRALH57/Peyrard - 2020 - How is information transmitted in a nerve.pdf:application/pdf},
}

@article{Rubinsky2008,
	title = {Spatio-temporal motifs ‘remembered’ in neuronal networks following profound hypothermia},
	volume = {21},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608008001202},
	doi = {10.1016/j.neunet.2008.06.008},
	abstract = {Surgical procedures using hypothermic temperatures have been linked to complications such as seizures, impaired mental development and impaired memory. Although there is some evidence that the profound hypothermia ({\textless}12 ∘C) used in these procedures may be contributing to these neurological impairments, skepticism remains because of lack of evidence from experimental studies isolating the effects of hypothermia on neuronal networks. In order to attain a better understanding of profound hypothermia effects on neurons during surgical procedures, we applied cold to a cultured in-vitro neuronal network. The typical pattern of activity of such cultures is in the form of synchronized bursts, in which most of the recorded neurons fire action potentials in a short time period. In most cases, the bursting activity shows one or more repeating precise spatio-temporal patterns (motifs) that are sustained over long periods of time. In this experimental study, neuronal networks grown on microelectrode arrays (MEA) are subjected to profound hypothermia for an hour and the collective dynamics of the network as a whole are assessed. We show, by using a similarity analysis that compares changes in the time delays between neuronal activation at different burst motifs, that neuronal networks survive total inhibition by profound hypothermia and retain their intrinsic synchronized burst motifs even with substantial generalized neuronal degeneration. By applying multiple sessions of cold, we also show a marked monotonic reduction in the rate of burst firing and in the number of spikes of each neuron after each session.},
	language = {en},
	number = {9},
	urldate = {2022-11-19},
	journal = {Neural Networks},
	author = {Rubinsky, Liel and Raichman, Nadav and Lavee, Jacob and Frenk, Hanan and Ben-Jacob, Eshel},
	month = nov,
	year = {2008},
	keywords = {⛔ No INSPIRE recid found, Low temperature, Microelectrode arrays, Neuronal cultures, Synchronized bursting events},
	pages = {1232--1237},
	file = {ScienceDirect Full Text PDF:/Users/laurentperrinet/Zotero/storage/REYFMP8Q/Rubinsky et al. - 2008 - Spatio-temporal motifs ‘remembered’ in neuronal ne.pdf:application/pdf},
}

@misc{Fang2021a,
	title = {Incorporating {Learnable} {Membrane} {Time} {Constant} to {Enhance} {Learning} of {Spiking} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2007.05785},
	abstract = {Spiking Neural Networks (SNNs) have attracted enormous research interest due to temporal information processing capability, low power consumption, and high biological plausibility. However, the formulation of efficient and high-performance learning algorithms for SNNs is still challenging. Most existing learning methods learn weights only, and require manual tuning of the membrane-related parameters that determine the dynamics of a single spiking neuron. These parameters are typically chosen to be the same for all neurons, which limits the diversity of neurons and thus the expressiveness of the resulting SNNs. In this paper, we take inspiration from the observation that membrane-related parameters are different across brain regions, and propose a training algorithm that is capable of learning not only the synaptic weights but also the membrane time constants of SNNs. We show that incorporating learnable membrane time constants can make the network less sensitive to initial values and can speed up learning. In addition, we reevaluate the pooling methods in SNNs and find that max-pooling will not lead to significant information loss and have the advantage of low computation cost and binary compatibility. We evaluate the proposed method for image classification tasks on both traditional static MNIST, Fashion-MNIST, CIFAR-10 datasets, and neuromorphic N-MNIST, CIFAR10-DVS, DVS128 Gesture datasets. The experiment results show that the proposed method outperforms the state-of-the-art accuracy on nearly all datasets, using fewer time-steps. Our codes are available at https://github.com/fangwei123456/Parametric-Leaky-Integrate-and-Fire-Spiking-Neuron.},
	urldate = {2022-12-15},
	publisher = {arXiv},
	author = {Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Masquelier, Timothee and Huang, Tiejun and Tian, Yonghong},
	month = aug,
	year = {2021},
	note = {arXiv:2007.05785 [cs]},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {arXiv:2007.05785 [cs]},
	annote = {arXiv:2007.05785 [cs]},
	annote = {Comment: Accepted by International Conference on Computer Vision (ICCV) 2021},
	file = {arXiv Fulltext PDF:/Users/laurentperrinet/Zotero/storage/GLK4XBIF/Fang et al. - 2021 - Incorporating Learnable Membrane Time Constant to .pdf:application/pdf;arXiv.org Snapshot:/Users/laurentperrinet/Zotero/storage/5R5UND2R/2007.html:text/html},
}

@article{Maunsell1983,
	title = {Functional properties of neurons in middle temporal visual area of the macaque monkey. {I}. {Selectivity} for stimulus direction, speed, and orientation},
	volume = {49},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.1983.49.5.1127},
	doi = {10.1152/jn.1983.49.5.1127},
	abstract = {1. Recordings were made from single units in the middle temporal visual area (MT) of anesthetized, paralyzed macaque monkeys. A computer-driven stimulator was used to make quantitative tests of selectivity for stimulus direction, speed, and orientation. The data were taken from 168 units that were histologically identified as being in MT. 2. The results confirm previous reports of a high degree of direction selectivity in MT. The response above background to stimuli moving in a unit's preferred direction was, an average, 10.9 times that to stimuli moving in the opposite direction. There was a marked tendency for nearby units to have similar preferred directions. 3. Most units were also sharply tuned for the speed of stimulus motion. For some cells the response fell to less than half-maximal at speeds only a factor of two from the optimum; on average, responses were greater than half-maximal only over a 7.7-fold range of speed. The distribution of preferred speeds for different units was unimodal, with a peak near 32 degrees/s; the total range of preferred speeds extended from 2 to 256 degrees/s. Nearby units generally responded best to similar speeds of motion. 4. Most units in MT showed selectivity for stimulus orientation when tested with stationary, flashed bars. However, stationary stimuli generally elicited only brief responses; when averaged over the duration of the stimulus, the responses were much less than those to moving stimuli. The preferred orientation was usually, but not always, perpendicular to the preferred direction of movement. 5. A comparison of the results of the present study with a previous quantitative investigation in the owl monkey shows a striking similarity in response properties in MT of the two species. 6. The presence of both direction and speed selectivity in MT of the macaque suggests that this area is more specialized for the analysis of visual motion than has been previously recognized.},
	language = {en},
	number = {5},
	urldate = {2022-12-15},
	journal = {Journal of Neurophysiology},
	author = {Maunsell, J. H. and Van Essen, D. C.},
	month = may,
	year = {1983},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1127--1147},
	file = {Maunsell and Van Essen - 1983 - Functional properties of neurons in middle tempora.pdf:/Users/laurentperrinet/Zotero/storage/FFTNMUAR/Maunsell and Van Essen - 1983 - Functional properties of neurons in middle tempora.pdf:application/pdf},
}

@article{Montemurro2008,
	title = {Phase-of-{Firing} {Coding} of {Natural} {Visual} {Stimuli} in {Primary} {Visual} {Cortex}},
	volume = {18},
	issn = {0960-9822},
	url = {http://www.cell.com/current-biology/abstract/S0960-9822(08)00168-1},
	doi = {10.1016/j.cub.2008.02.023},
	language = {English},
	number = {5},
	urldate = {2022-12-15},
	journal = {Current Biology},
	author = {Montemurro, Marcelo A. and Rasch, Malte J. and Murayama, Yusuke and Logothetis, Nikos K. and Panzeri, Stefano},
	month = mar,
	year = {2008},
	pmid = {18328702},
	note = {Publisher: Elsevier},
	keywords = {⛔ No INSPIRE recid found, SYSNEURO},
	pages = {375--380},
	annote = {Publisher: Elsevier},
	annote = {Publisher: Elsevier},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/48VAM9IW/Montemurro et al. - 2008 - Phase-of-Firing Coding of Natural Visual Stimuli i.pdf:application/pdf},
}

@article{Gouras1960,
	title = {Graded potentials of bream retina},
	volume = {152},
	issn = {0022-3751},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1363334/},
	abstract = {Images
null},
	number = {3},
	urldate = {2022-12-14},
	journal = {The Journal of Physiology},
	author = {Gouras, P.},
	month = jul,
	year = {1960},
	pmid = {13828605},
	pmcid = {PMC1363334},
	keywords = {⛔ No INSPIRE recid found},
	pages = {487--505},
	file = {PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/S66JVURJ/Gouras - 1960 - Graded potentials of bream retina.pdf:application/pdf},
}

@misc{Kohn2016,
	title = {Utah array extracellular recordings of spontaneous and visually evoked                 activity from anesthetized macaque primary visual cortex ({V1}).},
	url = {http://crcns.org/data-sets/vc/pvc-11},
	language = {en},
	urldate = {2022-12-19},
	publisher = {CRCNS.org},
	author = {Kohn, A. and Smith, M.A.},
	year = {2016},
	doi = {10.6080/K0NC5Z4X},
	keywords = {⛔ No INSPIRE recid found, Macaque, Neuroscience, Primary visual cortex},
	annote = {Other
The data comprise two conditions: spontaneous and evoked V1 activity. The data were
 recorded by Matthew Smith and Adam Kohn, in the Kohn lab at the Albert Einstein College
 of Medicine (both data sets), and J. Anthony Movshon’s lab at New York University
 (spontaneous data set). Tai Sing Lee (Carnegie Mellon University) provided research
 support and Ryan Kelly (Carnegie Mellon University) participated in the data collection
 and processing.},
}

@article{Kass2005,
	title = {Statistical issues in the analysis of neuronal data},
	volume = {94},
	doi = {10.1152/jn.00648.2004},
	number = {1},
	journal = {Journal of neurophysiology},
	author = {Kass, Robert E. and Ventura, Valérie and Brown, Emery N.},
	year = {2005},
	note = {Publisher: American Physiological Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {8--25},
	annote = {Publisher: American Physiological Society},
	annote = {Publisher: American Physiological Society},
}

@article{VanRullen2006a,
	title = {The continuous wagon wheel illusion is associated with changes in electroencephalogram power at approximately 13 {Hz}.},
	volume = {26},
	issn = {1529-2401},
	url = {http://dx.doi.org/10.1523/JNEUROSCI.4654-05.2006},
	doi = {10.1523/JNEUROSCI.4654-05.2006},
	abstract = {Continuously moving objects sometimes appear to spontaneously reverse their motion direction. The mechanisms underlying this bistable phenomenon (the "continuous wagon wheel illusion") are heavily debated, but one interpretation suggests that motion information is perceived in discrete episodes at a rate between 10 and 15 Hz. Here, we asked observers to report the perceived direction of a continuously rotating wheel while 32-channel electroencephalogram (EEG) was recorded. We then separated periods of perceived true from illusory (reversed) motion and compared the EEG power spectrum under these two perceptually distinct yet physically identical conditions. The only reliable difference was observed approximately 13 Hz over centroparietal electrodes, independent of the temporal frequency of the wheel. Thus, it is likely to reflect internal processes rather than purely stimulus-driven activity. EEG power (13 Hz) decreased before the onset of illusory motion and increased before transitions back to real motion. Using this relationship, it was possible to predict above chance, on a trial-by-trial basis, the direction of the upcoming perceptual transition. These data are compatible with the idea that motion perception occurs in snapshots {\textless}100 ms in duration.},
	number = {2},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {VanRullen, R and Reddy, L and Koch, C},
	year = {2006},
	keywords = {⛔ No INSPIRE recid found, cog-neuro, eeg-components, neuro-coding, neuro-connectivity, neuro-sync, neuro-timing, perception},
	pages = {507, 502},
	annote = {00000},
	annote = {00000},
}

@article{Sotomayor-Gomez2020,
	title = {{SpikeShip}: {A} method for fast, unsupervised discovery of high-dimensional neural spiking patterns},
	shorttitle = {{SpikeShip}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.06.03.131573},
	abstract = {Neural coding and memory formation depend on temporal spiking sequences that span high-dimensional neural ensembles. The unsupervised discovery and characterization of these spiking sequences requires a suitable dissimilarity measure to spiking patterns. Here, we present a new dissimilarity measure based on optimal transport theory called SpikeShip, which compares multi-neuron spiking patterns based on all the relative spike-timing relationships among neurons. SpikeShip computes the optimal transport cost to make all the relative spiketiming relationships (across neurons) identical between two spiking patterns. We show that this transport cost can be decomposed into a temporal rigid translation term and a vector of neuron-specific transport flows. SpikeShip can be effectively computed for high-dimensional neuronal ensembles, has a low (linear) computational cost, and is sensitive to higher-order correlations. We applied SpikeShip to large-scale Neuropixel recordings during spontaneous activity and visual encoding. We show that high-dimensional spiking sequences detected via SpikeShip reliably distinguish between different natural images and different behavioral states. These spiking sequences carried complementary information to conventional firing rate codes. SpikeShip opens new avenues for studying neural coding and memory consolidation by finding temporal patterns in high-dimensional neural ensembles.},
	language = {en},
	urldate = {2023-01-18},
	author = {Sotomayor-Gómez, Boris and Battaglia, Francesco P. and Vinck, Martin},
	month = jun,
	year = {2020},
	doi = {10.1101/2020.06.03.131573},
	keywords = {⛔ No INSPIRE recid found},
	annote = {Publisher: Cold Spring Harbor Laboratory},
	annote = {Publisher: Cold Spring Harbor Laboratory},
	file = {Sotomayor-Gómez et al. - 2020 - SpikeShip A method for fast, unsupervised discove.pdf:/Users/laurentperrinet/Zotero/storage/BWSI4WRN/Sotomayor-Gómez et al. - 2020 - SpikeShip A method for fast, unsupervised discove.pdf:application/pdf},
}

@article{Mackevicius2019,
	title = {Unsupervised discovery of temporal sequences in high-dimensional datasets, with applications to neuroscience},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.38471},
	doi = {10.7554/eLife.38471},
	abstract = {Identifying low-dimensional features that describe large-scale neural recordings is a major challenge in neuroscience. Repeated temporal patterns (sequences) are thought to be a salient feature of neural dynamics, but are not succinctly captured by traditional dimensionality reduction techniques. Here, we describe a software toolbox—called seqNMF—with new methods for extracting informative, non-redundant, sequences from high-dimensional neural data, testing the significance of these extracted patterns, and assessing the prevalence of sequential structure in data. We test these methods on simulated data under multiple noise conditions, and on several real neural and behavioral data sets. In hippocampal data, seqNMF identifies neural sequences that match those calculated manually by reference to behavioral events. In songbird data, seqNMF discovers neural sequences in untutored birds that lack stereotyped songs. Thus, by identifying temporal structure directly from neural data, seqNMF enables dissection of complex neural circuits without relying on temporal references from stimuli or behavioral outputs.},
	urldate = {2023-01-24},
	journal = {eLife},
	author = {Mackevicius, Emily L and Bahle, Andrew H and Williams, Alex H and Gu, Shijie and Denisenko, Natalia I and Goldman, Mark S and Fee, Michale S},
	editor = {Colgin, Laura and Behrens, Timothy E},
	month = feb,
	year = {2019},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {⛔ No INSPIRE recid found, matrix factorization, sequence, unsupervised, Zebra finch},
	pages = {e38471},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/X7YPWEMH/Mackevicius et al. - 2019 - Unsupervised discovery of temporal sequences in hi.pdf:application/pdf},
}

@article{Nessler2013,
	title = {Bayesian {Computation} {Emerges} in {Generic} {Cortical} {Microcircuits} through {Spike}-{Timing}-{Dependent} {Plasticity}},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003037},
	doi = {10.1371/journal.pcbi.1003037},
	abstract = {The principles by which networks of neurons compute, and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function, are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits, where pyramidal neurons inhibit each other via interneurons, are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact, a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability, since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex.},
	language = {en},
	number = {4},
	urldate = {2021-05-20},
	journal = {PLOS Computational Biology},
	author = {Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Action potentials, Learning, Machine learning, Neural networks, Neuronal plasticity, Neurons, Probability distribution, Synapses},
	pages = {e1003037},
	file = {Full Text PDF:/Users/laurentperrinet/Zotero/storage/6QYJJJWF/Nessler et al. - 2013 - Bayesian Computation Emerges in Generic Cortical M.pdf:application/pdf;Snapshot:/Users/laurentperrinet/Zotero/storage/6NGNFEFH/article.html:text/html},
}

@misc{Yu2022,
	title = {{STSC}-{SNN}: {Spatio}-{Temporal} {Synaptic} {Connection} with {Temporal} {Convolution} and {Attention} for {Spiking} {Neural} {Networks}},
	shorttitle = {{STSC}-{SNN}},
	url = {http://arxiv.org/abs/2210.05241},
	abstract = {Spiking Neural Networks (SNNs), as one of the algorithmic models in neuromorphic computing, have gained a great deal of research attention owing to temporal information processing capability, low power consumption, and high biological plausibility. The potential to efficiently extract spatio-temporal features makes it suitable for processing the event streams. However, existing synaptic structures in SNNs are almost full-connections or spatial 2D convolution, neither of which can extract temporal dependencies adequately. In this work, we take inspiration from biological synapses and propose a spatio-temporal synaptic connection SNN (STSC-SNN) model, to enhance the spatio-temporal receptive fields of synaptic connections, thereby establishing temporal dependencies across layers. Concretely, we incorporate temporal convolution and attention mechanisms to implement synaptic filtering and gating functions. We show that endowing synaptic models with temporal dependencies can improve the performance of SNNs on classification tasks. In addition, we investigate the impact of performance vias varied spatial-temporal receptive fields and reevaluate the temporal modules in SNNs. Our approach is tested on neuromorphic datasets, including DVS128 Gesture (gesture recognition), N-MNIST, CIFAR10-DVS (image classification), and SHD (speech digit recognition). The results show that the proposed model outperforms the state-of-the-art accuracy on nearly all datasets.},
	urldate = {2022-10-25},
	publisher = {arXiv},
	author = {Yu, Chengting and Gu, Zheming and Li, Da and Wang, Gaoang and Wang, Aili and Li, Erping},
	month = oct,
	year = {2022},
	note = {arXiv:2210.05241 [cs, q-bio, stat]},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
	annote = {arXiv:2210.05241 [cs, q-bio, stat]},
	annote = {arXiv:2210.05241 [cs, q-bio, stat]},
	annote = {arXiv:2210.05241 [cs, q-bio, stat]},
}

@inproceedings{Howard2019,
	title = {Searching for {MobileNetV3}},
	booktitle = {Proceedings of the {IEEE}/{CVF} international conference on computer vision ({ICCV})},
	author = {Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and Le, Quoc V. and Adam, Hartwig},
	month = oct,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computer Vision and Pattern Recognition},
}

@article{Baudot2013,
	title = {Animation of natural scene by virtual eye-movements evokes high precision and low noise in {V1} neurons},
	volume = {7},
	issn = {1662-5110},
	url = {https://www.frontiersin.org/articles/10.3389/fncir.2013.00206},
	doi = {10.3389/fncir.2013.00206},
	abstract = {Synaptic noise is thought to be a limiting factor for computational efficiency in the brain. In visual cortex (V1), ongoing activity is present in vivo, and spiking responses to simple stimuli are highly unreliable across trials. Stimulus statistics used to plot receptive fields, however, are quite different from those experienced during natural visuomotor exploration. We recorded V1 neurons intracellularly in the anaesthetized and paralyzed cat and compared their spiking and synaptic responses to full field natural images animated by simulated eye-movements to those evoked by simpler (grating) or higher dimensionality statistics (dense noise). In most cells, natural scene animation was the only condition where high temporal precision (in the 10–20 ms range) was maintained during sparse and reliable activity. At the subthreshold level, irregular but highly reproducible membrane potential dynamics were observed, even during long (several 100 ms) “spike-less” periods. We showed that both the spatial structure of natural scenes and the temporal dynamics of eye-movements increase the signal-to-noise ratio by a non-linear amplification of the signal combined with a reduction of the subthreshold contextual noise. These data support the view that the sparsening and the time precision of the neural code in V1 may depend primarily on three factors: (1) broadband input spectrum: the bandwidth must be rich enough for recruiting optimally the diversity of spatial and time constants during recurrent processing; (2) tight temporal interplay of excitation and inhibition: conductance measurements demonstrate that natural scene statistics narrow selectively the duration of the spiking opportunity window during which the balance between excitation and inhibition changes transiently and reversibly; (3) signal energy in the lower frequency band: a minimal level of power is needed below 10 Hz to reach consistently the spiking threshold, a situation rarely reached with visual dense noise.},
	urldate = {2022-09-29},
	journal = {Frontiers in Neural Circuits},
	author = {Baudot, Pierre and Levy, Manuel and Marre, Olivier and Monier, Cyril and Pananceau, Marc and Frégnac, Yves},
	year = {2013},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
}

@article{SanzLeon2013,
	title = {The {Virtual} {Brain}: a simulator of primate brain network dynamics},
	volume = {7},
	issn = {1662-5196},
	shorttitle = {The {Virtual} {Brain}},
	url = {https://www.frontiersin.org/articles/10.3389/fninf.2013.00010},
	doi = {10.3389/fninf.2013.00010},
	abstract = {We present The Virtual Brain (TVB), a neuroinformatics platform for full brain network simulations using biologically realistic connectivity. This simulation environment enables the model-based inference of neurophysiological mechanisms across different brain scales that underlie the generation of macroscopic neuroimaging signals including functional MRI (fMRI), EEG and MEG. Researchers from different backgrounds can benefit from an integrative software platform including a supporting framework for data management (generation, organization, storage, integration and sharing) and a simulation core written in Python. TVB allows the reproduction and evaluation of personalized configurations of the brain by using individual subject data. This personalization facilitates an exploration of the consequences of pathological changes in the system, permitting to investigate potential ways to counteract such unfavorable processes. The architecture of TVB supports interaction with MATLAB packages, for example, the well known Brain Connectivity Toolbox. TVB can be used in a client-server configuration, such that it can be remotely accessed through the Internet thanks to its web-based HTML5, JS, and WebGL graphical user interface. TVB is also accessible as a standalone cross-platform Python library and application, and users can interact with the scientific core through the scripting interface IDLE, enabling easy modeling, development and debugging of the scientific kernel. This second interface makes TVB extensible by combining it with other libraries and modules developed by the Python scientific community. In this article, we describe the theoretical background and foundations that led to the development of TVB, the architecture and features of its major software components as well as potential neuroscience applications.},
	urldate = {2022-09-28},
	journal = {Frontiers in Neuroinformatics},
	author = {Sanz Leon, Paula and Knock, Stuart and Woodman, M. and Domide, Lia and Mersmann, Jochen and McIntosh, Anthony and Jirsa, Viktor},
	year = {2013},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
}

@article{Lecun1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {00189219},
	url = {http://ieeexplore.ieee.org/document/726791/},
	doi = {10.1109/5.726791},
	number = {11},
	urldate = {2021-05-18},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	note = {tex.bdsk-url-2: https://doi.org/10.1109/5.726791
tex.date-added: 2022-05-05 19:08:15 +0200
tex.date-modified: 2022-05-05 19:08:15 +0200},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2278--2324},
	annote = {tex.bdsk-url-2: https://doi.org/10.1109/5.726791 tex.date-added: 2022-05-05 19:08:15 +0200 tex.date-modified: 2022-05-05 19:08:15 +0200},
}

@article{Schrimpf2020,
	title = {Brain-score: {Which} artificial neural network for object recognition is most brain-like?},
	url = {https://www.biorxiv.org/content/early/2020/01/02/407007},
	doi = {10.1101/407007},
	abstract = {The internal representations of early deep artificial neural networks (ANNs) were found to be remarkably similar to the internal neural representations measured experimentally in the primate brain. Here we ask, as deep ANNs have continued to evolve, are they becoming more or less brain-like? ANNs that are most functionally similar to the brain will contain mechanisms that are most like those used by the brain. We therefore developed Brain-Score – a composite of multiple neural and behavioral benchmarks that score any ANN on how similar it is to the brain’s mechanisms for core object recognition – and we deployed it to evaluate a wide range of state-of-the-art deep ANNs. Using this scoring system, we here report that: (1) DenseNet-169, CORnet-S and ResNet-101 are the most brain-like ANNs. (2) There remains considerable variability in neural and behavioral responses that is not predicted by any ANN, suggesting that no ANN model has yet captured all the relevant mechanisms. (3) Extending prior work, we found that gains in ANN ImageNet performance led to gains on Brain-Score. However, correlation weakened at ¿= 70\% top-1 ImageNet performance, suggesting that additional guidance from neuroscience is needed to make further advances in capturing brain mechanisms. (4) We uncovered smaller (i.e. less complex) ANNs that are more brain-like than many of the best-performing ImageNet models, which suggests the opportunity to simplify ANNs to better understand the ventral stream. The scoring system used here is far from complete. However, we propose that evaluating and tracking model-benchmark correspondences through a Brain-Score that is regularly updated with new brain data is an exciting opportunity: experimental benchmarks can be used to guide machine network evolution, and machine networks are mechanistic hypotheses of the brain’s network and thus drive next experiments. To facilitate both of these, we release Brain-Score.org: a platform that hosts the neural and behavioral benchmarks, where ANNs for visual processing can be submitted to receive a Brain-Score and their rank relative to other models, and where new experimental data can be naturally incorporated.},
	journal = {bioRxiv : the preprint server for biology},
	author = {Schrimpf, Martin and Kubilius, Jonas and Hong, Ha and Majaj, Najib J. and Rajalingham, Rishi and Issa, Elias B. and Kar, Kohitij and Bashivan, Pouya and Prescott-Roy, Jonathan and Geiger, Franziska and Schmidt, Kailyn and Yamins, Daniel L. K. and DiCarlo, James J.},
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
tex.elocation-id: 407007
tex.eprint: https://www.biorxiv.org/content/early/2020/01/02/407007.full.pdf},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	annote = {Publisher: Cold Spring Harbor Laboratory tex.elocation-id: 407007 tex.eprint: https://www.biorxiv.org/content/early/2020/01/02/407007.full.pdf},
}

@article{Simonyan2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2021-05-24},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {183 citations (INSPIRE 2023/3/22)
183 citations w/o self (INSPIRE 2023/3/22)
arXiv:1409.1556 [cs.CV]},
	keywords = {\#nosource, ⛔ No DOI found, Computer Science - Computer Vision and Pattern Recognition},
	annote = {158 citations (INSPIRE 2022/10/1) 158 citations w/o self (INSPIRE 2022/10/1) arXiv:1409.1556 [cs.CV]},
}

@book{Mandelbrot1982,
	title = {The fractal geometry of nature},
	isbn = {978-0-7167-1186-5},
	url = {http://archive.org/details/fractalgeometryo00beno},
	abstract = {Rev. ed. of: Fractals. c1977; Includes indexes; Bibliography: p. [425]-443},
	language = {eng},
	urldate = {2022-09-27},
	publisher = {San Francisco : W.H. Freeman},
	author = {Mandelbrot, Benoit B.},
	collaborator = {{Internet Archive}},
	year = {1982},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
}

@article{Macdonald2022,
	title = {Neuromorphic {Tactile} {Edge} {Orientation} {Classification} in an {Unsupervised} {Spiking} {Neural} {Network}},
	volume = {22},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/18/6998},
	doi = {10.3390/s22186998},
	abstract = {Dexterous manipulation in robotic hands relies on an accurate sense of artificial touch. Here we investigate neuromorphic tactile sensation with an event-based optical tactile sensor combined with spiking neural networks for edge orientation detection. The sensor incorporates an event-based vision system (mini-eDVS) into a low-form factor artificial fingertip (the NeuroTac). The processing of tactile information is performed through a Spiking Neural Network with unsupervised Spike-Timing-Dependent Plasticity (STDP) learning, and the resultant output is classified with a 3-nearest neighbours classifier. Edge orientations were classified in 10-degree increments while tapping vertically downward and sliding horizontally across the edge. In both cases, we demonstrate that the sensor is able to reliably detect edge orientation, and could lead to accurate, bio-inspired, tactile processing in robotics and prosthetics applications.},
	language = {en},
	number = {18},
	urldate = {2022-09-26},
	journal = {Sensors},
	author = {Macdonald, Fraser L. A. and Lepora, Nathan F. and Conradt, Jörg and Ward-Cherrier, Benjamin},
	month = jan,
	year = {2022},
	note = {Number: 18
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {6998},
	annote = {Number: 18 Publisher: Multidisciplinary Digital Publishing Institute},
}

@inproceedings{Lee2014,
	address = {Paris, France},
	title = {Real-time motion estimation based on event-based vision sensor},
	isbn = {978-1-4799-5751-4},
	url = {http://ieeexplore.ieee.org/document/7025040/},
	doi = {10.1109/ICIP.2014.7025040},
	abstract = {Fast and efficient motion estimation is essential for a number of applications including the gesture-based user interface (UI) for portable devices like smart phones. In this paper, we propose a highly efficient method that can estimate four degree of freedom (DOF) motional components of a moving object based on an event-based vision sensor, the dynamic vision sensor (DVS). The proposed method finds informative events occurred at edges and estimates their velocities for global motion analysis. We will also describe a novel method to correct the aperture problem in the motion estimation.},
	language = {en},
	urldate = {2022-07-19},
	booktitle = {2014 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Lee, Jun Haeng and Lee, Kyoobin and Ryu, Hyunsurk and Park, Paul K. J. and Shin, Chang-Woo and Woo, Jooyeon and Kim, Jun-Seok},
	month = oct,
	year = {2014},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {204--208},
}

@article{Frye2015,
	title = {Elementary motion detectors},
	volume = {25},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982215000159},
	doi = {10.1016/j.cub.2015.01.013},
	language = {en},
	number = {6},
	urldate = {2022-03-21},
	journal = {Current Biology},
	author = {Frye, Mark},
	month = mar,
	year = {2015},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {R215--R217},
}

@article{Brette2007,
	title = {Exact {Simulation} of {Integrate}-and-{Fire} {Models} with {Exponential} {Currents}},
	volume = {19},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/19/10/2604-2609/7220},
	doi = {10.1162/neco.2007.19.10.2604},
	abstract = {Neural networks can be simulated exactly using event-driven strategies, in which the algorithm advances directly from one spike to the next spike. It applies to neuron models for which we have (1) an explicit expression for the evolution of the state variables between spikes and (2) an explicit test on the state variables that predicts whether and when a spike will be emitted. In a previous work, we proposed a method that allows exact simulation of an integrate-and-fire model with exponential conductances, with the constraint of a single synaptic time constant. In this note, we propose a method, based on polynomial root finding, that applies to integrate-and-fire models with exponential currents, with possibly many different synaptic time constants. Models can include biexponential synaptic currents and spike-triggered adaptation currents.},
	language = {en},
	number = {10},
	urldate = {2022-09-15},
	journal = {Neural Computation},
	author = {Brette, Romain},
	month = oct,
	year = {2007},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {2604--2609},
}

@article{Yoonessi2011,
	title = {Contribution of motion parallax to segmentation and depth perception},
	volume = {11},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/11.9.13},
	doi = {10.1167/11.9.13},
	abstract = {Relative image motion resulting from active movement of the observer could potentially serve as a powerful perceptual cue, both for segmentation of object boundaries and for depth perception. To examine the perceptual role of motion parallax from shearing motion, we measured human performance in three psychophysical tasks: segmentation, depth ordering, and depth magnitude estimation. Stimuli consisted of random dot textures that were synchronized to head movement with sine- or square-wave modulation patterns. Segmentation was assessed with a 2AFC orientation judgment of a motion-defined boundary. In the depth-ordering task, observers reported which modulation half-cycle appeared in front of the other. Perceived depth magnitude was matched to that of a 3D rendered image with multiple static cues. The results indicate that head movement might not be important for segmentation, even though it is crucial for obtaining depth from motion parallax—thus, concomitant depth perception does not appear to facilitate segmentation. Our findings suggest that segmentation works best for abrupt, sharply defined motion boundaries, whereas smooth gradients are more powerful for obtaining depth from motion parallax. Thus, motion parallax may contribute in a different manner to segmentation and to depth perception and suggests that their underlying mechanisms might be distinct.},
	number = {9},
	urldate = {2022-09-15},
	journal = {Journal of Vision},
	author = {Yoonessi, Ahmad and Baker, Jr., Curtis L.},
	month = aug,
	year = {2011},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {13},
}

@article{Nawrot2003,
	title = {Eye movements provide the extra-retinal signal required for the perception of depth from motion parallax},
	volume = {43},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698903001445},
	doi = {10.1016/S0042-6989(03)00144-5},
	abstract = {It has been unclear whether the perception of depth from motion parallax is an entirely visual process or whether it requires extra-retinal information such as head movements, vestibular activation, or eye movements. Using a motion aftereffect and static test stimulus technique to eliminate visual cues to depth, this psychophysical study demonstrates that the visual system employs a slow eye movement signal, optokinetic response (OKR) in particular, for the unambiguous perception of depth from motion parallax. A vestibular signal, or vestibularly driven eye movement signal is insufficient for unambiguous depth from motion parallax. Removal of the OKR eye movement signal gives rise to ambiguous perceived depth in motion parallax conditions. Neurophysiological studies suggest a possible neural mechanism in medial temporal and medial superior temporal cortical neurons that are selective to depth, motion, and direction of eye movement.},
	language = {en},
	number = {14},
	urldate = {2022-09-15},
	journal = {Vision Research},
	author = {Nawrot, Mark},
	month = jun,
	year = {2003},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {1553--1562},
}

@article{Rogers1979,
	title = {Motion {Parallax} as an {Independent} {Cue} for {Depth} {Perception}},
	volume = {8},
	issn = {0301-0066},
	url = {https://doi.org/10.1068/p080125},
	doi = {10.1068/p080125},
	abstract = {The perspective transformations of the retinal image, produced by either the movement of an observer or the movement of objects in the visual world, were found to produce a reliable, consistent, and unambiguous impression of relative depth in the absence of all other cues to depth and distance. The stimulus displays consisted of computer-generated random-dot patterns that could be transformed by each movement of the observer or the display oscilloscope to simulate the relative movement information produced by a three-dimensional surface. Using a stereoscopic matching task, the second experiment showed that the perceived depth from parallax transformations is in close agreement with the degree of relative image displacement, as well as producing a compelling impression of three-dimensionality not unlike that found with random-dot stereograms.},
	language = {en},
	number = {2},
	urldate = {2022-09-15},
	journal = {Perception},
	author = {Rogers, Brian and Graham, Maureen},
	month = apr,
	year = {1979},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {125--134},
	annote = {Publisher: SAGE Publications Ltd STM},
}

@article{Lin2021,
	title = {Supervised {Learning} {Algorithm} for {Multilayer} {Spiking} {Neural} {Networks} with {Long}-{Term} {Memory} {Spike} {Response} {Model}},
	volume = {2021},
	issn = {1687-5265},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8635912/},
	doi = {10.1155/2021/8592824},
	abstract = {As a new brain-inspired computational model of artificial neural networks, spiking neural networks transmit and process information via precisely timed spike trains. Constructing efficient learning methods is a significant research field in spiking neural networks. In this paper, we present a supervised learning algorithm for multilayer feedforward spiking neural networks; all neurons can fire multiple spikes in all layers. The feedforward network consists of spiking neurons governed by biologically plausible long-term memory spike response model, in which the effect of earlier spikes on the refractoriness is not neglected to incorporate adaptation effects. The gradient descent method is employed to derive synaptic weight updating rule for learning spike trains. The proposed algorithm is tested and verified on spatiotemporal pattern learning problems, including a set of spike train learning tasks and nonlinear pattern classification problems on four UCI datasets. Simulation results indicate that the proposed algorithm can improve learning accuracy in comparison with other supervised learning algorithms.},
	urldate = {2022-09-14},
	journal = {Computational Intelligence and Neuroscience},
	author = {Lin, Xianghong and Zhang, Mengwei and Wang, Xiangwen},
	month = nov,
	year = {2021},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {8592824},
}

@article{Dandekar2012,
	title = {Neural saccadic response estimation during natural viewing},
	volume = {107},
	issn = {0022-3077},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3311669/},
	doi = {10.1152/jn.00237.2011},
	abstract = {Studying neural activity during natural viewing conditions is not often attempted. Isolating the neural response of a single saccade is necessary to study neural activity during natural viewing; however, the close temporal spacing of saccades that occurs during natural viewing makes it difficult to determine the response to a single saccade. Herein, a general linear model (GLM) approach is applied to estimate the EEG neural saccadic response for different segments of the saccadic main sequence separately. It is determined that, in visual search conditions, neural responses estimated by conventional event-related averaging are significantly and systematically distorted relative to GLM estimates due to the close temporal spacing of saccades during visual search. Before the GLM is applied, analyses are applied that demonstrate that saccades during visual search with intersaccadic spacings as low as 100–150 ms do not exhibit significant refractory effects. Therefore, saccades displaying different intersaccadic spacings during visual search can be modeled using the same regressor in a GLM. With the use of the GLM approach, neural responses were separately estimated for five different ranges of saccade amplitudes during visual search. Occipital responses time locked to the onsets of saccades during visual search were found to account for, on average, 79 percent of the variance of EEG activity in a window 90–200 ms after the onsets of saccades for all five saccade amplitude ranges that spanned a range of 0.2–6.0 degrees. A GLM approach was also used to examine the lateralized ocular artifacts associated with saccades. Possible extensions of the methods presented here to account for the superposition of microsaccades in event-related EEG studies conducted in nominal fixation conditions are discussed.},
	number = {6},
	urldate = {2022-09-14},
	journal = {Journal of Neurophysiology},
	author = {Dandekar, Sangita and Privitera, Claudio and Carney, Thom and Klein, Stanley A.},
	month = mar,
	year = {2012},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {1776--1790},
}

@article{Hanuschkin2010,
	title = {A {General} and {Efficient} {Method} for {Incorporating} {Precise} {Spike} {Times} in {Globally} {Time}-{Driven} {Simulations}},
	volume = {4},
	issn = {1662-5196},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2965048/},
	doi = {10.3389/fninf.2010.00113},
	abstract = {Traditionally, event-driven simulations have been limited to the very restricted class of neuronal models for which the timing of future spikes can be expressed in closed form. Recently, the class of models that is amenable to event-driven simulation has been extended by the development of techniques to accurately calculate firing times for some integrate-and-fire neuron models that do not enable the prediction of future spikes in closed form. The motivation of this development is the general perception that time-driven simulations are imprecise. Here, we demonstrate that a globally time-driven scheme can calculate firing times that cannot be discriminated from those calculated by an event-driven implementation of the same model; moreover, the time-driven scheme incurs lower computational costs. The key insight is that time-driven methods are based on identifying a threshold crossing in the recent past, which can be implemented by a much simpler algorithm than the techniques for predicting future threshold crossings that are necessary for event-driven approaches. As run time is dominated by the cost of the operations performed at each incoming spike, which includes spike prediction in the case of event-driven simulation and retrospective detection in the case of time-driven simulation, the simple time-driven algorithm outperforms the event-driven approaches. Additionally, our method is generally applicable to all commonly used integrate-and-fire neuronal models; we show that a non-linear model employing a standard adaptive solver can reproduce a reference spike train with a high degree of precision.},
	urldate = {2022-09-14},
	journal = {Frontiers in Neuroinformatics},
	author = {Hanuschkin, Alexander and Kunkel, Susanne and Helias, Moritz and Morrison, Abigail and Diesmann, Markus},
	month = oct,
	year = {2010},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {113},
}

@article{Tatler2011,
	title = {Eye guidance in natural vision: {Reinterpreting} salience},
	volume = {11},
	issn = {1534-7362},
	shorttitle = {Eye guidance in natural vision},
	url = {https://doi.org/10.1167/11.5.5},
	doi = {10.1167/11.5.5},
	abstract = {Models of gaze allocation in complex scenes are derived mainly from studies of static picture viewing. The dominant framework to emerge has been image salience, where properties of the stimulus play a crucial role in guiding the eyes. However, salience-based schemes are poor at accounting for many aspects of picture viewing and can fail dramatically in the context of natural task performance. These failures have led to the development of new models of gaze allocation in scene viewing that address a number of these issues. However, models based on the picture-viewing paradigm are unlikely to generalize to a broader range of experimental contexts, because the stimulus context is limited, and the dynamic, task-driven nature of vision is not represented. We argue that there is a need to move away from this class of model and find the principles that govern gaze allocation in a broader range of settings. We outline the major limitations of salience-based selection schemes and highlight what we have learned from studies of gaze allocation in natural vision. Clear principles of selection are found across many instances of natural vision and these are not the principles that might be expected from picture-viewing studies. We discuss the emerging theoretical framework for gaze allocation on the basis of reward maximization and uncertainty reduction.},
	number = {5},
	urldate = {2022-09-14},
	journal = {Journal of Vision},
	author = {Tatler, Benjamin W. and Hayhoe, Mary M. and Land, Michael F. and Ballard, Dana H.},
	month = may,
	year = {2011},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {5},
}

@article{Poletti2015,
	title = {Head-{Eye} {Coordination} at a {Microscopic} {Scale}},
	volume = {25},
	issn = {0960-9822},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(15)01365-2},
	doi = {10.1016/j.cub.2015.11.004},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}Humans explore static visual scenes by alternating rapid eye movements (saccades) with periods of slow and incessant eye drifts [1–3]. These drifts are commonly believed to be the consequence of physiological limits in maintaining steady gaze, resulting in Brownian-like trajectories [4–7], which are almost independent in the two eyes [8–10]. However, because of the technical difficulty of recording minute eye movements, most knowledge on ocular drift comes from artificial laboratory conditions, in which the head of the observer is strictly immobilized. Little is known about eye drift during natural head-free fixation, when microscopic head movements are also continually present [11–13]. We have recently observed that the power spectrum of the visual input to the retina during ocular drift is largely unaffected by fixational head movements [14]. Here we elucidate the mechanism responsible for this invariance. We show that, contrary to common assumption, ocular drift does not move the eyes randomly, but compensates for microscopic head movements, thereby yielding highly correlated movements in the two eyes. This compensatory behavior is extremely fast, persists with one eye patched, and results in image motion trajectories that are only partially correlated on the two retinas. These findings challenge established views of how humans acquire visual information. They show that ocular drift is precisely controlled, as long speculated [15], and imply the existence of neural mechanisms that integrate minute multimodal signals.{\textless}/p{\textgreater}},
	language = {English},
	number = {24},
	urldate = {2022-09-13},
	journal = {Current Biology},
	author = {Poletti, Martina and Aytekin, Murat and Rucci, Michele},
	month = dec,
	year = {2015},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {3253--3259},
}

@article{VanderStigchel2006,
	title = {Eye movement trajectories and what they tell us},
	volume = {30},
	issn = {0149-7634},
	url = {https://www.sciencedirect.com/science/article/pii/S0149763405001740},
	doi = {10.1016/j.neubiorev.2005.12.001},
	abstract = {In the last two decades, research has shown that eye movement trajectories can be modified by situational determinants. These modifications can inform us about the mechanisms that control eye movements and they can yield information about the oculomotor, memory and attention system that is not easily obtained via other sources. Eye movement trajectories can deviate either towards or away from elements in the visual field. We review the conditions in which these deviations are found and the mechanisms underlying trajectory deviations. It is argued that deviations towards an element are caused by the unresolved competition in the oculomotor system between elements in a visual scene. Deviations away from an element are mainly observed in situations in which top-down preparation can influence the target selection process, but the exact cause of such deviations remains unclear.},
	language = {en},
	number = {5},
	urldate = {2022-09-13},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Van der Stigchel, Stefan and Meeter, Martijn and Theeuwes, Jan},
	month = jan,
	year = {2006},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {666--679},
}

@misc{Stringer2020,
	title = {{MouseLand}/rastermap: {A} multi-dimensional embedding algorithm},
	url = {https://github.com/MouseLand/rastermap},
	urldate = {2022-12-19},
	author = {Stringer, Carsen},
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
}

@article{Simoncelli2003a,
	title = {Characterization of {Neural} {Responses} with {Stochastic} {Stimuli}},
	url = {http://pillowlab.princeton.edu/pubs/simoncelli03c-preprint.pdf},
	language = {en},
	author = {Simoncelli, Eero P and Paninski, Liam and Pillow, Jonathan and Schwartz, Odelia},
	year = {2003},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{Ben-yishai1997,
	title = {Traveling {Waves} and the {Processing} of {Weakly} {Tuned} {Inputs} in a {Cortical} {Network} {Module}},
	volume = {77},
	author = {Ben-yishai, Rani and Hansel, David},
	year = {1997},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found, orientation selectivity, population vector, primary visual cortex},
	pages = {57--77},
	annote = {00000},
	annote = {00000},
}

@article{Konishi2003,
	title = {Coding of auditory space},
	volume = {26},
	issn = {0147-006X},
	doi = {10.1146/annurev.neuro.26.041002.131123},
	abstract = {Behavioral, anatomical, and physiological approaches can be integrated in the study of sound localization in barn owls. Space representation in owls provides a useful example for discussion of place and ensemble coding. Selectivity for space is broad and ambiguous in low-order neurons. Parallel pathways for binaural cues and for different frequency bands converge on high-order space-specific neurons, which encode space more precisely. An ensemble of broadly tuned place-coding neurons may converge on a single high-order neuron to create an improved labeled line. Thus, the two coding schemes are not alternate methods. Owls can localize sounds by using either the isomorphic map of auditory space in the midbrain or forebrain neural networks in which space is not mapped.},
	language = {eng},
	journal = {Annual Review of Neuroscience},
	author = {Konishi, Masakazu},
	year = {2003},
	pmid = {14527266},
	keywords = {⛔ No INSPIRE recid found, Animal, Animals, Auditory Pathways, Auditory Perception, Behavior, Brain, Brain Mapping, Forms and Records Control, Models, Nerve Net, Neural Inhibition, Neurological, Sound Localization, Space Perception, Strigiformes},
	pages = {31--55},
}

@article{Lazar2004,
	title = {Time encoding with an integrate-and-fire neuron with a refractory period},
	volume = {58-60},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231204000177},
	doi = {10.1016/j.neucom.2004.01.022},
	abstract = {Time encoding is a formal method of mapping amplitude information into a time sequence. We show that under simple conditions, bandlimited stimuli encoded with an integrate-and-ÿre neuron with an absolute refractory period can be recovered loss-free from the neural spike train at its output. We provide an algorithm for perfect recovery and derive conditions for its convergence. c 2003 Elsevier B.V. All rights reserved.},
	language = {en},
	urldate = {2022-12-19},
	journal = {Neurocomputing},
	author = {Lazar, Aurel A.},
	month = jun,
	year = {2004},
	keywords = {⛔ No INSPIRE recid found},
	pages = {53--58},
}

@article{Golding2002,
	title = {Dendritic spikes as a mechanism for cooperative long-term potentiation},
	volume = {418},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature00854},
	doi = {10.1038/nature00854},
	abstract = {Strengthening of synaptic connections following coincident pre- and postsynaptic activity was proposed by Hebb as a cellular mechanism for learning1. Contemporary models assume that multiple synapses must act cooperatively to induce the postsynaptic activity required for hebbian synaptic plasticity2,3,4,5. One mechanism for the implementation of this cooperation is action potential firing, which begins in the axon, but which can influence synaptic potentiation following active backpropagation into dendrites6. Backpropagation is limited, however, and action potentials often fail to invade the most distal dendrites7,8,9,10. Here we show that long-term potentiation of synapses on the distal dendrites of hippocampal CA1 pyramidal neurons does require cooperative synaptic inputs, but does not require axonal action potential firing and backpropagation. Rather, locally generated and spatially restricted regenerative potentials (dendritic spikes) contribute to the postsynaptic depolarization and calcium entry necessary to trigger potentiation of distal synapses. We find that this mechanism can also function at proximal synapses, suggesting that dendritic spikes participate generally in a form of synaptic potentiation that does not require postsynaptic action potential firing in the axon.},
	language = {en},
	number = {6895},
	urldate = {2022-12-16},
	journal = {Nature},
	author = {Golding, Nace L. and Staff, Nathan P. and Spruston, Nelson},
	month = jul,
	year = {2002},
	note = {tex.copyright: 2002 Macmillan Magazines Ltd.},
	keywords = {⛔ No INSPIRE recid found, Humanities and Social Sciences, multidisciplinary, Science},
	pages = {326--331},
	annote = {Number: 6895 Publisher: Nature Publishing Group},
	annote = {Number: 6895 Publisher: Nature Publishing Group},
}

@article{Mel2017,
	title = {Synaptic plasticity in dendrites: complications and coping strategies},
	volume = {43},
	issn = {1873-6882},
	shorttitle = {Synaptic plasticity in dendrites},
	doi = {10.1016/j.conb.2017.03.012},
	abstract = {The elaborate morphology, nonlinear membrane mechanisms and spatiotemporally varying synaptic activation patterns of dendrites complicate the expression, compartmentalization and modulation of synaptic plasticity. To grapple with this complexity, we start with the observation that neurons in different brain areas face markedly different learning problems, and dendrites of different neuron types contribute to the cell's input-output function in markedly different ways. By committing to specific assumptions regarding a neuron's learning problem and its input-output function, specific inferences can be drawn regarding the synaptic plasticity mechanisms and outcomes that we 'ought' to expect for that neuron. Exploiting this assumption-driven approach can help both in interpreting existing experimental data and designing future experiments aimed at understanding the brain's myriad learning processes.},
	language = {eng},
	journal = {Current Opinion in Neurobiology},
	author = {Mel, Bartlett W. and Schiller, Jackie and Poirazi, Panayiota},
	month = apr,
	year = {2017},
	pmid = {28453975},
	keywords = {⛔ No INSPIRE recid found, Dendrites, Humans, Learning, Models, Neurological, Neuronal Plasticity, Synapses},
	pages = {177--186},
}

@article{Jeffress1948,
	title = {A place theory of sound localization},
	volume = {41},
	issn = {0021-9940},
	doi = {10.1037/h0061495},
	abstract = {The author presents a place theory of sound localization based upon the time difference of stimulation of the 2 ears. The hypothesis depends upon the known slow rate of conduction in small nerve fibers and the phenomenon of spatial summation. It assumes that some secondary fibers of the auditory tract divide, sending branches homolaterally and contralaterally. There is a further assumption that these neurons make synaptic connection with other fibers on each side, the latter neurones synapsing with both contralateral and homolateral neurones. Then, if the sound is in a median plane, the summation effect would be maximal in a central group of the tertiary fibers on each side. If the sound source is shifted, the summation effect would result in a shifting of the transmission through synapses in the tertiary zone. This provides a spatial change in the pattern of nerve discharge as a consequence of a temporal change in the binaural stimulation. The anatomical location of such a center is suggested either in the inferior colliculus or the medial geniculate body. Possible experimental procedures are suggested. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Journal of Comparative and Physiological Psychology},
	author = {Jeffress, Lloyd A.},
	year = {1948},
	keywords = {⛔ No INSPIRE recid found, Auditory Localization, Ear (Anatomy), Neurons, Temporal Frequency},
	pages = {35--39},
	annote = {Place: US Publisher: American Psychological Association},
	annote = {Place: US Publisher: American Psychological Association},
}

@incollection{Middlebrooks2015,
	series = {The {Human} {Auditory} {System}},
	title = {Chapter 6 - {Sound} localization},
	volume = {129},
	url = {https://www.sciencedirect.com/science/article/pii/B9780444626301000068},
	abstract = {The auditory system derives locations of sound sources from spatial cues provided by the interaction of sound with the head and external ears. Those cues are analyzed in specific brainstem pathways and then integrated as cortical representation of locations. The principal cues for horizontal localization are interaural time differences (ITDs) and interaural differences in sound level (ILDs). Vertical and front/back localization rely on spectral-shape cues derived from direction-dependent filtering properties of the external ears. The likely first sites of analysis of these cues are the medial superior olive (MSO) for ITDs, lateral superior olive (LSO) for ILDs, and dorsal cochlear nucleus (DCN) for spectral-shape cues. Localization in distance is much less accurate than that in horizontal and vertical dimensions, and interpretation of the basic cues is influenced by additional factors, including acoustics of the surroundings and familiarity of source spectra and levels. Listeners are quite sensitive to sound motion, but it remains unclear whether that reflects specific motion detection mechanisms or simply detection of changes in static location. Intact auditory cortex is essential for normal sound localization. Cortical representation of sound locations is highly distributed, with no evidence for point-to-point topography. Spatial representation is strictly contralateral in laboratory animals that have been studied, whereas humans show a prominent right-hemisphere dominance.},
	language = {en},
	urldate = {2022-12-16},
	booktitle = {Handbook of {Clinical} {Neurology}},
	publisher = {Elsevier},
	author = {Middlebrooks, John C.},
	editor = {Aminoff, Michael J. and Boller, François and Swaab, Dick F.},
	month = jan,
	year = {2015},
	doi = {10.1016/B978-0-444-62630-1.00006-8},
	keywords = {⛔ No INSPIRE recid found, auditory cortex, auditory motion, distance perception, HRTF, interaural level difference, interaural time difference, precedence effect, Spatial hearing, superior colliculus, superior olivary complex},
	pages = {99--116},
}

@article{Rinberg2006,
	title = {Speed-{Accuracy} {Tradeoff} in {Olfaction}},
	volume = {51},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627306005538},
	doi = {10.1016/j.neuron.2006.07.013},
	abstract = {The basic psychophysical principle of speed-accuracy tradeoff (SAT) has been used to understand key aspects of neuronal information processing in vision and audition, but the principle of SAT is still debated in olfaction. In this study we present the direct observation of SAT in olfaction. We developed a behavioral paradigm for mice in which both the duration of odorant sampling and the difficulty of the odor discrimination task were controlled by the experimenter. We observed that the accuracy of odor discrimination increases with the duration of imposed odorant sampling, and that the rate of this increase is slower for harder tasks. We also present a unifying picture of two previous, seemingly disparate experiments on timing of odorant sampling in odor discrimination tasks. The presence of SAT in olfaction provides strong evidence for temporal integration in olfaction and puts a constraint on models of olfactory processing.},
	language = {en},
	number = {3},
	urldate = {2022-12-16},
	journal = {Neuron},
	author = {Rinberg, Dmitry and Koulakov, Alexei and Gelperin, Alan},
	month = aug,
	year = {2006},
	keywords = {⛔ No INSPIRE recid found, SYSNEURO},
	pages = {351--358},
}

@incollection{Cleland2014,
	title = {Construction of {Odor} {Representations} by {Olfactory} {Bulb} {Microcircuits}},
	volume = {208},
	isbn = {978-0-444-63350-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444633507000073},
	abstract = {Like other sensory systems, the olfactory system transduces specific features of the external environment and must construct an organized sensory representation from these highly fragmented inputs. As with these other systems, this representation is not accurate per se, but is constructed for utility, and emphasizes certain, presumably useful, features over others. I here describe the cellular and circuit mechanisms of the peripheral olfactory system that underlie this process of sensory construction, emphasizing the distinct architectures and properties of the two prominent computational layers in the olfactory bulb. Notably, while the olfactory system solves essentially similar conceptual problems to other sensory systems, such as contrast enhancement, activity normalization, and extending dynamic range, its peculiarities often require qualitatively different computational algorithms than are deployed in other sensory modalities. In particular, the olfactory modality is intrinsically high dimensional, and lacks a simple, externally defined basis analogous to wavelength or pitch on which elemental odor stimuli can be quantitatively compared. Accordingly, the quantitative similarities of the receptive fields of different odorant receptors (ORs) vary according to the statistics of the odor environment. To resolve these unusual challenges, the olfactory bulb appears to utilize unique nontopographical computations and intrinsic learning mechanisms to perform the necessary high-dimensional, similarity-dependent computations. In sum, the early olfactory system implements a coordinated set of early sensory transformations directly analogous to those in other sensory systems, but accomplishes these with unique circuit architectures adapted to the properties of the olfactory modality.},
	language = {en},
	urldate = {2022-12-16},
	booktitle = {Progress in {Brain} {Research}},
	publisher = {Elsevier},
	author = {Cleland, Thomas A.},
	year = {2014},
	doi = {10.1016/B978-0-444-63350-7.00007-3},
	keywords = {⛔ No INSPIRE recid found},
	pages = {177--203},
}

@article{Kashiwadani1999,
	title = {Synchronized {Oscillatory} {Discharges} of {Mitral}/{Tufted} {Cells} {With} {Different} {Molecular} {Receptive} {Ranges} in the {Rabbit} {Olfactory} {Bulb}},
	volume = {82},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/full/10.1152/jn.1999.82.4.1786},
	doi = {10.1152/jn.1999.82.4.1786},
	abstract = {Individual glomeruli in the mammalian olfactory bulb represent a single or a few type(s) of odorant receptors. Signals from different types of receptors are thus sorted out into different glomeruli. How does the neuronal circuit in the olfactory bulb contribute to the combination and integration of signals received by different glomeruli? Here we examined electrophysiologically whether there were functional interactions between mitral/tufted cells associated with different glomeruli in the rabbit olfactory bulb. First, we made simultaneous recordings of extracellular single-unit spike responses of mitral/tufted cells and oscillatory local field potentials in the dorsomedial fatty acid–responsive region of the olfactory bulb in urethan-anesthetized rabbits. Using periodic artificial inhalation, the olfactory epithelium was stimulated with a homologous series ofn-fatty acids or n-aliphatic aldehydes. The odor-evoked spike discharges of mitral/tufted cells tended to phase-lock to the oscillatory local field potential, suggesting that spike discharges of many cells occur synchronously during odor stimulation. We then made simultaneous recordings of spike discharges from pairs of mitral/tufted cells located 300–500 μm apart and performed a cross-correlation analysis of their spike responses to odor stimulation. In ∼27\% of cell pairs examined, two cells with distinct molecular receptive ranges showed synchronized oscillatory discharges when olfactory epithelium was stimulated with one or a mixture of odorant(s) effective in activating both. The results suggest that the neuronal circuit in the olfactory bulb causes synchronized spike discharges of specific pairs of mitral/tufted cells associated with different glomeruli and the synchronization of odor-evoked spike discharges may contribute to the temporal binding of signals derived from different types of odorant receptor.},
	number = {4},
	urldate = {2022-12-16},
	journal = {Journal of Neurophysiology},
	author = {Kashiwadani, Hideki and Sasaki, Yasnory F. and Uchida, Naoshige and Mori, Kensaku},
	month = oct,
	year = {1999},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1786--1792},
	annote = {Publisher: American Physiological Society},
	annote = {Publisher: American Physiological Society},
}

@article{Vidyasagar1996,
	title = {Multiple mechanisms underlying the orientation selectivity of visual cortical neurones},
	volume = {19},
	issn = {0166-2236},
	url = {https://www.sciencedirect.com/science/article/pii/S016622369620027X},
	doi = {10.1016/S0166-2236(96)20027-X},
	abstract = {For over three decades, the mechanism of orientation selectivity of visual cortical neurones has been hotly debated. While intracortical inhibition has been implicated as playing a vital role, it has been difficult to observe it clearly. On the basis of recent findings, we propose a model in which the visual cortex brings together a number of different mechanisms for generating orientation-selective responses. Orientation biases in the thalamo-cortical input fibres provide an initial weak selectivity either directly in the excitatory input or by acting via cortical interneurones. This weak selectivity of postsynaptic potentials is then amplified by voltage-sensitive conductances of the cell membrane and excitatory and inhibitory intracortical circuitry, resulting in the sharp tuning seen in the spike discharges of visual cortical cells.},
	language = {en},
	number = {7},
	urldate = {2022-12-16},
	journal = {Trends in Neurosciences},
	author = {Vidyasagar, T. R. and Pei, X. and Volgushev, M.},
	month = jul,
	year = {1996},
	keywords = {⛔ No INSPIRE recid found},
	pages = {272--277},
}

@article{Chagnac-Amitai1989,
	title = {Horizontal spread of synchronized activity in neocortex and its control by {GABA}-mediated inhibition},
	volume = {61},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/abs/10.1152/jn.1989.61.4.747},
	doi = {10.1152/jn.1989.61.4.747},
	abstract = {1. Suppression of GABAA receptor-mediated inhibition disrupts the neural activity of neocortex and can lead to synchronized discharges that mimic those of partial epilepsy. We have studied the role of GABAA-mediated inhibition in controlling the synchronization and horizontal (tangential) spread of cortical activity. 2. Slices of rat SmI were maintained in vitro and focally stimulated in layer VI while recording with a horizontal array of extracellular electrodes. Inhibition was slightly suppressed by adding low concentrations of the GABAA antagonists bicuculline or bicuculline methiodide to the bathing medium. Under control conditions neural activity was narrowly confined to a vertical strip of cortex. The horizontal spread of activity expanded about twofold in the presence of antagonist concentrations (less than or equal to 0.5 microM) that were expected to suppress GABAA function by no more than 10-20\%. 3. At antagonist concentrations between 0.4 and 1.0 microM, evoked epileptiform activity appeared. These threshold-dose epileptiform events showed wide variations in size and duration (even at the same recording site), very variable distances of horizontal propagation, specific sites of propagation failure, reversals of propagation direction, and directional asymmetries in their probability of propagation. This contrasts with activity observed previously (Ref. 9) in high bicuculline concentrations (greater than or equal to 10 microM): large, stereotyped events that propagate reliably without decrement or reflection. 4. Intracellular recordings were obtained from pyramidal neurons in layers II/III in the presence of less than or equal to 1 microM bicuculline. Inhibitory postsynaptic potentials (IPSPs) were observed during both primary evoked responses and propagating epileptiform events and were often comparable in size and duration to those in untreated cortex. Epileptiform field potentials were always correlated with synaptic activity in single cells, but the pattern and type of PSPs varied with the form of the field potentials. Large amplitude epileptiform events coincided with an overwhelming inhibition of upper layer neurons. 5. We conclude that 1) the horizontal spread of normal cortical activity is strongly constrained by GABAA-mediated IPSPs, 2) a relatively small reduction in the efficacy of inhibition leads to a large increase in the spread of excitation, 3) initiation and propagation of synchronized epileptiform activity can occur even in the presence of robust cortical inhibition, and 4) the character of epileptiform activity is strongly affected by the influences of inhibition.},
	number = {4},
	urldate = {2022-12-16},
	journal = {Journal of Neurophysiology},
	author = {Chagnac-Amitai, Y. and Connors, B. W.},
	month = apr,
	year = {1989},
	keywords = {⛔ No INSPIRE recid found},
	pages = {747--758},
	annote = {Publisher: American Physiological Society},
	annote = {Publisher: American Physiological Society},
}

@article{Ballard2011,
	title = {Dual {Roles} for {Spike} {Signaling} in {Cortical} {Neural} {Populations}},
	volume = {5},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2011.00022},
	abstract = {A prominent feature of signaling in cortical neurons is that of randomness in the action potential. The output of a typical pyramidal cell can be well fit with a Poisson model, and variations in the Poisson rate repeatedly have been shown to be correlated with stimuli. However while the rate provides a very useful characterization of neural spike data, it may not be the most fundamental description of the signaling code. Recent data showing γ frequency range multi-cell action potential correlations, together with spike timing dependent plasticity, are spurring a re-examination of the classical model, since precise timing codes imply that the generation of spikes is essentially deterministic. Could the observed Poisson randomness and timing determinism reflect two separate modes of communication, or do they somehow derive from a single process? We investigate in a timing-based model whether the apparent incompatibility between these probabilistic and deterministic observations may be resolved by examining how spikes could be used in the underlying neural circuits. The crucial component of this model draws on dual roles for spike signaling. In learning receptive fields from ensembles of inputs, spikes need to behave probabilistically, whereas for fast signaling of individual stimuli, the spikes need to behave deterministically. Our simulations show that this combination is possible if deterministic signals using γ latency coding are probabilistically routed through different members of a cortical cell population at different times. This model exhibits standard features characteristic of Poisson models such as orientation tuning and exponential interval histograms. In addition, it makes testable predictions that follow from the γ latency coding.},
	urldate = {2022-12-16},
	journal = {Frontiers in Computational Neuroscience},
	author = {Ballard, Dana and Jehee, Janneke},
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
}

@article{Feller1997,
	title = {Dynamic {Processes} {Shape} {Spatiotemporal} {Properties} of {Retinal} {Waves}},
	volume = {19},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S089662730080940X},
	doi = {10.1016/S0896-6273(00)80940-X},
	abstract = {In the developing mammalian retina, spontaneous waves of action potentials are present in the ganglion cell layer weeks before vision. These waves are known to be generated by a synaptically connected network of amacrine cells and retinal ganglion cells, and exhibit complex spatiotemporal patterns, characterized by shifting domains of coactivation. Here, we present a novel dynamical model consisting of two coupled populations of cells that quantitatively reproduces the experimentally observed domain sizes, interwave intervals, and wavefront velocity profiles. Model and experiment together show that the highly correlated activity generated by retinal waves can be explained by a combination of random spontaneous activation of cells and the past history of local retinal activity.},
	language = {en},
	number = {2},
	urldate = {2022-12-16},
	journal = {Neuron},
	author = {Feller, Marla B. and Butts, Daniel A. and Aaron, Holly L. and Rokhsar, Daniel S. and Shatz, Carla J.},
	month = aug,
	year = {1997},
	keywords = {⛔ No INSPIRE recid found},
	pages = {293--306},
}

@article{Javanshir2022,
	title = {Advancements in {Algorithms} and {Neuromorphic} {Hardware} for {Spiking} {Neural} {Networks}},
	volume = {34},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco_a_01499},
	doi = {10.1162/neco_a_01499},
	abstract = {Artificial neural networks (ANNs) have experienced a rapid advancement for their success in various application domains, including autonomous driving and drone vision. Researchers have been improving the performance efficiency and computational requirement of ANNs inspired by the mechanisms of the biological brain. Spiking neural networks (SNNs) provide a power-efficient and brain-inspired computing paradigm for machine learning applications. However, evaluating large-scale SNNs on classical von Neumann architectures (central processing units/graphics processing units) demands a high amount of power and time. Therefore, hardware designers have developed neuromorphic platforms to execute SNNs in and approach that combines fast processing and low power consumption. Recently, field-programmable gate arrays (FPGAs) have been considered promising candidates for implementing neuromorphic solutions due to their varied advantages, such as higher flexibility, shorter design, and excellent stability. This review aims to describe recent advances in SNNs and the neuromorphic hardware platforms (digital, analog, hybrid, and FPGA based) suitable for their implementation. We present that biological background of SNN learning, such as neuron models and information encoding techniques, followed by a categorization of SNN training. In addition, we describe state-of-the-art SNN simulators. Furthermore, we review and present FPGA-based hardware implementation of SNNs. Finally, we discuss some future directions for research in this field.},
	number = {6},
	urldate = {2022-12-16},
	journal = {Neural Computation},
	author = {Javanshir, Amirhossein and Nguyen, Thanh Thi and Mahmud, M. A. Parvez and Kouzani, Abbas Z.},
	month = may,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1289--1328},
}

@article{Bryant1976,
	title = {Spike initiation by transmembrane current: a white-noise analysis.},
	volume = {260},
	issn = {1469-7793},
	shorttitle = {Spike initiation by transmembrane current},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1976.sp011516},
	doi = {10.1113/jphysiol.1976.sp011516},
	abstract = {1. Those features of a transmembrane current correlated with spike initiation were examined in Aplysia neurones using a Gaussian white-noise stimulus. This stimulus has the advantages that it presents numerous wave forms in random order without prejudgement as to their efficacies, and that it allows straightforward statistical calculations. 2. Stimulation with a repeating segment of Gaussian white-noise current revealed remarkable invariance in the firing times of the tested neurones and indicated a high degree of reliability of their response. 3. Frequencies (less than 5 Hz) involved in spike triggering propagated faithfully for up to several millimetres, justifying intrasomatic current injection to examine spike initiation at the trigger locus. 4. Examination of current wave forms preceding spikes indicated that a wide variety could be effective. Hence, a statistical analysis was performed, including computation of probability densities, averages, standard deviations and correlation coefficients of pairs of current values. Each statistic was displayed as a function of time before the spike. 5. The average current trajectory preceding a spike was multiphasic and depended on the presence and polarity of a d.c. bias. An early relatively small inward- or outward-going phase was followed by a large outward phase before the spike. The early phase tended to oppose the polarity of the d.c. bias. 6. The late outward phase of the average current trajectory reached a maximum 40–75 msec before triggering the action potential (AP) and returned to near zero values at the moment of triggering. The fact that the current peak occurs in advance of the AP may be partially explained by a phase delay between the transmembrane current and potential. The failure of the average current trajectory to return to control values immediately following the peak argues for a positive role of the declining phase in spike triggering. 7. Probability densities preceding spikes were Gaussian, indicating that the average was also the most probable value. Although the densities were broad, confirming that spikes were preceded by a wide variety of current wave forms, their standard deviations were reduced significantly with respect to controls, suggesting preferred status of the average current trajectory in spike triggering. 8. The matrix of correlation coefficients between current pairs suggested that spikes tended to be preceded by wave forms that in part kept close to the average current trajectory and in part preserved its shape. 9. The average first and second derivatives of spike-evoking epochs revealed that current slope and acceleration, respectively, were most crucial in the last 200 msec before spike triggering, and that these dynamic stimulus components were more important for a cell maintained under a depolarizing, rather than a hyperpolarizing bias. 10...},
	language = {en},
	number = {2},
	urldate = {2022-12-13},
	journal = {The Journal of Physiology},
	author = {Bryant, H L and Segundo, J P},
	year = {1976},
	note = {tex.copyright: © 1976 The Physiological Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {279--314},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1976.sp011516},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1976.sp011516},
}

@book{DiLorenzo2013,
	title = {Spike {Timing}: {Mechanisms} and {Function}},
	isbn = {978-1-4398-3815-0},
	shorttitle = {Spike {Timing}},
	abstract = {Neuronal communication forms the basis for all behavior, from the smallest movement to our grandest thought processes. Among the many mechanisms that support these functions, spike timing is among the most powerful and—until recently—perhaps the least studied. In the last two decades, however, the study of spike timing has exploded. The heightened interest is due to several factors. These include the development of physiological tools for measuring the activity of neural ensembles and analytical tools for assessing and characterizing spike timing. These advances are coupled with a growing appreciation of spike timing’s theoretical importance for the design principles of the brain. Spike Timing: Mechanisms and Function examines the function of spike timing in sensory, motor, and integrative processes, providing readers with a broad perspective on how spike timing is produced and used by the nervous system. It brings together the work and ideas of leaders in the field to address current thinking as well as future possibilities. The first section of the book describes the foundation for quantitative analysis and theory. It examines the information contained in spike timing, how it can be quantified, and how neural systems can extract it. The second section explores how input-output relationships are reflected in spike timing across a range of sensory systems. Drawing together multiple perspectives, including theoretical and computational studies as well as experimental studies in a range of model systems, the book provides a firm background for investigators to consider spike timing as it applies to their own work. It also offers a glimpse of future advances related to mechanisms of spike timing and its role in neural function, such as the development of novel computational technologies.},
	language = {en},
	publisher = {CRC Press},
	author = {DiLorenzo, Patricia M. and Victor, Jonathan D.},
	month = may,
	year = {2013},
	keywords = {⛔ No INSPIRE recid found, Computers / Software Development \& Engineering / Systems Analysis \& Design, Medical / Biotechnology, Science / Life Sciences / Biophysics, Science / Life Sciences / Neuroscience, Science / Physics / General, Technology \& Engineering / Biomedical},
	annote = {Google-Books-ID: KTHUIMUpQCUC},
	annote = {Google-Books-ID: KTHUIMUpQCUC},
}

@inproceedings{Arnold2021,
	title = {Conduction delay plasticity can robustly learn spatiotemporal patterns embedded in noise},
	doi = {10.1109/IJCNN52387.2021.9533934},
	abstract = {Noise and temporal dynamics are ubiquitous in neural systems yet the computational consequences of these two phenomena interacting are not well studied. Temporal dynamics in spiking networks are often considered only implicitly as part of membrane time constants or synaptic transfer functions. We explicitly model temporal structure using plastic conduction delays between neuron's and characterise the influence of different kinds of noise on learning including temporal jitter, dropout, pattern size, and pattern presentation frequency. We simplify the conduction delay plasticity (CDP) rule called synaptic delay variance learning (SDVL) and demonstrate it is robust to several kinds of noise including; internal pattern jitter, number of pattern afferents, pattern presentation rate, and pattern spike dropout. In particular, after unsupervised training the simplified version of SDVL can achieve an accuracy of up to 99.7 percent averaged over 100 trials. These results demonstrate that learning algorithms based on explicitly modelling temporal structure in inputs can be functional and robust for unsupervised learning of spatiotemporal patterns across a range of noise conditions.},
	booktitle = {2021 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Arnold, Joshua and Stratton, Peter and Wiles, Janet},
	month = jul,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found, Biological systems, Conduction delay, delay learning, Delays, Jitter, Noise measurement, noise robust, plasticity, Spatiotemporal phenomena, spiking neural network, Training, Transfer functions},
	pages = {1--10},
	annote = {ISSN: 2161-4407},
	annote = {ISSN: 2161-4407},
}

@article{Linden2022a,
	title = {Movement is governed by rotational neural dynamics in spinal motor networks},
	volume = {610},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-022-05293-w},
	doi = {10.1038/s41586-022-05293-w},
	abstract = {Although the generation of movements is a fundamental function of the nervous system, the underlying neural principles remain unclear. As flexor and extensor muscle activities alternate during rhythmic movements such as walking, it is often assumed that the responsible neural circuitry is similarly exhibiting alternating activity1. Here we present ensemble recordings of neurons in the lumbar spinal cord that indicate that, rather than alternating, the population is performing a low-dimensional ‘rotation’ in neural space, in which the neural activity is cycling through all phases continuously during the rhythmic behaviour. The radius of rotation correlates with the intended muscle force, and a perturbation of the low-dimensional trajectory can modify the motor behaviour. As existing models of spinal motor control do not offer an adequate explanation of rotation1,2, we propose a theory of neural generation of movements from which this and other unresolved issues, such as speed regulation, force control and multifunctionalism, are readily explained.},
	language = {en},
	number = {7932},
	urldate = {2022-11-16},
	journal = {Nature},
	author = {Lindén, Henrik and Petersen, Peter C. and Vestergaard, Mikkel and Berg, Rune W.},
	month = oct,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found, Central pattern generators, Network models},
	pages = {526--531},
}

@article{Schmitt1939,
	title = {The {Ultrastructure} of the {Nerve} {Axon} {Sheath}},
	volume = {14},
	issn = {1469-185X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-185X.1939.tb00922.x},
	doi = {10.1111/j.1469-185X.1939.tb00922.x},
	abstract = {1. In avoiding certain inherent indeterminacies in classical morphological methods and in obtaining further details regarding the microscopic and ultra-microscopic structure of nerve axon sheaths, the methods of polarization optics and X-ray diffraction are of great value. In the case of the myelin sheaths of vertebrate nerve fibres, for example, the optical and diffraction studies indicate the structure of the living fibre's sheath to be of smectic mixed fluid-crystalline nature. The structure is, therefore, readily altered by chemical treatment to form the artifacts commonly observed in histological preparations. 2. A number of considerations suggest that the specific configuration of the lipoid and protein components of the myelin sheath is as follows. The proteins occur as thin sheets wrapped concentrically about the axon, with two bimolecular layers of lipoids interspersed between adjacent protein layers. While this means that in a radial direction within the cylindrical sheath there are alternate predominantly aqueous and predominantly hyirocarbon phases, the latter cannot be described as being entirely “non-aqueous” 3. Polarization optical studies show that, contrary to the general view, invertebrate nerve fibres quite widely possess, aside from connective tissue investments, thin sheaths which are essentially similar in ultrastructure to the well-defined myelin sheaths of vertebrate fibres. The demonstration of this fact involved a reinterpretation of the meaning of Gothlin's metatropic reaction, in which immersion of the fibre in media of high refractive index permits the (intrinsic) birefringence of lipoids present in the normal sheath in an oriented condition to become apparent by the reduction of the masking (form) double refraction of protein. Associated with the invertebrate metatropic axon sheaths are cells similar to the Schwann cells of vertebrate fibres. 4. Quantitative birefringence studies have disclosed that the axon sheaths of a wide variety of fibre types differ chiefly with respect to the relative amounts of oriented protein and lipoid present. This difference is observed not only between typical invertebrate and vertebrate fibres, but also when the fibres of a single vertebrate nerve are compared. For example, the curve obtained when sheath birefringence of frog sciatic fibres is plotted against fibre diameter shows wide variations in the magnitude of double refraction, changing continuously from birefringence due preponderantly to lipoids, in the case of the larger fibres, to that which, in the smallest fibres, results primarily from proteins. The transition from lipoid to protein predominance occurs at a fibre diameter of about 2μ., agreeing well with the division between “medullated” and “non-medullated” fibres arrived at by histologists. It has been suggested that the low concentration of lipoid in the sheaths of small fibres is related to physical factors opposing the introduction of the lipoids into cylindrical structures of high curvature. 5. Examination of available information with respect to the relation of the velocity of impulse propagation to certain fibre characteristics, such as diameter and sheath ultrastructure, indicates that in a wide variety of fibres conduction velocity is a function of both of these factors. Thus, if fibres from invertebrate and vertebrate sources are classified according to sheath composition and ultrastructure, it is found that, within a group having similar sheaths, fast conduction is favoured by large diameter, while between groups with different sheaths, heavy myelination results in faster propagation. Comparison of fibre velocities with diameter alone, without regard to degree of myelination, is apt to be confusing, a fact which should be borne in mind in attempting to relate conduction velocity to diameter in a nerve, such as the frog sciatic, which contains fibres with very different sheaths. 6. Several types of invertebrate and vertebrate unipolar ganglion cells have been observed to possess investments similar to the axon sheaths and continuous with the latter. The entire surface of these neurons, therefore, is provided with a characteristic lipoid-protein covering, except possibly at the nodes of the myelin sheaths of the vertebrate sensory axons. The limiting envelopes of certain other cells and nuclei have been shown to possess an ultrastructure similar in type to that of the axon sheath. Permeability studies on cells have indicated the importance of lipoids and proteins in determining the properties of the plasma membrane, but it cannot be concluded that the visible envelopes are identical with the membrane which determines the physiological properties, since electrical and chemical studies favour the view that this membrane is extremely thin. The parallelisms observed between nerve sheath ultrastructure and physiological function, however, suggest some relation of these to membrane phenomena, and it is particularly difficult to understand how a multilayered structure, such as the vertebrate axon's myelin sheath, could fail to influence the chemical and electrical accessibility of the axon.},
	language = {en},
	number = {1},
	urldate = {2022-11-08},
	journal = {Biological Reviews},
	author = {Schmitt, Francis O. and Bear, Richard S.},
	year = {1939},
	keywords = {⛔ No INSPIRE recid found},
	pages = {27--50},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-185X.1939.tb00922.x},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-185X.1939.tb00922.x},
}

@article{Reynolds1928,
	title = {A {Study} of the {Structure} and {Function} of the {Interstitial} {Tissue} of the {Central} {Nervous} {System}},
	volume = {35},
	issn = {0367-1038},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5297025/},
	number = {2},
	urldate = {2022-11-08},
	journal = {Edinburgh Medical Journal},
	author = {Reynolds, F. E. and Slater, James K.},
	month = feb,
	year = {1928},
	pmid = {null},
	note = {tex.pmcid: PMC5297025},
	keywords = {⛔ No INSPIRE recid found},
	pages = {49--57},
}

@article{Brill1977,
	title = {Conduction velocity and spike configuration in myelinated fibres: computed dependence on internode distance.},
	volume = {40},
	issn = {0022-3050},
	shorttitle = {Conduction velocity and spike configuration in myelinated fibres},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC492833/},
	abstract = {It has been argued theoretically and confirmed experimentally that conduction velocity (theta) should be proportional to nerve fibre diameter for myelinated fibre tracts, such as normal peripheral nerve, exhibiting 'structural' similarity'. In some axons, however, the nodes of Ranvier are more closely spaced than in normal peripheral nerve. Analytic arguments have suggested that when internodal distance (L) alone is changed, the plot of theta versus L should have a relatively flat maximum. This was confirmed by several previous computer simulations of myelinated axons, but internode lengths of less than half the normal case were not examined. In order to gain insight into impulse propagation in myelinated and remyelinated fibres with short internodal lengths, the present study examines the conduction velocity and spike configuration for a wide range of internodal lengths. As L becomes large, theta falls and finally propagation is blocked; as L becomes small, theta decreases more and more steeply. From this, it is predicted that for fibres with very short internodal lengths, small local changes in L should affect substantially the conduction velocity.},
	number = {8},
	urldate = {2022-11-07},
	journal = {Journal of Neurology, Neurosurgery, and Psychiatry},
	author = {Brill, M H and Waxman, S G and Moore, J W and Joyner, R W},
	month = aug,
	year = {1977},
	pmid = {925697},
	note = {tex.pmcid: PMC492833},
	keywords = {⛔ No INSPIRE recid found},
	pages = {769--774},
}

@article{Gasser1939,
	title = {{AXON} {DIAMETERS} {IN} {RELATION} {TO} {THE} {SPIKE} {DIMENSIONS} {AND} {THE} {CONDUCTION} {VELOCITY} {IN} {MAMMALIAN} {A} {FIBERS}},
	url = {https://journals.physiology.org/doi/10.1152/ajplegacy.1939.127.2.393},
	doi = {10.1152/ajplegacy.1939.127.2.393},
	language = {en},
	urldate = {2022-11-07},
	journal = {American Journal of Physiology-Legacy Content},
	author = {Gasser, H. S. and Grundfest, H.},
	month = aug,
	year = {1939},
	note = {tex.copyright: Copyright © 1939 by American Physiological Society},
	keywords = {⛔ No INSPIRE recid found},
	annote = {Publisher: American Physiological Society},
	annote = {Publisher: American Physiological Society},
}

@article{Ermentrout2008,
	title = {Reliability, synchrony and noise},
	volume = {31},
	issn = {0166-2236},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2574942/},
	doi = {10.1016/j.tins.2008.06.002},
	abstract = {The brain is noisy. Neurons receive tens of thousands of highly fluctuating inputs and generate spike trains that appear highly irregular. Much of this activity is spontaneous—uncoupled to overt stimuli or motor outputs—leading to questions about the functional impact of this noise. Although noise is most often thought of as disrupting patterned activity and interfering with the encoding of stimuli, recent theoretical and experimental work has shown that noise can play a constructive role—leading to increased reliability or regularity of neuronal firing in single neurons and across populations. These results raise fundamental questions about how noise can influence neural function and computation.},
	number = {8},
	urldate = {2022-11-08},
	journal = {Trends in neurosciences},
	author = {Ermentrout, G. Bard and Galán, Roberto F. and Urban, Nathaniel N.},
	month = aug,
	year = {2008},
	pmid = {18603311},
	note = {tex.pmcid: PMC2574942},
	keywords = {⛔ No INSPIRE recid found},
	pages = {428--434},
}

@article{Vanni2001,
	title = {Coinciding early activation of the human primary visual cortex and anteromedial cuneus},
	volume = {98},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC30215/},
	doi = {10.1073/pnas.041600898},
	abstract = {Proper understanding of processes underlying visual perception requires information on the activation order of distinct brain areas. We measured dynamics of cortical signals with magnetoencephalography while human subjects viewed stimuli at four visual quadrants. The signals were analyzed with minimum current estimates at the individual and group level. Activation emerged 55–70 ms after stimulus onset both in the primary posterior visual areas and in the anteromedial part of the cuneus. Other cortical areas were active after this initial dual activation. Comparison of data between species suggests that the anteromedial cuneus either comprises a homologue of the monkey area V6 or is an area unique to humans. Our results show that visual stimuli activate two cortical areas right from the beginning of the cortical response. The anteromedial cuneus has the temporal position needed to interact with the primary visual cortex V1 and thereby to modify information transferred via V1 to extrastriate cortices.},
	number = {5},
	urldate = {2022-11-08},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Vanni, Simo and Tanskanen, Topi and Seppä, Mika and Uutela, Kimmo and Hari, Riitta},
	month = feb,
	year = {2001},
	pmid = {11226316},
	note = {tex.pmcid: PMC30215},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2776--2780},
}

@misc{Hazan2022,
	title = {Memory via {Temporal} {Delays} in weightless {Spiking} {Neural} {Network}},
	url = {http://arxiv.org/abs/2202.07132},
	abstract = {A common view in the neuroscience community is that memory is encoded in the connection strength between neurons. This perception led artificial neural network models to focus on connection weights as the key variables to modulate learning. In this paper, we present a prototype for weightless spiking neural networks that can perform a simple classification task. The memory in this network is stored in the timing between neurons, rather than the strength of the connection, and is trained using a Hebbian Spike Timing Dependent Plasticity (STDP), which modulates the delays of the connection.},
	urldate = {2022-10-27},
	publisher = {arXiv},
	author = {Hazan, Hananel and Caby, Simon and Earl, Christopher and Siegelmann, Hava and Levin, Michael},
	month = feb,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition, Statistics - Computation},
	annote = {arXiv:2202.07132 [cs, q-bio, stat]},
	annote = {arXiv:2202.07132 [cs, q-bio, stat]},
}

@article{Gautrais1998,
	title = {Rate coding versus temporal order coding: a theoretical approach},
	volume = {48},
	shorttitle = {Rate coding versus temporal order coding},
	doi = {10.1016/S0303-2647(98)00050-1},
	number = {1-3},
	journal = {Bio Systems},
	author = {Gautrais, Jacques and Thorpe, Simon},
	year = {1998},
	keywords = {⛔ No INSPIRE recid found},
	pages = {57--65},
	annote = {Publisher: Elsevier},
	annote = {Publisher: Elsevier},
}

@book{Datadien2011,
	title = {The {Right} {Delay} - {Detecting} {Specific} {Spike} {Patterns} with {STDP} and {Axonal} {Conduction} {Delays}.},
	abstract = {Axonal conduction delays should not be ignored in simulations of spiking neural networks. Here it is shown that by using axonal conduction delays, neurons can display sensitivity to a specific spatio-temporal spike pattern. By using delays that complement the firing times in a pattern, spikes can arrive simultaneously at an output neuron, giving it a high chance of firing in response to that pattern. An unsupervised learning mechanism called spike-timing-dependent plasticity then increases the weights for connections used in the pattern, and decreases the others. This allows for an attunement of output neurons to specific activity patterns, based on temporal aspects of axonal conductivity.},
	author = {Datadien, Arvind and Haselager, Pim and Sprinkhuizen-Kuyper, Ida},
	month = jan,
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
	annote = {Pages: 99},
	annote = {Pages: 99},
}

@article{Kreuz2007,
	title = {Measuring spike train synchrony},
	volume = {165},
	issn = {0165-0270},
	doi = {10.1016/j.jneumeth.2007.05.031},
	abstract = {Estimating the degree of synchrony or reliability between two or more spike trains is a frequent task in both experimental and computational neuroscience. In recent years, many different methods have been proposed that typically compare the timing of spikes on a certain time scale to be optimized by the analyst. Here, we propose the ISI-distance, a simple complementary approach that extracts information from the interspike intervals by evaluating the ratio of the instantaneous firing rates. The method is parameter free, time scale independent and easy to visualize as illustrated by an application to real neuronal spike trains obtained in vitro from rat slices. In a comparison with existing approaches on spike trains extracted from a simulated Hindemarsh-Rose network, the ISI-distance performs as well as the best time-scale-optimized measure based on spike timing.},
	language = {eng},
	number = {1},
	journal = {Journal of Neuroscience Methods},
	author = {Kreuz, Thomas and Haas, Julie S. and Morelli, Alice and Abarbanel, Henry D. I. and Politi, Antonio},
	month = sep,
	year = {2007},
	pmid = {17628690},
	keywords = {⛔ No INSPIRE recid found, Action Potentials, Animals, Electrophysiology, Neurons, Rats},
	pages = {151--161},
}

@techreport{Panahi2021a,
	title = {Generative {Models} of {Brain} {Dynamics} – {A} review},
	url = {https://arxiv.org/abs/2112.12147},
	abstract = {The principled design and discovery of biologically- and physically-informed models of neuronal dynamics has been advancing since the mid-twentieth century. Recent developments in artificial intelligence (AI) have accelerated this progress. This review article gives a high-level overview of the approaches across different scales of organization and levels of abstraction. The studies covered in this paper include fundamental models in computational neuroscience, nonlinear dynamics, data-driven methods, as well as emergent practices. While not all of these models span the intersection of neuroscience, AI, and system dynamics, all of them do or can work in tandem as generative models, which, as we argue, provide superior properties for the analysis of neuroscientific data. We discuss the limitations and unique dynamical traits of brain data and the complementary need for hypothesis- and data-driven modeling. By way of conclusion, we present several hybrid generative models from recent literature in scientific machine learning, which can be efficiently deployed to yield interpretable models of neural dynamics.},
	number = {2112.12147},
	institution = {arXiv},
	author = {Panahi, Mahta Ramezanian and Abrevaya, Germán and Gagnon-Audet, Jean-Christophe and Voleti, Vikram and Rish, Irina and Dumas, Guillaume},
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
}

@misc{Jeremie2022a,
	title = {Ultrafast image categorization in vivo and in silico},
	url = {http://arxiv.org/abs/2205.03635},
	abstract = {Humans are able to categorize images very efficiently, in particular to detect very rapidly the presence of an animal. Recently, deep learning algorithms have achieved higher accuracy than humans for a large set of visual recognition tasks. However, the tasks on which these artificial networks are usually trained and evaluated are usually very specialized which do not generalize well, for example with an accuracy drop following a rotation of the image. In this regard, biological visual systems are more flexible and efficient than artificial systems for more generic tasks, such as detecting an animal. To further the comparison between biological and artificial neural networks, we retrained the standard VGG16 convolutional neural network (CNN) on two independent tasks that are ecologically relevant to humans: detecting the presence of an animal or an artifact. We show that retraining the network achieves a human-like level of performance, comparable to what is reported in psychophysical tasks. Moreover, we show that categorization is better when combining the models' outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). Furthermore, these re-trained models were able to reproduce some unexpected behavioral observations of human psychophysics, such as robustness to rotations (e.g., an upside-down or tilted image) or to a grayscale transformation. Finally, we quantified the number of CNN layers needed to achieve such performance, showing that good accuracy for ultrafast image categorization could be achieved with only a few layers, challenging the belief that image recognition would require a deep sequential analysis of visual objects.},
	urldate = {2022-10-26},
	publisher = {arXiv},
	author = {Jérémie, Jean-Nicolas and Perrinet, Laurent U.},
	month = oct,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition},
	annote = {arXiv:2205.03635 [cs, q-bio]},
	annote = {arXiv:2205.03635 [cs, q-bio]},
}

@article{Wang2015,
	title = {A neuromorphic implementation of multiple spike-timing synaptic plasticity rules for large-scale neural networks},
	volume = {9},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2015.00180},
	doi = {10.3389/fnins.2015.00180},
	abstract = {We present a neuromorphic implementation of multiple synaptic plasticity learning rules, which include both Spike Timing Dependent Plasticity (STDP) and Spike Timing Dependent Delay Plasticity (STDDP). We present a fully digital implementation as well as a mixed-signal implementation, both of which use a novel dynamic-assignment time-multiplexing approach and support up to 226 (64M) synaptic plasticity elements. Rather than implementing dedicated synapses for particular types of synaptic plasticity, we implemented a more generic synaptic plasticity adaptor array that is separate from the neurons in the neural network. Each adaptor performs synaptic plasticity according to the arrival times of the pre- and post-synaptic spikes assigned to it, and sends out a weighted or delayed pre-synaptic spike to the post-synaptic neuron in the neural network. This strategy provides great flexibility for building complex large-scale neural networks, as a neural network can be configured for multiple synaptic plasticity rules without changing its structure. We validate the proposed neuromorphic implementations with measurement results and illustrate that the circuits are capable of performing both STDP and STDDP. We argue that it is practical to scale the work presented here up to 236 (64G) synaptic adaptors on a current high-end FPGA platform.},
	urldate = {2022-10-06},
	journal = {Frontiers in Neuroscience},
	author = {Wang, Runchun M. and Hamilton, Tara J. and Tapson, Jonathan C. and van Schaik, André},
	year = {2015},
	keywords = {⛔ No INSPIRE recid found},
}

@article{Isbister2021,
	title = {Clustering and control for adaptation uncovers time-warped spike time patterns in cortical networks in vivo},
	volume = {11},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-94002-0},
	doi = {10.1038/s41598-021-94002-0},
	abstract = {How information in the nervous system is encoded by patterns of action potentials (i.e. spikes) remains an open question. Multi-neuron patterns of single spikes are a prime candidate for spike time encoding but their temporal variability requires further characterisation. Here we show how known sources of spike count variability affect stimulus-evoked spike time patterns between neurons separated over multiple layers and columns of adult rat somatosensory cortex in vivo. On subsets of trials (clusters) and after controlling for stimulus-response adaptation, spike time differences between pairs of neurons are “time-warped” (compressed/stretched) by trial-to-trial changes in shared excitability, explaining why fixed spike time patterns and noise correlations are seldom reported. We show that predicted cortical state is correlated between groups of 4 neurons, introducing the possibility of spike time pattern modulation by population-wide trial-to-trial changes in excitability (i.e. cortical state). Under the assumption of state-dependent coding, we propose an improved potential encoding capacity.},
	language = {en},
	number = {1},
	urldate = {2022-10-06},
	journal = {Scientific Reports},
	author = {Isbister, James B. and Reyes-Puerta, Vicente and Sun, Jyh-Jang and Horenko, Illia and Luhmann, Heiko J.},
	month = jul,
	year = {2021},
	note = {tex.copyright: 2021 The Author(s)},
	keywords = {⛔ No INSPIRE recid found},
	pages = {15066},
	annote = {Number: 1 Publisher: Nature Publishing Group},
	annote = {Number: 1 Publisher: Nature Publishing Group},
}

@article{Delorme2000,
	title = {Ultra-rapid categorisation of natural scenes does not rely on colour cues: a study in monkeys and humans},
	volume = {40},
	issn = {0042-6989},
	shorttitle = {Ultra-rapid categorisation of natural scenes does not rely on colour cues},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698900000833},
	doi = {10.1016/S0042-6989(00)00083-3},
	abstract = {In a rapid categorisation task, monkeys and humans had to detect a target (animal or food) in briefly flashed (32 ms) and previously unseen natural images. Removing colour cues had very little effect on average performance. Impairments were restricted to a mild accuracy drop (in some human subjects) and a small reaction time mean increase (10–15 ms) observed both in monkeys and humans but only in the detection of food targets. In both tasks, accuracy and latency of the fastest behavioural responses were unaffected, suggesting that such ultra-rapid categorisations could depend on feed-forward processing of early coarse achromatic magnocellular information.},
	language = {en},
	number = {16},
	urldate = {2022-09-21},
	journal = {Vision Research},
	author = {Delorme, A and Richard, G and Fabre-Thorpe, M},
	month = jul,
	year = {2000},
	note = {tex.bdsk-url-2: https://doi.org/10.1016/S0042-6989(00)00083-3
tex.date-added: 2023-04-07 16:39:21 +0200
tex.date-modified: 2023-04-07 16:39:21 +0200},
	keywords = {⛔ No INSPIRE recid found, Categorisation, Colour, Natural scenes, Primate, Visual processing},
	pages = {2187--2200},
	file = {Texte intégral:/Users/laurentperrinet/Zotero/storage/NGPXFGWR/Delorme et al. - 2000 - Ultra-rapid categorisation of natural scenes does .pdf:application/pdf},
}

@inproceedings{Deneve2004,
	title = {Bayesian inference in spiking neurons},
	volume = {17},
	url = {https://papers.nips.cc/paper/2004/hash/cdd96eedd7f695f4d61802f8105ba2b0-Abstract.html},
	abstract = {We propose a new interpretation of spiking neurons as Bayesian integra- tors accumulating evidence over time about events in the external world or the body, and communicating to other neurons their certainties about these events. In this model, spikes signal the occurrence of new infor- mation, i.e. what cannot be predicted from the past activity. As a result, firing statistics are close to Poisson, albeit providing a deterministic rep- resentation of probabilities. We proceed to develop a theory of Bayesian inference in spiking neural networks, recurrent interactions implement- ing a variant of belief propagation.},
	urldate = {2022-12-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Deneve, Sophie},
	year = {2004},
	note = {tex.date-added: 2023-04-07 16:39:21 +0200
tex.date-modified: 2023-04-07 16:39:21 +0200},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@techreport{Grimaldi2022g,
	title = {Learning heterogeneous delays in a layer of spiking neurons for fast motion detection},
	url = {https://www.researchsquare.com/article/rs-2120999/v1},
	abstract = {The response of a biological neuron depends on the precise timing of afferent spikes. This temporal aspect of the neuronal code is essential in understanding information processing in neurobiology and applies particularly well to the output of neuromorphic hardware such as event-based cameras. Ho...},
	language = {en},
	urldate = {2022-11-06},
	author = {Grimaldi, Antoine and Perrinet, Laurent U},
	month = oct,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
}

@article{Delorme1999,
	title = {{SpikeNET}: {A} simulator for modeling large networks of integrate and fire neurons},
	volume = {26-27},
	issn = {0925-2312},
	shorttitle = {{SpikeNET}},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231299000958},
	doi = {10.1016/S0925-2312(99)00095-8},
	abstract = {SpikeNET is a simulator for modeling large networks of asynchronously spiking neurons. It uses simple integrate-and-fire neurons which undergo step-like changes in membrane potential when synaptic inputs arrive. If a threshold is exceeded, the potential is reset and the neuron added to a list to be propagated on the next time step. Using such spike lists greatly reduces the computations associated with large networks, and simplifies implementations using parallel hardware since inter-processor communication can be limited to sending lists of the neurons which just fired. We have used it to model complex multi-layer architectures based on the primate visual system that involve millions of neurons and billions of synaptic connections. Such models are not only biological but also efficient, robust and very fast, qualities which they share with the human visual system.},
	language = {en},
	urldate = {2022-09-28},
	journal = {Neurocomputing},
	author = {Delorme, Arnaud and Gautrais, Jacques and van Rullen, Rufin and Thorpe, Simon},
	month = jun,
	year = {1999},
	note = {tex.bdsk-url-2: https://doi.org/10.1016/S0925-2312(99)00095-8},
	keywords = {\#nosource, ⛔ No INSPIRE recid found, Biological visual systems, Categorization, Modeling software, Natural scenes},
	pages = {989--996},
	annote = {Publisher: Elsevier},
	annote = {Publisher: Elsevier},
}
